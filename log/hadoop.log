2017-02-22 10:34:16,596 INFO  [main] zookeeper.MiniZooKeeperCluster(200): Started MiniZK Cluster and connect 1 ZK server on client port: 16262
2017-02-22 10:34:16,686 DEBUG [main] security.Groups(180):  Creating new Groups object
2017-02-22 10:34:16,701 DEBUG [main] util.NativeCodeLoader(46): Trying to load the custom-built native-hadoop library...
2017-02-22 10:34:16,703 DEBUG [main] util.NativeCodeLoader(55): Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2017-02-22 10:34:16,703 DEBUG [main] util.NativeCodeLoader(56): java.library.path=/Users/roger/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2017-02-22 10:34:16,703 WARN  [main] util.NativeCodeLoader(62): Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-02-22 10:34:16,703 DEBUG [main] security.JniBasedUnixGroupsMappingWithFallback(40): Falling back to shell based
2017-02-22 10:34:16,706 DEBUG [main] security.JniBasedUnixGroupsMappingWithFallback(44): Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2017-02-22 10:34:16,750 DEBUG [main] security.Groups(66): Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2017-02-22 10:34:16,851 DEBUG [main] lib.MutableMetricsFactory(42): field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2017-02-22 10:34:16,863 DEBUG [main] lib.MutableMetricsFactory(42): field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2017-02-22 10:34:16,865 DEBUG [main] impl.MetricsSystemImpl(220): UgiMetrics, User and group related metrics
2017-02-22 10:34:16,928 DEBUG [main] util.KerberosName(87): Kerberos krb5 configuration not found, setting default realm to empty
2017-02-22 10:34:16,933 DEBUG [main] security.UserGroupInformation$HadoopLoginModule(177): hadoop login
2017-02-22 10:34:16,934 DEBUG [main] security.UserGroupInformation$HadoopLoginModule(126): hadoop login commit
2017-02-22 10:34:16,938 DEBUG [main] security.UserGroupInformation$HadoopLoginModule(156): using local user:UnixPrincipal: roger
2017-02-22 10:34:16,939 DEBUG [main] security.UserGroupInformation(703): UGI loginUser:roger (auth:SIMPLE)
2017-02-22 10:34:16,995 DEBUG [main] util.Shell(322): setsid is not available on this machine. So not using it.
2017-02-22 10:34:16,995 DEBUG [main] util.Shell(326): setsid exited with exit code 0
2017-02-22 10:34:17,006 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:34:17,052 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:17,054 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x70e8f8e-0x15a652bd7820000 connected
2017-02-22 10:34:17,058 INFO  [main] client.ZooKeeperRegistry(85): ClusterId read in ZooKeeper is null
2017-02-22 10:34:17,059 DEBUG [main] client.HConnectionManager$HConnectionImplementation(932): clusterid came back null, using default default-cluster
2017-02-22 10:34:17,070 DEBUG [main] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@313ac989, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:17,131 DEBUG [main] client.HConnectionManager(2976): master//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:34:17,244 INFO  [main] ipc.RpcServer$Listener(649): master//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:34:17,266 DEBUG [main] impl.MetricsSystemImpl(581): from system property: null
2017-02-22 10:34:17,266 DEBUG [main] impl.MetricsSystemImpl(582): from environment variable: null
2017-02-22 10:34:17,307 WARN  [main] impl.MetricsConfig(124): Cannot locate configuration: tried hadoop-metrics2-hbase.properties,hadoop-metrics2.properties
2017-02-22 10:34:17,314 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: period
2017-02-22 10:34:17,317 DEBUG [main] lib.MutableMetricsFactory(42): field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.snapshotStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Snapshot, Snapshot stats], valueName=Time)
2017-02-22 10:34:17,318 DEBUG [main] lib.MutableMetricsFactory(42): field org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishStat with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Publish, Publishing stats], valueName=Time)
2017-02-22 10:34:17,319 DEBUG [main] lib.MutableMetricsFactory(42): field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.metrics2.impl.MetricsSystemImpl.droppedPubAll with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Dropped updates by all sinks], valueName=Time)
2017-02-22 10:34:17,324 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:17,325 DEBUG [main] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:17,325 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:17,330 DEBUG [main] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:17,331 DEBUG [main] impl.MetricsSourceAdapter(252): Done. # tags & metrics=10
2017-02-22 10:34:17,331 DEBUG [main] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:17,331 DEBUG [main] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sources, name=NumActiveSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sources, name=NumAllSources, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of active metrics sinks, name=NumActiveSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of all registered metrics sinks, name=NumAllSinks, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for snapshot stats, name=SnapshotNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for snapshot stats, name=SnapshotAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for publishing stats, name=PublishNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for publishing stats, name=PublishAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Dropped updates by all sinks, name=DroppedPubAll, type=java.lang.Long, read-only, descriptor={}]]
2017-02-22 10:34:17,335 DEBUG [main] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:17,336 DEBUG [main] util.MBeans(58): Registered Hadoop:service=HBase,name=MetricsSystem,sub=Stats
2017-02-22 10:34:17,336 DEBUG [main] impl.MetricsSourceAdapter(221): MBean for source MetricsSystem,sub=Stats registered.
2017-02-22 10:34:17,337 INFO  [main] impl.MetricsSystemImpl(344): Scheduled snapshot period at 10 second(s).
2017-02-22 10:34:17,337 INFO  [main] impl.MetricsSystemImpl(183): HBase metrics system started
2017-02-22 10:34:17,338 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:17,338 DEBUG [main] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:17,338 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:17,339 DEBUG [main] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:17,339 DEBUG [main] impl.MetricsSourceAdapter(252): Done. # tags & metrics=6
2017-02-22 10:34:17,339 DEBUG [main] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:17,340 DEBUG [main] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of successful kerberos logins and latency (milliseconds), name=LoginSuccessAvgTime, type=java.lang.Double, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of ops for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureNumOps, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Average time for rate of failed kerberos logins and latency (milliseconds), name=LoginFailureAvgTime, type=java.lang.Double, read-only, descriptor={}]]
2017-02-22 10:34:17,340 DEBUG [main] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:17,340 DEBUG [main] util.MBeans(58): Registered Hadoop:service=HBase,name=UgiMetrics
2017-02-22 10:34:17,341 DEBUG [main] impl.MetricsSourceAdapter(221): MBean for source UgiMetrics registered.
2017-02-22 10:34:17,341 DEBUG [main] impl.MetricsSystemImpl(245): Registered source UgiMetrics
2017-02-22 10:34:17,342 DEBUG [main] util.MBeans(58): Registered Hadoop:service=HBase,name=MetricsSystem,sub=Control
2017-02-22 10:34:17,345 DEBUG [main] impl.MetricsSystemImpl(220): JvmMetrics, JVM related metrics etc.
2017-02-22 10:34:17,346 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:17,346 DEBUG [main] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:17,346 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:17,354 DEBUG [main] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:17,354 DEBUG [main] impl.MetricsSourceAdapter(252): Done. # tags & metrics=25
2017-02-22 10:34:17,354 DEBUG [main] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:17,355 DEBUG [main] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Process name, name=tag.ProcessName, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Session ID, name=tag.SessionId, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Non-heap memory used in MB, name=MemNonHeapUsedM, type=java.lang.Float, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Non-heap memory committed in MB, name=MemNonHeapCommittedM, type=java.lang.Float, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Heap memory used in MB, name=MemHeapUsedM, type=java.lang.Float, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Heap memory committed in MB, name=MemHeapCommittedM, type=java.lang.Float, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Max memory size in MB, name=MemMaxM, type=java.lang.Float, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GC Count for PS Scavenge, name=GcCountPS Scavenge, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GC Time for PS Scavenge, name=GcTimeMillisPS Scavenge, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GC Count for PS MarkSweep, name=GcCountPS MarkSweep, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=GC Time for PS MarkSweep, name=GcTimeMillisPS MarkSweep, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total GC count, name=GcCount, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total GC time in milliseconds, name=GcTimeMillis, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of new threads, name=ThreadsNew, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of runnable threads, name=ThreadsRunnable, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of blocked threads, name=ThreadsBlocked, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of waiting threads, name=ThreadsWaiting, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of timed waiting threads, name=ThreadsTimedWaiting, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Number of terminated threads, name=ThreadsTerminated, type=java.lang.Integer, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of fatal log events, name=LogFatal, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of error log events, name=LogError, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of warning log events, name=LogWarn, type=java.lang.Long, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Total number of info log events, name=LogInfo, type=java.lang.Long, read-only, descriptor={}]]
2017-02-22 10:34:17,356 DEBUG [main] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:17,356 DEBUG [main] util.MBeans(58): Registered Hadoop:service=HBase,name=JvmMetrics
2017-02-22 10:34:17,357 DEBUG [main] impl.MetricsSourceAdapter(221): MBean for source JvmMetrics registered.
2017-02-22 10:34:17,357 DEBUG [main] impl.MetricsSystemImpl(245): Registered source JvmMetrics
2017-02-22 10:34:17,360 DEBUG [main] impl.MetricsSystemImpl(220): IPC,sub=IPC, Metrics about HBase Server IPC
2017-02-22 10:34:17,361 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:17,361 DEBUG [main] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:17,361 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:17,362 DEBUG [main] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:17,363 DEBUG [main] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:17,363 DEBUG [main] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:17,364 DEBUG [main] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:17,364 DEBUG [main] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:17,364 DEBUG [main] util.MBeans(58): Registered Hadoop:service=HBase,name=IPC,sub=IPC
2017-02-22 10:34:17,364 DEBUG [main] impl.MetricsSourceAdapter(221): MBean for source IPC,sub=IPC registered.
2017-02-22 10:34:17,365 DEBUG [main] impl.MetricsSystemImpl(245): Registered source IPC,sub=IPC
2017-02-22 10:34:17,447 INFO  [main] master.HMaster(547): hbase.rootdir=file:/var/tmp/test-data/cluster1/root, hbase.cluster.distributed=false
2017-02-22 10:34:17,454 INFO  [main] conf.Configuration(840): mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2017-02-22 10:34:17,478 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=master:51895 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:34:17,484 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:518950x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:17,484 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): master:51895-0x15a652bd7820001 connected
2017-02-22 10:34:17,533 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:34:17,533 INFO  [RpcServer.listener,port=51895] ipc.RpcServer$Listener(783): RpcServer.listener,port=51895: starting
2017-02-22 10:34:17,537 DEBUG [main] impl.MetricsSystemImpl(220): Master,sub=Server, Metrics about HBase master server
2017-02-22 10:34:17,537 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:17,537 DEBUG [main] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:17,538 DEBUG [main] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:17,538 DEBUG [main] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:17,538 DEBUG [main] impl.MetricsSourceAdapter(252): Done. # tags & metrics=3
2017-02-22 10:34:17,539 DEBUG [main] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:17,539 DEBUG [main] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:17,539 DEBUG [main] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:17,539 DEBUG [main] util.MBeans(58): Registered Hadoop:service=HBase,name=Master,sub=Server
2017-02-22 10:34:17,539 DEBUG [main] impl.MetricsSourceAdapter(221): MBean for source Master,sub=Server registered.
2017-02-22 10:34:17,539 DEBUG [main] impl.MetricsSystemImpl(245): Registered source Master,sub=Server
2017-02-22 10:34:17,654 INFO  [main] conf.Configuration(840): hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2017-02-22 10:34:17,786 DEBUG [main] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:34:17,802 DEBUG [main] client.HConnectionManager(2976): regionserver//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:34:17,904 INFO  [main] ipc.SimpleRpcScheduler(86): Using default user call queue, count=3
2017-02-22 10:34:17,911 INFO  [main] ipc.RpcServer$Listener(649): regionserver//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:34:17,918 INFO  [main] hfile.CacheConfig(527): Allocating LruBlockCache with maximum size 1.4 G
2017-02-22 10:34:17,923 INFO  [main] hfile.CacheConfig(215): Created cacheConfig: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:18,002 INFO  [main] http.HttpServer(525): Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-02-22 10:34:18,007 INFO  [main] http.HttpServer(503): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2017-02-22 10:34:18,010 INFO  [main] http.HttpServer(510): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-02-22 10:34:18,025 INFO  [main] http.HttpServer(687): Jetty bound to port 51898
2017-02-22 10:34:18,499 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKUtil(368): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:34:18,502 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKUtil(368): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:34:18,552 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2017-02-22 10:34:18,555 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKUtil(366): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:18,559 WARN  [M:0;192.168.1.25:51895] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:34:18,559 INFO  [M:0;192.168.1.25:51895] master.ActiveMasterManager(170): Registered Active Master=192.168.1.25,51895,1487756057370
2017-02-22 10:34:18,560 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:18,560 DEBUG [main-EventThread] master.ActiveMasterManager(119): A master is now available
2017-02-22 10:34:18,566 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(220): Master,sub=FileSystem, Metrics about HBase master file system.
2017-02-22 10:34:18,566 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:18,566 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:18,566 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:18,566 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:18,566 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:18,566 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:18,567 DEBUG [M:0;192.168.1.25:51895] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:18,567 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:18,567 DEBUG [M:0;192.168.1.25:51895] util.MBeans(58): Registered Hadoop:service=HBase,name=Master,sub=FileSystem
2017-02-22 10:34:18,567 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(221): MBean for source Master,sub=FileSystem registered.
2017-02-22 10:34:18,567 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(245): Registered source Master,sub=FileSystem
2017-02-22 10:34:18,568 INFO  [M:0;192.168.1.25:51895] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:18,600 INFO  [main] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RS:0;192.168.1.25:51897
2017-02-22 10:34:18,601 DEBUG [RS:0;192.168.1.25:51897] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:339)
2017-02-22 10:34:18,601 INFO  [RS:0;192.168.1.25:51897] zookeeper.RecoverableZooKeeper(120): Process identifier=regionserver:51897 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:34:18,612 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:518970x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:18,612 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(591): regionserver:51897-0x15a652bd7820002 connected
2017-02-22 10:34:18,614 DEBUG [RS:0;192.168.1.25:51897] zookeeper.ZKUtil(366): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:18,616 INFO  [M:0;192.168.1.25:51895] util.FSUtils(696): Created version file at file:/var/tmp/test-data/cluster1/root with version=8
2017-02-22 10:34:18,623 DEBUG [RS:0;192.168.1.25:51897] zookeeper.ZKUtil(368): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:34:18,631 DEBUG [M:0;192.168.1.25:51895] util.FSUtils(848): Created cluster ID file at file:/var/tmp/test-data/cluster1/root/hbase.id with ID: 466fb901-930a-4d1a-81e7-53b5c702969c
2017-02-22 10:34:18,640 INFO  [M:0;192.168.1.25:51895] master.MasterFileSystem(550): BOOTSTRAP: creating hbase:meta region
2017-02-22 10:34:18,676 INFO  [M:0;192.168.1.25:51895] regionserver.HRegion(4729): creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster1/root Table name == hbase:meta
2017-02-22 10:34:18,705 INFO  [M:0;192.168.1.25:51895] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:18,725 INFO  [M:0;192.168.1.25:51895] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/WALs/hlog.1487756058707
2017-02-22 10:34:18,725 INFO  [M:0;192.168.1.25:51895] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2017-02-22 10:34:18,725 INFO  [M:0;192.168.1.25:51895] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2017-02-22 10:34:18,732 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(220): RegionServer,sub=WAL, Metrics about HBase RegionServer HLog
2017-02-22 10:34:18,732 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:18,732 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:18,732 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=WAL
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=WAL registered.
2017-02-22 10:34:18,733 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=WAL
2017-02-22 10:34:18,739 DEBUG [M:0;192.168.1.25:51895] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:34:18,770 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:18,778 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:18,788 INFO  [StoreOpener-1588230740-1] util.ChecksumType$2(70): Checksum using org.apache.hadoop.util.PureJavaCrc32
2017-02-22 10:34:18,790 INFO  [StoreOpener-1588230740-1] util.ChecksumType$3(113): Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2017-02-22 10:34:18,792 DEBUG [M:0;192.168.1.25:51895] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740
2017-02-22 10:34:18,795 INFO  [M:0;192.168.1.25:51895] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:34:18,795 DEBUG [M:0;192.168.1.25:51895] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:34:18,795 DEBUG [M:0;192.168.1.25:51895] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:34:18,796 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:34:18,797 INFO  [M:0;192.168.1.25:51895] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:34:18,797 DEBUG [M:0;192.168.1.25:51895-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): M:0;192.168.1.25:51895-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:34:18,797 INFO  [M:0;192.168.1.25:51895-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): M:0;192.168.1.25:51895-WAL.AsyncNotifier exiting
2017-02-22 10:34:18,797 DEBUG [M:0;192.168.1.25:51895-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51895-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:18,797 INFO  [M:0;192.168.1.25:51895-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51895-WAL.AsyncSyncer0 exiting
2017-02-22 10:34:18,797 DEBUG [M:0;192.168.1.25:51895-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51895-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:18,797 INFO  [M:0;192.168.1.25:51895-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51895-WAL.AsyncSyncer1 exiting
2017-02-22 10:34:18,797 DEBUG [M:0;192.168.1.25:51895-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51895-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:18,797 INFO  [M:0;192.168.1.25:51895-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51895-WAL.AsyncSyncer2 exiting
2017-02-22 10:34:18,798 DEBUG [M:0;192.168.1.25:51895-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51895-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:18,798 INFO  [M:0;192.168.1.25:51895-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51895-WAL.AsyncSyncer3 exiting
2017-02-22 10:34:18,798 DEBUG [M:0;192.168.1.25:51895-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51895-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:18,798 INFO  [M:0;192.168.1.25:51895-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51895-WAL.AsyncSyncer4 exiting
2017-02-22 10:34:18,798 DEBUG [M:0;192.168.1.25:51895-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): M:0;192.168.1.25:51895-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:34:18,798 INFO  [M:0;192.168.1.25:51895-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): M:0;192.168.1.25:51895-WAL.AsyncWriter exiting
2017-02-22 10:34:18,798 DEBUG [M:0;192.168.1.25:51895] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/WALs
2017-02-22 10:34:18,799 DEBUG [M:0;192.168.1.25:51895] wal.FSHLog(892): Moved 1 WAL file(s) to /var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/oldWALs
2017-02-22 10:34:18,820 DEBUG [M:0;192.168.1.25:51895] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster1/root/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-02-22 10:34:18,826 DEBUG [M:0;192.168.1.25:51895] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:34:18,832 DEBUG [M:0;192.168.1.25:51895] master.SplitLogManager(1360): Distributed log replay=false, hfile.format.version=2
2017-02-22 10:34:18,842 INFO  [M:0;192.168.1.25:51895] master.SplitLogManager(224): Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-02-22 10:34:18,846 INFO  [M:0;192.168.1.25:51895] master.SplitLogManager(1100): Found 0 orphan tasks and 0 rescan nodes
2017-02-22 10:34:18,846 DEBUG [M:0;192.168.1.25:51895] util.FSTableDescriptors(208): Fetching table descriptors from the filesystem.
2017-02-22 10:34:18,855 INFO  [M:0;192.168.1.25:51895] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x48bb59f3 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:34:18,858 DEBUG [M:0;192.168.1.25:51895-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x48bb59f30x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:18,858 DEBUG [M:0;192.168.1.25:51895-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x48bb59f3-0x15a652bd7820003 connected
2017-02-22 10:34:18,860 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@51198236, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:18,865 DEBUG [M:0;192.168.1.25:51895] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@42e065b0
2017-02-22 10:34:18,866 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKUtil(368): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(220): Master,sub=Balancer, Metrics about HBase master balancer
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] util.MBeans(58): Registered Hadoop:service=HBase,name=Master,sub=Balancer
2017-02-22 10:34:18,870 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(221): MBean for source Master,sub=Balancer registered.
2017-02-22 10:34:18,871 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(245): Registered source Master,sub=Balancer
2017-02-22 10:34:18,876 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKUtil(368): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/balancer
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(220): Master,sub=AssignmentManger, Metrics about HBase master assingment manager.
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:18,896 DEBUG [M:0;192.168.1.25:51895] util.MBeans(58): Registered Hadoop:service=HBase,name=Master,sub=AssignmentManger
2017-02-22 10:34:18,897 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSourceAdapter(221): MBean for source Master,sub=AssignmentManger registered.
2017-02-22 10:34:18,897 DEBUG [M:0;192.168.1.25:51895] impl.MetricsSystemImpl(245): Registered source Master,sub=AssignmentManger
2017-02-22 10:34:18,909 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:34:18,909 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:34:18,910 DEBUG [RS:0;192.168.1.25:51897] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@369db2a0
2017-02-22 10:34:18,911 INFO  [M:0;192.168.1.25:51895] master.HMaster(801): Server active/primary master=192.168.1.25,51895,1487756057370, sessionid=0x15a652bd7820001, setting cluster-up flag (Was=false)
2017-02-22 10:34:18,912 DEBUG [RS:0;192.168.1.25:51897] zookeeper.ZKUtil(368): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:34:18,915 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(805): ClusterId : 466fb901-930a-4d1a-81e7-53b5c702969c
2017-02-22 10:34:18,917 INFO  [RS:0;192.168.1.25:51897] procedure.RegionServerProcedureManagerHost(43): Procedure online-snapshot is initializing
2017-02-22 10:34:18,924 INFO  [RS:0;192.168.1.25:51897] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:34:18,928 INFO  [M:0;192.168.1.25:51895] procedure.ZKProcedureUtil(270): Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-02-22 10:34:18,929 INFO  [RS:0;192.168.1.25:51897] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/abort already exists and this is not a retry
2017-02-22 10:34:18,930 INFO  [RS:0;192.168.1.25:51897] procedure.RegionServerProcedureManagerHost(45): Procedure online-snapshot is initialized
2017-02-22 10:34:18,932 DEBUG [M:0;192.168.1.25:51895] procedure.ZKProcedureCoordinatorRpcs(195): Starting the controller for procedure member:192.168.1.25,51895,1487756057370
2017-02-22 10:34:18,934 INFO  [RS:0;192.168.1.25:51897] regionserver.MemStoreFlusher(119): globalMemStoreLimit=1.4 G, globalMemStoreLimitLowMark=1.4 G, maxHeap=3.6 G
2017-02-22 10:34:18,939 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer$CompactionChecker(1508): CompactionChecker runs every 10sec
2017-02-22 10:34:18,942 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@187a2021, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=192.168.1.25/192.168.1.25:0
2017-02-22 10:34:18,947 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,51895,1487756057370 with port=51897, startcode=1487756057911
2017-02-22 10:34:18,947 INFO  [M:0;192.168.1.25:51895] master.MasterCoprocessorHost(85): System coprocessor loading is enabled
2017-02-22 10:34:18,950 DEBUG [M:0;192.168.1.25:51895] executor.ExecutorService(100): Starting executor service name=MASTER_OPEN_REGION-192.168.1.25:51895, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:18,950 DEBUG [M:0;192.168.1.25:51895] executor.ExecutorService(100): Starting executor service name=MASTER_CLOSE_REGION-192.168.1.25:51895, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:18,950 DEBUG [M:0;192.168.1.25:51895] executor.ExecutorService(100): Starting executor service name=MASTER_SERVER_OPERATIONS-192.168.1.25:51895, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:18,950 DEBUG [M:0;192.168.1.25:51895] executor.ExecutorService(100): Starting executor service name=MASTER_META_SERVER_OPERATIONS-192.168.1.25:51895, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:18,950 DEBUG [M:0;192.168.1.25:51895] executor.ExecutorService(100): Starting executor service name=M_LOG_REPLAY_OPS-192.168.1.25:51895, corePoolSize=10, maxPoolSize=10
2017-02-22 10:34:18,950 DEBUG [M:0;192.168.1.25:51895] executor.ExecutorService(100): Starting executor service name=MASTER_TABLE_OPERATIONS-192.168.1.25:51895, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:18,952 DEBUG [M:0;192.168.1.25:51895] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-02-22 10:34:18,953 INFO  [M:0;192.168.1.25:51895] zookeeper.RecoverableZooKeeper(120): Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:34:18,957 DEBUG [M:0;192.168.1.25:51895-EventThread] zookeeper.ZooKeeperWatcher(528): replicationLogCleaner0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:18,957 DEBUG [M:0;192.168.1.25:51895-EventThread] zookeeper.ZooKeeperWatcher(591): replicationLogCleaner-0x15a652bd7820004 connected
2017-02-22 10:34:18,965 DEBUG [M:0;192.168.1.25:51895] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-02-22 10:34:18,970 DEBUG [M:0;192.168.1.25:51895] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-02-22 10:34:18,971 DEBUG [M:0;192.168.1.25:51895] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-02-22 10:34:18,973 DEBUG [M:0;192.168.1.25:51895] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-02-22 10:34:18,974 DEBUG [M:0;192.168.1.25:51895] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-02-22 10:34:18,974 INFO  [M:0;192.168.1.25:51895] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:19,043 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service RegionServerStatusService, sasl=false
2017-02-22 10:34:19,051 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51895
2017-02-22 10:34:19,057 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: starting, connections 1
2017-02-22 10:34:19,060 DEBUG [RpcServer.listener,port=51895] ipc.RpcServer$Listener(885): RpcServer.listener,port=51895: connection from 192.168.1.25:51902; # active connections: 1
2017-02-22 10:34:19,068 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 0 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:34:19,069 DEBUG [RpcServer.reader=1,port=51895] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "RegionServerStatusService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:19,087 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager(423): Registering server=192.168.1.25,51897,1487756057911
2017-02-22 10:34:19,090 INFO  [FifoRpcScheduler.handler1-thread-1] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:19,098 DEBUG [FifoRpcScheduler.handler1-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 184 bytes.
2017-02-22 10:34:19,100 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 0, totalSize: 180 bytes
2017-02-22 10:34:19,101 DEBUG [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1323): Config from master: hbase.rootdir=file:///var/tmp/test-data/cluster1/root
2017-02-22 10:34:19,101 DEBUG [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1323): Config from master: fs.default.name=file:/
2017-02-22 10:34:19,101 DEBUG [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1323): Config from master: hbase.master.info.port=-1
2017-02-22 10:34:19,104 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:34:19,108 DEBUG [RS:0;192.168.1.25:51897] zookeeper.ZKUtil(366): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51897,1487756057911
2017-02-22 10:34:19,111 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51897,1487756057911
2017-02-22 10:34:19,112 INFO  [RS:0;192.168.1.25:51897] regionserver.RegionServerCoprocessorHost(66): System coprocessor loading is enabled
2017-02-22 10:34:19,112 INFO  [RS:0;192.168.1.25:51897] regionserver.RegionServerCoprocessorHost(67): Table coprocessor loading is enabled
2017-02-22 10:34:19,112 WARN  [RS:0;192.168.1.25:51897] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:34:19,113 DEBUG [main-EventThread] zookeeper.RegionServerTracker(95): Added tracking of RS /hbase/rs/192.168.1.25,51897,1487756057911
2017-02-22 10:34:19,115 DEBUG [RS:0;192.168.1.25:51897] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:34:19,116 DEBUG [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1605): logdir=file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,51897,1487756057911
2017-02-22 10:34:19,132 INFO  [M:0;192.168.1.25:51895] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 158 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:19,134 DEBUG [RS:0;192.168.1.25:51897] regionserver.Replication(141): ReplicationStatisticsThread 300
2017-02-22 10:34:19,136 INFO  [RS:0;192.168.1.25:51897] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:19,153 INFO  [RS:0;192.168.1.25:51897] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster1/root/WALs/192.168.1.25,51897,1487756057911/192.168.1.25%2C51897%2C1487756057911.1487756059137
2017-02-22 10:34:19,153 INFO  [RS:0;192.168.1.25:51897] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:19,153 INFO  [RS:0;192.168.1.25:51897] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:19,158 INFO  [RS:0;192.168.1.25:51897] regionserver.MetricsRegionServerWrapperImpl(101): Computing regionserver metrics every 5000 milliseconds
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSystemImpl(220): RegionServer,sub=Server, Metrics about HBase RegionServer
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:19,161 DEBUG [RS:0;192.168.1.25:51897] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:19,162 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:19,162 DEBUG [RS:0;192.168.1.25:51897] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Server
2017-02-22 10:34:19,162 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Server registered.
2017-02-22 10:34:19,162 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Server
2017-02-22 10:34:19,163 DEBUG [RS:0;192.168.1.25:51897] executor.ExecutorService(100): Starting executor service name=RS_OPEN_REGION-192.168.1.25:51897, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:19,163 DEBUG [RS:0;192.168.1.25:51897] executor.ExecutorService(100): Starting executor service name=RS_OPEN_META-192.168.1.25:51897, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:19,163 DEBUG [RS:0;192.168.1.25:51897] executor.ExecutorService(100): Starting executor service name=RS_OPEN_PRIORITY_REGION-192.168.1.25:51897, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:19,163 DEBUG [RS:0;192.168.1.25:51897] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_REGION-192.168.1.25:51897, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:19,163 DEBUG [RS:0;192.168.1.25:51897] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_META-192.168.1.25:51897, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:19,163 DEBUG [RS:0;192.168.1.25:51897] executor.ExecutorService(100): Starting executor service name=RS_LOG_REPLAY_OPS-192.168.1.25:51897, corePoolSize=2, maxPoolSize=2
2017-02-22 10:34:19,169 DEBUG [RS:0;192.168.1.25:51897] zookeeper.ZKUtil(366): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51897,1487756057911
2017-02-22 10:34:19,169 INFO  [RS:0;192.168.1.25:51897] regionserver.ReplicationSourceManager(226): Current list of replicators: [192.168.1.25,51897,1487756057911] other RSs: [192.168.1.25,51897,1487756057911]
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker.persist.jobstatus.hours is deprecated. Instead, use mapreduce.jobtracker.persist.jobstatus.hours
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.heartbeats.in.second is deprecated. Instead, use mapreduce.jobtracker.heartbeats.in.second
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): jobclient.completion.poll.interval is deprecated. Instead, use mapreduce.client.completion.pollinterval
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.tasks.sleeptime-before-sigkill is deprecated. Instead, use mapreduce.tasktracker.tasks.sleeptimebeforesigkill
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.replication.considerLoad is deprecated. Instead, use dfs.namenode.replication.considerLoad
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.block.size is deprecated. Instead, use dfs.blocksize
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.permissions is deprecated. Instead, use dfs.permissions.enabled
2017-02-22 10:34:19,186 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
2017-02-22 10:34:19,187 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.access.time.precision is deprecated. Instead, use dfs.namenode.accesstime.precision
2017-02-22 10:34:19,187 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.skip.map.max.skip.records is deprecated. Instead, use mapreduce.map.skip.maxrecords
2017-02-22 10:34:19,187 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication
2017-02-22 10:34:19,187 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.https.client.keystore.resource is deprecated. Instead, use dfs.client.https.keystore.resource
2017-02-22 10:34:19,187 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): job.end.retry.attempts is deprecated. Instead, use mapreduce.job.end-notification.retry.attempts
2017-02-22 10:34:19,187 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2017-02-22 10:34:19,187 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.write.packet.size is deprecated. Instead, use dfs.client-write-packet-size
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.reduce.slowstart.completed.maps is deprecated. Instead, use mapreduce.job.reduce.slowstart.completedmaps
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.backup.http.address is deprecated. Instead, use dfs.namenode.backup.http-address
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.profile.reduces is deprecated. Instead, use mapreduce.task.profile.reduces
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.queue.name is deprecated. Instead, use mapreduce.job.queuename
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker.jobhistory.lru.cache.size is deprecated. Instead, use mapreduce.jobtracker.jobhistory.lru.cache.size
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.skip.attempts.to.start.skipping is deprecated. Instead, use mapreduce.task.skip.start.attempts
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.safemode.threshold.pct is deprecated. Instead, use dfs.namenode.safemode.threshold-pct
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.expiry.interval is deprecated. Instead, use mapreduce.jobtracker.expire.trackers.interval
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): keep.failed.task.files is deprecated. Instead, use mapreduce.task.files.preserve.failedtasks
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.map.tasks.maximum is deprecated. Instead, use mapreduce.tasktracker.map.tasks.maximum
2017-02-22 10:34:19,188 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.datanode.max.xcievers is deprecated. Instead, use dfs.datanode.max.transfer.threads
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.max.tracker.failures is deprecated. Instead, use mapreduce.job.maxtaskfailures.per.tracker
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.replication.min is deprecated. Instead, use dfs.namenode.replication.min
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.name.dir is deprecated. Instead, use dfs.namenode.name.dir
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.map.child.log.level is deprecated. Instead, use mapreduce.map.log.level
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.child.tmp is deprecated. Instead, use mapreduce.task.tmp.dir
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.local.dir.minspacestart is deprecated. Instead, use mapreduce.tasktracker.local.dir.minspacestart
2017-02-22 10:34:19,189 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): fs.checkpoint.period is deprecated. Instead, use dfs.namenode.checkpoint.period
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.safemode.extension is deprecated. Instead, use dfs.namenode.safemode.extension
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): tasktracker.http.threads is deprecated. Instead, use mapreduce.tasktracker.http.threads
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.jobtracker.restart.recover is deprecated. Instead, use mapreduce.jobtracker.restart.recover
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.jobtracker.taskScheduler is deprecated. Instead, use mapreduce.jobtracker.taskscheduler
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapreduce.jobtracker.split.metainfo.maxsize is deprecated. Instead, use mapreduce.job.split.metainfo.maxsize
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.tracker.report.address is deprecated. Instead, use mapreduce.tasktracker.report.address
2017-02-22 10:34:19,190 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.secondary.http.address is deprecated. Instead, use dfs.namenode.secondary.http-address
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.data.dir is deprecated. Instead, use dfs.datanode.data.dir
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.profile is deprecated. Instead, use mapreduce.task.profile
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.merge.recordsBeforeProgress is deprecated. Instead, use mapreduce.task.merge.progress.records
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.reduce.input.buffer.percent is deprecated. Instead, use mapreduce.reduce.input.buffer.percent
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.shuffle.input.buffer.percent is deprecated. Instead, use mapreduce.reduce.shuffle.input.buffer.percent
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): job.end.retry.interval is deprecated. Instead, use mapreduce.job.end-notification.retry.interval
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.dns.nameserver is deprecated. Instead, use mapreduce.tasktracker.dns.nameserver
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.speculative.execution.slowTaskThreshold is deprecated. Instead, use mapreduce.job.speculative.slowtaskthreshold
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.name.dir.restore is deprecated. Instead, use dfs.namenode.name.dir.restore
2017-02-22 10:34:19,191 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.df.interval is deprecated. Instead, use fs.df.interval
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.temp.dir is deprecated. Instead, use mapreduce.cluster.temp.dir
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.acls.enabled is deprecated. Instead, use mapreduce.cluster.acls.enabled
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): io.sort.spill.percent is deprecated. Instead, use mapreduce.map.sort.spill.percent
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.instrumentation is deprecated. Instead, use mapreduce.tasktracker.instrumentation
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker.handler.count is deprecated. Instead, use mapreduce.jobtracker.handler.count
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.shuffle.merge.percent is deprecated. Instead, use mapreduce.reduce.shuffle.merge.percent
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.system.dir is deprecated. Instead, use mapreduce.jobtracker.system.dir
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker.retiredjobs.cache.size is deprecated. Instead, use mapreduce.jobtracker.retiredjobs.cache.size
2017-02-22 10:34:19,192 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.jobtracker.instrumentation is deprecated. Instead, use mapreduce.jobtracker.instrumentation
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.skip.reduce.max.skip.groups is deprecated. Instead, use mapreduce.reduce.skip.maxgroups
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.jobtracker.maxtasks.per.job is deprecated. Instead, use mapreduce.jobtracker.maxtasks.perjob
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.tracker.task-controller is deprecated. Instead, use mapreduce.tasktracker.taskcontroller
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.reduce.parallel.copies is deprecated. Instead, use mapreduce.reduce.shuffle.parallelcopies
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): jobclient.progress.monitor.poll.interval is deprecated. Instead, use mapreduce.client.progressmonitor.pollinterval
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.map.max.attempts is deprecated. Instead, use mapreduce.map.maxattempts
2017-02-22 10:34:19,193 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.profile.maps is deprecated. Instead, use mapreduce.task.profile.maps
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.shuffle.read.timeout is deprecated. Instead, use mapreduce.reduce.shuffle.read.timeout
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.indexcache.mb is deprecated. Instead, use mapreduce.tasktracker.indexcache.mb
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.max.tracker.blacklists is deprecated. Instead, use mapreduce.jobtracker.tasktracker.maxblacklists
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): topology.script.number.args is deprecated. Instead, use net.topology.script.number.args
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.http.address is deprecated. Instead, use dfs.namenode.http-address
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.permissions.supergroup is deprecated. Instead, use dfs.permissions.superusergroup
2017-02-22 10:34:19,194 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.dns.interface is deprecated. Instead, use mapreduce.tasktracker.dns.interface
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker.persist.jobstatus.active is deprecated. Instead, use mapreduce.jobtracker.persist.jobstatus.active
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.cache.levels is deprecated. Instead, use mapreduce.jobtracker.taskcache.levels
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.https.address is deprecated. Instead, use dfs.namenode.https-address
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.speculative.execution.slowNodeThreshold is deprecated. Instead, use mapreduce.job.speculative.slownodethreshold
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.tracker.persist.jobstatus.dir is deprecated. Instead, use mapreduce.jobtracker.persist.jobstatus.dir
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.task.tracker.http.address is deprecated. Instead, use mapreduce.tasktracker.http.address
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.taskmemorymanager.monitoring-interval is deprecated. Instead, use mapreduce.tasktracker.taskmemorymanager.monitoringinterval
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.inmem.merge.threshold is deprecated. Instead, use mapreduce.reduce.merge.inmem.threshold
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.umaskmode is deprecated. Instead, use fs.permissions.umask-mode
2017-02-22 10:34:19,195 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.backup.address is deprecated. Instead, use dfs.namenode.backup.address
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.map.output.compression.codec is deprecated. Instead, use mapreduce.map.output.compress.codec
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.reduce.child.log.level is deprecated. Instead, use mapreduce.reduce.log.level
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): fs.checkpoint.edits.dir is deprecated. Instead, use dfs.namenode.checkpoint.edits.dir
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.healthChecker.interval is deprecated. Instead, use mapreduce.tasktracker.healthchecker.interval
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.output.compression.codec is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.codec
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.speculative.execution.speculativeCap is deprecated. Instead, use mapreduce.job.speculative.speculativecap
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): fs.checkpoint.dir is deprecated. Instead, use dfs.namenode.checkpoint.dir
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.balance.bandwidthPerSec is deprecated. Instead, use dfs.datanode.balance.bandwidthPerSec
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.shuffle.connect.timeout is deprecated. Instead, use mapreduce.reduce.shuffle.connect.timeout
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.https.need.client.auth is deprecated. Instead, use dfs.client.https.need-auth
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): jobclient.output.filter is deprecated. Instead, use mapreduce.client.output.filter
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.jobtracker.job.history.block.size is deprecated. Instead, use mapreduce.jobtracker.jobhistory.block.size
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.job.reuse.jvm.num.tasks is deprecated. Instead, use mapreduce.job.jvm.numtasks
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.reduce.max.attempts is deprecated. Instead, use mapreduce.reduce.maxattempts
2017-02-22 10:34:19,196 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.healthChecker.script.timeout is deprecated. Instead, use mapreduce.tasktracker.healthchecker.script.timeout
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.tasktracker.reduce.tasks.maximum is deprecated. Instead, use mapreduce.tasktracker.reduce.tasks.maximum
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.userlog.limit.kb is deprecated. Instead, use mapreduce.task.userlog.limit.kb
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.userlog.retain.hours is deprecated. Instead, use mapreduce.job.userlog.retain.hours
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.max.objects is deprecated. Instead, use dfs.namenode.max.objects
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.name.edits.dir is deprecated. Instead, use dfs.namenode.edits.dir
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): dfs.replication.interval is deprecated. Instead, use dfs.namenode.replication.interval
2017-02-22 10:34:19,197 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapred.local.dir.minspacekill is deprecated. Instead, use mapreduce.tasktracker.local.dir.minspacekill
2017-02-22 10:34:19,200 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSystemImpl(220): RegionServer,sub=Replication, Metrics about HBase replication
2017-02-22 10:34:19,200 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:19,200 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:19,200 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:19,200 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:19,201 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:19,201 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:19,201 DEBUG [RS:0;192.168.1.25:51897] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:19,201 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:19,201 DEBUG [RS:0;192.168.1.25:51897] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Replication
2017-02-22 10:34:19,201 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Replication registered.
2017-02-22 10:34:19,201 DEBUG [RS:0;192.168.1.25:51897] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Replication
2017-02-22 10:34:19,202 INFO  [RS:0;192.168.1.25:51897] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x3c28b592 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:34:19,208 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x3c28b5920x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:19,208 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x3c28b592-0x15a652bd7820005 connected
2017-02-22 10:34:19,211 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3f4985d0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:19,212 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:34:19,213 INFO  [RpcServer.listener,port=51897] ipc.RpcServer$Listener(783): RpcServer.listener,port=51897: starting
2017-02-22 10:34:19,213 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=0 queue=0
2017-02-22 10:34:19,214 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=1 queue=1
2017-02-22 10:34:19,214 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=2 queue=2
2017-02-22 10:34:19,214 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=3 queue=0
2017-02-22 10:34:19,214 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=4 queue=1
2017-02-22 10:34:19,215 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=5 queue=2
2017-02-22 10:34:19,215 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=6 queue=0
2017-02-22 10:34:19,215 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=7 queue=1
2017-02-22 10:34:19,215 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=8 queue=2
2017-02-22 10:34:19,216 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=9 queue=0
2017-02-22 10:34:19,216 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=10 queue=1
2017-02-22 10:34:19,216 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=11 queue=2
2017-02-22 10:34:19,217 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=12 queue=0
2017-02-22 10:34:19,217 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=13 queue=1
2017-02-22 10:34:19,218 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=14 queue=2
2017-02-22 10:34:19,218 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=15 queue=0
2017-02-22 10:34:19,219 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=16 queue=1
2017-02-22 10:34:19,219 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=17 queue=2
2017-02-22 10:34:19,219 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=18 queue=0
2017-02-22 10:34:19,220 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=19 queue=1
2017-02-22 10:34:19,220 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=20 queue=2
2017-02-22 10:34:19,221 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=21 queue=0
2017-02-22 10:34:19,221 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=22 queue=1
2017-02-22 10:34:19,221 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=23 queue=2
2017-02-22 10:34:19,221 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=24 queue=0
2017-02-22 10:34:19,222 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=25 queue=1
2017-02-22 10:34:19,222 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=26 queue=2
2017-02-22 10:34:19,222 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=27 queue=0
2017-02-22 10:34:19,223 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=28 queue=1
2017-02-22 10:34:19,223 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): B.Default Start Handler index=29 queue=2
2017-02-22 10:34:19,223 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=0 queue=0
2017-02-22 10:34:19,224 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=1 queue=0
2017-02-22 10:34:19,224 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=2 queue=0
2017-02-22 10:34:19,224 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=3 queue=0
2017-02-22 10:34:19,225 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=4 queue=0
2017-02-22 10:34:19,225 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=5 queue=0
2017-02-22 10:34:19,225 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=6 queue=0
2017-02-22 10:34:19,225 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=7 queue=0
2017-02-22 10:34:19,226 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=8 queue=0
2017-02-22 10:34:19,226 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Priority Start Handler index=9 queue=0
2017-02-22 10:34:19,226 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Replication Start Handler index=0 queue=0
2017-02-22 10:34:19,226 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Replication Start Handler index=1 queue=0
2017-02-22 10:34:19,227 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcExecutor(115): Replication Start Handler index=2 queue=0
2017-02-22 10:34:19,244 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:34:19,245 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:34:19,245 INFO  [RS:0;192.168.1.25:51897] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:19,249 INFO  [SplitLogWorker-192.168.1.25,51897,1487756057911] regionserver.SplitLogWorker(176): SplitLogWorker 192.168.1.25,51897,1487756057911 starting
2017-02-22 10:34:19,251 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1367): Serving as 192.168.1.25,51897,1487756057911, RpcServer on 192.168.1.25/192.168.1.25:51897, sessionid=0x15a652bd7820002
2017-02-22 10:34:19,252 INFO  [RS:0;192.168.1.25:51897] procedure.RegionServerProcedureManagerHost(51): Procedure online-snapshot is starting
2017-02-22 10:34:19,252 DEBUG [RS:0;192.168.1.25:51897] snapshot.RegionServerSnapshotManager(124): Start Snapshot Manager 192.168.1.25,51897,1487756057911
2017-02-22 10:34:19,252 DEBUG [RS:0;192.168.1.25:51897] procedure.ZKProcedureMemberRpcs(340): Starting procedure member '192.168.1.25,51897,1487756057911'
2017-02-22 10:34:19,252 DEBUG [RS:0;192.168.1.25:51897] procedure.ZKProcedureMemberRpcs(136): Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2017-02-22 10:34:19,253 INFO  [SplitLogWorker-192.168.1.25,51897,1487756057911] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x34904cda connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:34:19,257 DEBUG [RS:0;192.168.1.25:51897] procedure.ZKProcedureMemberRpcs(152): Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2017-02-22 10:34:19,259 INFO  [RS:0;192.168.1.25:51897] procedure.RegionServerProcedureManagerHost(53): Procedure online-snapshot is started
2017-02-22 10:34:19,261 DEBUG [SplitLogWorker-192.168.1.25,51897,1487756057911-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x34904cda0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:19,261 DEBUG [SplitLogWorker-192.168.1.25,51897,1487756057911-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x34904cda-0x15a652bd7820006 connected
2017-02-22 10:34:19,265 DEBUG [SplitLogWorker-192.168.1.25,51897,1487756057911] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@75ad46e1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:19,278 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 1 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:19,281 DEBUG [FifoRpcScheduler.handler1-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:34:19,281 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:34:20,646 INFO  [M:0;192.168.1.25:51895] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 1672 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:22,191 INFO  [M:0;192.168.1.25:51895] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 3217 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:22,287 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 2 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:22,289 DEBUG [FifoRpcScheduler.handler1-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 8 bytes.
2017-02-22 10:34:22,289 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 2, totalSize: 4 bytes
2017-02-22 10:34:23,529 INFO  [M:0;192.168.1.25:51895] master.ServerManager(918): Finished waiting for region servers count to settle; checked in 1, slept for 4555 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-02-22 10:34:23,530 INFO  [M:0;192.168.1.25:51895] master.MasterFileSystem(260): Log folder file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,51897,1487756057911 belongs to an existing region server
2017-02-22 10:34:24,367 INFO  [M:0;192.168.1.25:51895] zookeeper.MetaRegionTracker(184): Unsetting hbase:meta region location in ZooKeeper
2017-02-22 10:34:24,371 DEBUG [M:0;192.168.1.25:51895] zookeeper.RecoverableZooKeeper(188): Node /hbase/meta-region-server already deleted, retry=false
2017-02-22 10:34:24,374 DEBUG [M:0;192.168.1.25:51895] master.AssignmentManager(2461): No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=192.168.1.25,51897,1487756057911; 1 (online=1, available=1) available servers, forceNewPlan=false
2017-02-22 10:34:24,374 INFO  [M:0;192.168.1.25:51895] master.AssignmentManager(2089): Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:24,375 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKAssign(206): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-02-22 10:34:24,382 DEBUG [M:0;192.168.1.25:51895] master.AssignmentManager(2105): Setting table hbase:meta to ENABLED state.
2017-02-22 10:34:24,390 INFO  [M:0;192.168.1.25:51895] master.AssignmentManager(2120): Assigning hbase:meta,,1.1588230740 to 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,390 INFO  [M:0;192.168.1.25:51895] master.RegionStates(894): Transition {1588230740 state=OFFLINE, ts=1487756064374, server=null} to {1588230740 state=PENDING_OPEN, ts=1487756064390, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,390 DEBUG [M:0;192.168.1.25:51895] master.ServerManager(836): New admin connection to 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,404 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:34:24,404 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51897
2017-02-22 10:34:24,404 DEBUG [RpcServer.listener,port=51897] ipc.RpcServer$Listener(885): RpcServer.listener,port=51897: connection from 192.168.1.25:51905; # active connections: 1
2017-02-22 10:34:24,405 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: starting, connections 1
2017-02-22 10:34:24,405 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 0 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:34:24,406 DEBUG [RpcServer.reader=1,port=51897] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:24,408 INFO  [PriorityRpcServer.handler=0,queue=0,port=51897] regionserver.HRegionServer(4011): Open hbase:meta,,1.1588230740
2017-02-22 10:34:24,411 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] zookeeper.ZKAssign(832): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:24,412 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:34:24,412 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:34:24,415 INFO  [M:0;192.168.1.25:51895] master.ServerManager(618): AssignmentManager hasn't finished failover cleanup; waiting
2017-02-22 10:34:24,416 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:24,416 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] zookeeper.ZKAssign(907): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:24,416 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] regionserver.HRegionServer(1622): logdir=file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,417 INFO  [RS_OPEN_META-192.168.1.25:51897-0] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:24,422 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51897,1487756057911, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1487756064390, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,422 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates(894): Transition {1588230740 state=PENDING_OPEN, ts=1487756064390, server=192.168.1.25,51897,1487756057911} to {1588230740 state=OPENING, ts=1487756064422, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,444 INFO  [RS_OPEN_META-192.168.1.25:51897-0] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster1/root/WALs/192.168.1.25,51897,1487756057911/192.168.1.25%2C51897%2C1487756057911.1487756064418.meta
2017-02-22 10:34:24,445 INFO  [RS_OPEN_META-192.168.1.25:51897-0] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:24,445 INFO  [RS_OPEN_META-192.168.1.25:51897-0] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:24,448 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] regionserver.HRegion(4915): Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:24,500 INFO  [RS_OPEN_META-192.168.1.25:51897-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:34:24,501 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] coprocessor.CoprocessorHost(226): Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2017-02-22 10:34:24,505 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] regionserver.HRegion(6103): Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2017-02-22 10:34:24,506 INFO  [RS_OPEN_META-192.168.1.25:51897-0] regionserver.RegionCoprocessorHost(373): Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2017-02-22 10:34:24,513 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsSystemImpl(220): RegionServer,sub=Regions, Metrics about HBase RegionServer regions and tables
2017-02-22 10:34:24,513 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:24,513 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:24,513 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:24,513 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:24,513 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:24,514 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:24,514 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:24,514 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:24,514 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Regions
2017-02-22 10:34:24,514 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Regions registered.
2017-02-22 10:34:24,514 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Regions
2017-02-22 10:34:24,515 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table meta 1588230740
2017-02-22 10:34:24,515 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:34:24,520 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:24,521 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:24,522 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740
2017-02-22 10:34:24,524 INFO  [RS_OPEN_META-192.168.1.25:51897-0] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:34:24,524 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] zookeeper.ZKAssign(644): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2017-02-22 10:34:24,528 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:meta,,1.1588230740
2017-02-22 10:34:24,529 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1911): Updating zk with meta location
2017-02-22 10:34:24,529 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaRegionTracker(142): Setting hbase:meta region location in ZooKeeper as 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,538 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:34:24,538 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:34:24,542 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:meta,,1.1588230740
2017-02-22 10:34:24,543 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] zookeeper.ZKAssign(832): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:24,550 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] zookeeper.ZKAssign(907): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:24,550 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] handler.OpenRegionHandler(403): Transitioned 1588230740 to OPENED in zk on 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,551 DEBUG [RS_OPEN_META-192.168.1.25:51897-0] handler.OpenRegionHandler(189): Opened hbase:meta,,1.1588230740 on 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,551 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:24,553 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51897,1487756057911, region=1588230740, current_state={1588230740 state=OPENING, ts=1487756064422, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,553 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates(894): Transition {1588230740 state=OPENING, ts=1487756064422, server=192.168.1.25,51897,1487756057911} to {1588230740 state=OPEN, ts=1487756064553, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,555 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler(147): Handling OPENED of 1588230740 from 192.168.1.25,51897,1487756057911; deleting unassigned node
2017-02-22 10:34:24,561 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:24,561 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign(480): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:34:24,562 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager$4(1316): Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1487756064553, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,563 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates(397): Onlined 1588230740 on 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,564 INFO  [M:0;192.168.1.25:51895] master.HMaster(1162): hbase:meta assigned=1, rit=false, location=192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,618 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:34:24,618 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51897
2017-02-22 10:34:24,619 DEBUG [RpcServer.listener,port=51897] ipc.RpcServer$Listener(885): RpcServer.listener,port=51897: connection from 192.168.1.25:51906; # active connections: 2
2017-02-22 10:34:24,619 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: starting, connections 2
2017-02-22 10:34:24,621 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 1 method_name: "Scan" request_param: true
2017-02-22 10:34:24,622 DEBUG [RpcServer.reader=2,port=51897] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:24,649 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 16 bytes.
2017-02-22 10:34:24,649 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 1, totalSize: 12 bytes
2017-02-22 10:34:24,650 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,652 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 18 bytes.
2017-02-22 10:34:24,652 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 2, totalSize: 14 bytes
2017-02-22 10:34:24,653 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,654 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 12 bytes.
2017-02-22 10:34:24,654 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 3, totalSize: 8 bytes
2017-02-22 10:34:24,654 INFO  [M:0;192.168.1.25:51895] catalog.MetaMigrationConvertingToPB(166): hbase:meta doesn't have any entries to update.
2017-02-22 10:34:24,654 INFO  [M:0;192.168.1.25:51895] catalog.MetaMigrationConvertingToPB(132): META already up-to date with PB serialization
2017-02-22 10:34:24,664 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true
2017-02-22 10:34:24,667 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 16 bytes.
2017-02-22 10:34:24,667 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 4, totalSize: 12 bytes
2017-02-22 10:34:24,667 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,668 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 18 bytes.
2017-02-22 10:34:24,668 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 5, totalSize: 14 bytes
2017-02-22 10:34:24,669 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,669 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 12 bytes.
2017-02-22 10:34:24,669 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 6, totalSize: 8 bytes
2017-02-22 10:34:24,676 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKAssign(498): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Deleting any existing unassigned nodes
2017-02-22 10:34:24,678 INFO  [M:0;192.168.1.25:51895] master.AssignmentManager(646): Clean cluster startup. Assigning user regions
2017-02-22 10:34:24,680 INFO  [M:0;192.168.1.25:51895] master.SnapshotOfRegionAssignmentFromMeta(95): Start to scan the hbase:meta for the current region assignment snappshot
2017-02-22 10:34:24,681 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true
2017-02-22 10:34:24,682 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 16 bytes.
2017-02-22 10:34:24,683 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 7, totalSize: 12 bytes
2017-02-22 10:34:24,683 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,684 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 18 bytes.
2017-02-22 10:34:24,684 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 8, totalSize: 14 bytes
2017-02-22 10:34:24,685 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,685 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 12 bytes.
2017-02-22 10:34:24,686 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 9, totalSize: 8 bytes
2017-02-22 10:34:24,686 INFO  [M:0;192.168.1.25:51895] master.SnapshotOfRegionAssignmentFromMeta(138): Finished to scan the hbase:meta for the current region assignmentsnapshot
2017-02-22 10:34:24,706 INFO  [M:0;192.168.1.25:51895] master.AssignmentManager(511): Joined the cluster in 51ms, failover=false
2017-02-22 10:34:24,718 DEBUG [CatalogJanitor-192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 11 method_name: "Scan" request_param: true
2017-02-22 10:34:24,718 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true
2017-02-22 10:34:24,719 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 16 bytes.
2017-02-22 10:34:24,719 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 11, totalSize: 12 bytes
2017-02-22 10:34:24,719 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 16 bytes.
2017-02-22 10:34:24,719 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 10, totalSize: 12 bytes
2017-02-22 10:34:24,721 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 18 bytes.
2017-02-22 10:34:24,721 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:34:24,722 DEBUG [CatalogJanitor-192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,722 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 13 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,723 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 12, totalSize: 14 bytes
2017-02-22 10:34:24,723 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:34:24,723 DEBUG [CatalogJanitor-192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 14 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,724 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 15 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,724 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 12 bytes.
2017-02-22 10:34:24,724 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 14, totalSize: 8 bytes
2017-02-22 10:34:24,725 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 12 bytes.
2017-02-22 10:34:24,725 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 15, totalSize: 8 bytes
2017-02-22 10:34:24,725 INFO  [M:0;192.168.1.25:51895] master.TableNamespaceManager(85): Namespace table not found. Creating...
2017-02-22 10:34:24,756 DEBUG [M:0;192.168.1.25:51895] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:518950000000000
2017-02-22 10:34:24,757 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 16 method_name: "Scan" request_param: true
2017-02-22 10:34:24,759 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 16 bytes.
2017-02-22 10:34:24,759 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 16, totalSize: 12 bytes
2017-02-22 10:34:24,759 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 17 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,760 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 18 bytes.
2017-02-22 10:34:24,760 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 17, totalSize: 14 bytes
2017-02-22 10:34:24,761 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 12 bytes.
2017-02-22 10:34:24,761 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 18 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:24,761 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 18, totalSize: 8 bytes
2017-02-22 10:34:24,763 WARN  [M:0;192.168.1.25:51895] zookeeper.ZKTable(133): Moving table hbase:namespace state to enabling but was not first in disabled state: null
2017-02-22 10:34:24,769 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.CreateTableHandler(165): Create table hbase:namespace
2017-02-22 10:34:24,802 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster1/root/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2017-02-22 10:34:24,805 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(4729): creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster1/root/.tmp Table name == hbase:namespace
2017-02-22 10:34:24,829 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:34:24,829 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.: disabling compactions & flushes
2017-02-22 10:34:24,829 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:34:24,829 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:34:24,873 DEBUG [htable-pool9-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 19 method_name: "Multi" request_param: true cell_block_meta { length: 141 } priority: 100
2017-02-22 10:34:24,911 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 18 bytes.
2017-02-22 10:34:24,911 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 19, totalSize: 14 bytes
2017-02-22 10:34:24,913 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:34:24,914 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,916 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] zookeeper.ZKAssign(175): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Async create of unassigned node 80d0e76c1cadc7268bac2fe88eb7755b with OFFLINE state
2017-02-22 10:34:24,920 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:34:24,922 DEBUG [main-EventThread] master.OfflineCallback(69): rs={80d0e76c1cadc7268bac2fe88eb7755b state=OFFLINE, ts=1487756064913, server=null}, server=192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,923 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={80d0e76c1cadc7268bac2fe88eb7755b state=OFFLINE, ts=1487756064913, server=null}, server=192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,927 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.AssignmentManager(1673): 192.168.1.25,51897,1487756057911 unassigned znodes=1 of total=1
2017-02-22 10:34:24,928 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.RegionStates(894): Transition {80d0e76c1cadc7268bac2fe88eb7755b state=OFFLINE, ts=1487756064916, server=null} to {80d0e76c1cadc7268bac2fe88eb7755b state=PENDING_OPEN, ts=1487756064928, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,929 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 20 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:34:24,929 INFO  [PriorityRpcServer.handler=0,queue=0,port=51897] regionserver.HRegionServer(4011): Open hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:34:24,933 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 10 bytes.
2017-02-22 10:34:24,933 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(832): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioning 80d0e76c1cadc7268bac2fe88eb7755b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:24,933 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 20, totalSize: 6 bytes
2017-02-22 10:34:24,933 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,936 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/80d0e76c1cadc7268bac2fe88eb7755b
2017-02-22 10:34:24,936 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(907): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioned node 80d0e76c1cadc7268bac2fe88eb7755b from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:24,937 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] regionserver.HRegion(4915): Opening region: {ENCODED => 80d0e76c1cadc7268bac2fe88eb7755b, NAME => 'hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:24,938 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:34:24,938 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51897,1487756057911, region=80d0e76c1cadc7268bac2fe88eb7755b, current_state={80d0e76c1cadc7268bac2fe88eb7755b state=PENDING_OPEN, ts=1487756064928, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,938 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates(894): Transition {80d0e76c1cadc7268bac2fe88eb7755b state=PENDING_OPEN, ts=1487756064928, server=192.168.1.25,51897,1487756057911} to {80d0e76c1cadc7268bac2fe88eb7755b state=OPENING, ts=1487756064938, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,938 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table namespace 80d0e76c1cadc7268bac2fe88eb7755b
2017-02-22 10:34:24,939 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:34:24,940 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/hbase:namespace/write-master:518950000000000
2017-02-22 10:34:24,941 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:34:24,942 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:34:24,950 INFO  [StoreOpener-80d0e76c1cadc7268bac2fe88eb7755b-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:24,951 INFO  [StoreOpener-80d0e76c1cadc7268bac2fe88eb7755b-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:24,952 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/80d0e76c1cadc7268bac2fe88eb7755b
2017-02-22 10:34:24,953 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] regionserver.HRegion(826): Onlined 80d0e76c1cadc7268bac2fe88eb7755b; next sequenceid=1
2017-02-22 10:34:24,953 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(644): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Attempting to retransition opening state of node 80d0e76c1cadc7268bac2fe88eb7755b
2017-02-22 10:34:24,954 INFO  [PostOpenDeployTasks:80d0e76c1cadc7268bac2fe88eb7755b] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:34:24,956 DEBUG [htable-pool10-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 21 method_name: "Multi" request_param: true cell_block_meta { length: 347 } priority: 100
2017-02-22 10:34:24,958 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 18 bytes.
2017-02-22 10:34:24,958 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 21, totalSize: 14 bytes
2017-02-22 10:34:24,958 INFO  [PostOpenDeployTasks:80d0e76c1cadc7268bac2fe88eb7755b] catalog.MetaEditor(523): Updated row hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b. with server=192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,958 INFO  [PostOpenDeployTasks:80d0e76c1cadc7268bac2fe88eb7755b] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:34:24,959 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(832): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioning 80d0e76c1cadc7268bac2fe88eb7755b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:24,961 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/80d0e76c1cadc7268bac2fe88eb7755b
2017-02-22 10:34:24,961 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(907): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioned node 80d0e76c1cadc7268bac2fe88eb7755b from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:24,961 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] handler.OpenRegionHandler(403): Transitioned 80d0e76c1cadc7268bac2fe88eb7755b to OPENED in zk on 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,962 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51897-0] handler.OpenRegionHandler(189): Opened hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b. on 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,963 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51897,1487756057911, region=80d0e76c1cadc7268bac2fe88eb7755b, current_state={80d0e76c1cadc7268bac2fe88eb7755b state=OPENING, ts=1487756064938, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,963 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates(894): Transition {80d0e76c1cadc7268bac2fe88eb7755b state=OPENING, ts=1487756064938, server=192.168.1.25,51897,1487756057911} to {80d0e76c1cadc7268bac2fe88eb7755b state=OPEN, ts=1487756064963, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,963 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler(149): Handling OPENED of 80d0e76c1cadc7268bac2fe88eb7755b from 192.168.1.25,51897,1487756057911; deleting unassigned node
2017-02-22 10:34:24,967 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/80d0e76c1cadc7268bac2fe88eb7755b
2017-02-22 10:34:24,967 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign(480): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Deleted unassigned node 80d0e76c1cadc7268bac2fe88eb7755b in expected state RS_ZK_REGION_OPENED
2017-02-22 10:34:24,968 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:34:24,970 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager$4(1316): Znode hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b. deleted, state: {80d0e76c1cadc7268bac2fe88eb7755b state=OPEN, ts=1487756064963, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:34:24,970 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates(397): Onlined 80d0e76c1cadc7268bac2fe88eb7755b on 192.168.1.25,51897,1487756057911
2017-02-22 10:34:24,983 DEBUG [M:0;192.168.1.25:51895] zookeeper.ZKUtil(368): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/namespace
2017-02-22 10:34:24,984 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:24,990 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 22 method_name: "Get" request_param: true
2017-02-22 10:34:25,000 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 481 bytes.
2017-02-22 10:34:25,000 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 22, totalSize: 477 bytes
2017-02-22 10:34:25,003 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 23 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:25,004 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 509 bytes.
2017-02-22 10:34:25,005 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 23 cell_block_meta { length: 488 }, totalSize: 505 bytes
2017-02-22 10:34:25,005 DEBUG [M:0;192.168.1.25:51895] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:25,007 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 24 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:25,008 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 12 bytes.
2017-02-22 10:34:25,008 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 24, totalSize: 8 bytes
2017-02-22 10:34:25,008 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:25,010 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 12 bytes.
2017-02-22 10:34:25,010 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 25, totalSize: 8 bytes
2017-02-22 10:34:25,013 DEBUG [htable-pool11-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 26 method_name: "Multi" request_param: true cell_block_meta { length: 45 } priority: 100
2017-02-22 10:34:25,015 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 18 bytes.
2017-02-22 10:34:25,015 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 26, totalSize: 14 bytes
2017-02-22 10:34:25,016 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:25,019 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 27 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:25,019 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:34:25,019 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 12 bytes.
2017-02-22 10:34:25,019 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 27, totalSize: 8 bytes
2017-02-22 10:34:25,020 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:25,021 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 12 bytes.
2017-02-22 10:34:25,021 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 28, totalSize: 8 bytes
2017-02-22 10:34:25,022 DEBUG [htable-pool11-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 29 method_name: "Multi" request_param: true cell_block_meta { length: 41 } priority: 100
2017-02-22 10:34:25,024 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 18 bytes.
2017-02-22 10:34:25,024 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 29, totalSize: 14 bytes
2017-02-22 10:34:25,025 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:25,027 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 30 method_name: "Scan" request_param: true
2017-02-22 10:34:25,028 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:34:25,028 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-02-22 10:34:25,028 DEBUG [B.DefaultRpcServer.handler=2,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 16 bytes.
2017-02-22 10:34:25,028 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 30, totalSize: 12 bytes
2017-02-22 10:34:25,029 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 31 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:25,030 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 112 bytes.
2017-02-22 10:34:25,031 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 31 cell_block_meta { length: 86 }, totalSize: 108 bytes
2017-02-22 10:34:25,031 DEBUG [M:0;192.168.1.25:51895] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 32 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:25,031 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 12 bytes.
2017-02-22 10:34:25,032 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 32, totalSize: 8 bytes
2017-02-22 10:34:25,033 INFO  [M:0;192.168.1.25:51895] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:34:25,034 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:34:25,035 INFO  [M:0;192.168.1.25:51895] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:34:25,036 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:34:25,037 INFO  [M:0;192.168.1.25:51895] master.HMaster(1043): Master has completed initialization
2017-02-22 10:34:25,037 INFO  [M:0;192.168.1.25:51895] zookeeper.ZooKeeperWatcher(236): not a secure deployment, proceeding
2017-02-22 10:34:25,201 INFO  [main] zookeeper.MiniZooKeeperCluster(200): Started MiniZK Cluster and connect 1 ZK server on client port: 26262
2017-02-22 10:34:25,202 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:34:25,213 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:25,213 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x774698ab-0x15a652bf9a60000 connected
2017-02-22 10:34:25,214 INFO  [main] client.ZooKeeperRegistry(85): ClusterId read in ZooKeeper is null
2017-02-22 10:34:25,214 DEBUG [main] client.HConnectionManager$HConnectionImplementation(932): clusterid came back null, using default default-cluster
2017-02-22 10:34:25,214 DEBUG [main] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@a4ca3f6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:25,216 DEBUG [main] client.HConnectionManager(2976): master//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:34:25,219 INFO  [main] ipc.RpcServer$Listener(649): master//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:34:25,221 INFO  [main] master.HMaster(547): hbase.rootdir=file:/var/tmp/test-data/cluster2/root, hbase.cluster.distributed=false
2017-02-22 10:34:25,221 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=master:51909 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:34:25,228 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:519090x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:25,228 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): master:51909-0x15a652bf9a60001 connected
2017-02-22 10:34:25,254 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:34:25,255 INFO  [RpcServer.listener,port=51909] ipc.RpcServer$Listener(783): RpcServer.listener,port=51909: starting
2017-02-22 10:34:25,274 DEBUG [main] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:34:25,274 DEBUG [main] client.HConnectionManager(2976): regionserver//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:34:25,274 INFO  [main] ipc.SimpleRpcScheduler(86): Using default user call queue, count=3
2017-02-22 10:34:25,280 INFO  [main] ipc.RpcServer$Listener(649): regionserver//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:34:25,281 INFO  [main] hfile.CacheConfig(215): Created cacheConfig: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:25,289 INFO  [main] http.HttpServer(525): Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-02-22 10:34:25,291 INFO  [main] http.HttpServer(503): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2017-02-22 10:34:25,292 INFO  [main] http.HttpServer(510): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-02-22 10:34:25,293 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 3 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:25,297 DEBUG [FifoRpcScheduler.handler1-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 8 bytes.
2017-02-22 10:34:25,298 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 3, totalSize: 4 bytes
2017-02-22 10:34:25,308 INFO  [main] http.HttpServer(687): Jetty bound to port 51912
2017-02-22 10:34:25,681 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKUtil(368): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:34:25,683 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKUtil(368): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:34:25,685 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2017-02-22 10:34:25,687 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKUtil(366): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:25,688 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:25,688 DEBUG [main-EventThread] master.ActiveMasterManager(119): A master is now available
2017-02-22 10:34:25,688 WARN  [M:0;192.168.1.25:51909] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:34:25,689 INFO  [M:0;192.168.1.25:51909] master.ActiveMasterManager(170): Registered Active Master=192.168.1.25,51909,1487756065220
2017-02-22 10:34:25,690 INFO  [M:0;192.168.1.25:51909] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:25,706 INFO  [M:0;192.168.1.25:51909] util.FSUtils(696): Created version file at file:/var/tmp/test-data/cluster2/root with version=8
2017-02-22 10:34:25,720 DEBUG [M:0;192.168.1.25:51909] util.FSUtils(848): Created cluster ID file at file:/var/tmp/test-data/cluster2/root/hbase.id with ID: dc3bdf0a-580f-4360-94b0-0922decdfc3b
2017-02-22 10:34:25,720 INFO  [M:0;192.168.1.25:51909] master.MasterFileSystem(550): BOOTSTRAP: creating hbase:meta region
2017-02-22 10:34:25,721 INFO  [M:0;192.168.1.25:51909] regionserver.HRegion(4729): creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster2/root Table name == hbase:meta
2017-02-22 10:34:25,737 INFO  [M:0;192.168.1.25:51909] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:25,753 INFO  [M:0;192.168.1.25:51909] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/WALs/hlog.1487756065738
2017-02-22 10:34:25,753 INFO  [M:0;192.168.1.25:51909] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:25,753 INFO  [M:0;192.168.1.25:51909] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:25,754 DEBUG [M:0;192.168.1.25:51909] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:34:25,757 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:25,757 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:25,758 DEBUG [M:0;192.168.1.25:51909] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740
2017-02-22 10:34:25,759 INFO  [M:0;192.168.1.25:51909] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:34:25,759 DEBUG [M:0;192.168.1.25:51909] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:34:25,759 DEBUG [M:0;192.168.1.25:51909] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:34:25,760 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:34:25,760 INFO  [M:0;192.168.1.25:51909] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:34:25,760 DEBUG [M:0;192.168.1.25:51909-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): M:0;192.168.1.25:51909-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:34:25,760 INFO  [M:0;192.168.1.25:51909-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): M:0;192.168.1.25:51909-WAL.AsyncNotifier exiting
2017-02-22 10:34:25,760 DEBUG [M:0;192.168.1.25:51909-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51909-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:25,760 INFO  [M:0;192.168.1.25:51909-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51909-WAL.AsyncSyncer0 exiting
2017-02-22 10:34:25,760 DEBUG [M:0;192.168.1.25:51909-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51909-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:25,760 INFO  [M:0;192.168.1.25:51909-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51909-WAL.AsyncSyncer1 exiting
2017-02-22 10:34:25,761 DEBUG [M:0;192.168.1.25:51909-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51909-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:25,761 INFO  [M:0;192.168.1.25:51909-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51909-WAL.AsyncSyncer2 exiting
2017-02-22 10:34:25,761 DEBUG [M:0;192.168.1.25:51909-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51909-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:25,761 INFO  [M:0;192.168.1.25:51909-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51909-WAL.AsyncSyncer3 exiting
2017-02-22 10:34:25,761 DEBUG [M:0;192.168.1.25:51909-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51909-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:25,761 INFO  [M:0;192.168.1.25:51909-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51909-WAL.AsyncSyncer4 exiting
2017-02-22 10:34:25,761 DEBUG [M:0;192.168.1.25:51909-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): M:0;192.168.1.25:51909-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:34:25,761 INFO  [M:0;192.168.1.25:51909-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): M:0;192.168.1.25:51909-WAL.AsyncWriter exiting
2017-02-22 10:34:25,761 DEBUG [M:0;192.168.1.25:51909] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/WALs
2017-02-22 10:34:25,762 DEBUG [M:0;192.168.1.25:51909] wal.FSHLog(892): Moved 1 WAL file(s) to /var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/oldWALs
2017-02-22 10:34:25,775 DEBUG [M:0;192.168.1.25:51909] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster2/root/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-02-22 10:34:25,777 DEBUG [M:0;192.168.1.25:51909] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:34:25,777 DEBUG [M:0;192.168.1.25:51909] master.SplitLogManager(1360): Distributed log replay=false, hfile.format.version=2
2017-02-22 10:34:25,780 INFO  [M:0;192.168.1.25:51909] master.SplitLogManager(224): Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-02-22 10:34:25,781 INFO  [M:0;192.168.1.25:51909] master.SplitLogManager(1100): Found 0 orphan tasks and 0 rescan nodes
2017-02-22 10:34:25,781 DEBUG [M:0;192.168.1.25:51909] util.FSTableDescriptors(208): Fetching table descriptors from the filesystem.
2017-02-22 10:34:25,785 INFO  [M:0;192.168.1.25:51909] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x3bca7cee connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:34:25,785 INFO  [main] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RS:0;192.168.1.25:51911
2017-02-22 10:34:25,786 DEBUG [RS:0;192.168.1.25:51911] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:339)
2017-02-22 10:34:25,788 INFO  [RS:0;192.168.1.25:51911] zookeeper.RecoverableZooKeeper(120): Process identifier=regionserver:51911 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:34:25,793 DEBUG [M:0;192.168.1.25:51909-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x3bca7cee0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:25,793 DEBUG [M:0;192.168.1.25:51909-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x3bca7cee-0x15a652bf9a60002 connected
2017-02-22 10:34:25,795 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:519110x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:25,796 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(591): regionserver:51911-0x15a652bf9a60003 connected
2017-02-22 10:34:25,796 DEBUG [RS:0;192.168.1.25:51911] zookeeper.ZKUtil(366): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:25,797 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@a3b6246, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:25,798 DEBUG [RS:0;192.168.1.25:51911] zookeeper.ZKUtil(368): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:34:25,798 DEBUG [M:0;192.168.1.25:51909] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3320b427
2017-02-22 10:34:25,799 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKUtil(368): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:34:25,801 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKUtil(368): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/balancer
2017-02-22 10:34:25,805 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:34:25,805 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:34:25,807 DEBUG [RS:0;192.168.1.25:51911] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3f2ab743
2017-02-22 10:34:25,807 INFO  [M:0;192.168.1.25:51909] master.HMaster(801): Server active/primary master=192.168.1.25,51909,1487756065220, sessionid=0x15a652bf9a60001, setting cluster-up flag (Was=false)
2017-02-22 10:34:25,808 DEBUG [RS:0;192.168.1.25:51911] zookeeper.ZKUtil(368): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:34:25,810 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(805): ClusterId : dc3bdf0a-580f-4360-94b0-0922decdfc3b
2017-02-22 10:34:25,810 INFO  [RS:0;192.168.1.25:51911] procedure.RegionServerProcedureManagerHost(43): Procedure online-snapshot is initializing
2017-02-22 10:34:25,811 INFO  [RS:0;192.168.1.25:51911] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:34:25,814 INFO  [M:0;192.168.1.25:51909] procedure.ZKProcedureUtil(270): Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-02-22 10:34:25,814 INFO  [RS:0;192.168.1.25:51911] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/abort already exists and this is not a retry
2017-02-22 10:34:25,815 INFO  [RS:0;192.168.1.25:51911] procedure.RegionServerProcedureManagerHost(45): Procedure online-snapshot is initialized
2017-02-22 10:34:25,815 INFO  [RS:0;192.168.1.25:51911] regionserver.MemStoreFlusher(119): globalMemStoreLimit=1.4 G, globalMemStoreLimitLowMark=1.4 G, maxHeap=3.6 G
2017-02-22 10:34:25,815 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer$CompactionChecker(1508): CompactionChecker runs every 10sec
2017-02-22 10:34:25,816 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3b15347e, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=192.168.1.25/192.168.1.25:0
2017-02-22 10:34:25,816 DEBUG [M:0;192.168.1.25:51909] procedure.ZKProcedureCoordinatorRpcs(195): Starting the controller for procedure member:192.168.1.25,51909,1487756065220
2017-02-22 10:34:25,816 INFO  [M:0;192.168.1.25:51909] master.MasterCoprocessorHost(85): System coprocessor loading is enabled
2017-02-22 10:34:25,817 DEBUG [M:0;192.168.1.25:51909] executor.ExecutorService(100): Starting executor service name=MASTER_OPEN_REGION-192.168.1.25:51909, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:25,817 DEBUG [M:0;192.168.1.25:51909] executor.ExecutorService(100): Starting executor service name=MASTER_CLOSE_REGION-192.168.1.25:51909, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:25,817 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,51909,1487756065220 with port=51911, startcode=1487756065280
2017-02-22 10:34:25,817 DEBUG [M:0;192.168.1.25:51909] executor.ExecutorService(100): Starting executor service name=MASTER_SERVER_OPERATIONS-192.168.1.25:51909, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:25,817 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service RegionServerStatusService, sasl=false
2017-02-22 10:34:25,817 DEBUG [M:0;192.168.1.25:51909] executor.ExecutorService(100): Starting executor service name=MASTER_META_SERVER_OPERATIONS-192.168.1.25:51909, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:25,817 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51909
2017-02-22 10:34:25,817 DEBUG [M:0;192.168.1.25:51909] executor.ExecutorService(100): Starting executor service name=M_LOG_REPLAY_OPS-192.168.1.25:51909, corePoolSize=10, maxPoolSize=10
2017-02-22 10:34:25,818 DEBUG [M:0;192.168.1.25:51909] executor.ExecutorService(100): Starting executor service name=MASTER_TABLE_OPERATIONS-192.168.1.25:51909, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:25,818 DEBUG [M:0;192.168.1.25:51909] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-02-22 10:34:25,819 DEBUG [RpcServer.listener,port=51909] ipc.RpcServer$Listener(885): RpcServer.listener,port=51909: connection from 192.168.1.25:51915; # active connections: 1
2017-02-22 10:34:25,821 INFO  [M:0;192.168.1.25:51909] zookeeper.RecoverableZooKeeper(120): Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:34:25,821 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 0 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:34:25,822 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: starting, connections 1
2017-02-22 10:34:25,822 DEBUG [RpcServer.reader=1,port=51909] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "RegionServerStatusService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:25,824 DEBUG [FifoRpcScheduler.handler4-thread-1] ipc.CallRunner(107): FifoRpcScheduler.handler4-thread-1: callId: 0 service: RegionServerStatusService methodName: RegionServerStartup size: 47 connection: 192.168.1.25:51915
org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.25/192.168.1.25:51909 is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:97)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-02-22 10:34:25,826 DEBUG [FifoRpcScheduler.handler4-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 685 bytes.
2017-02-22 10:34:25,827 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 0 exception { exception_class_name: "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException" stack_trace: "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.25/192.168.1.25:51909 is not running yet\n\tat org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:97)\n\tat org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n" do_not_retry: false }, totalSize: 681 bytes
2017-02-22 10:34:25,827 DEBUG [M:0;192.168.1.25:51909-EventThread] zookeeper.ZooKeeperWatcher(528): replicationLogCleaner0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:25,828 DEBUG [M:0;192.168.1.25:51909-EventThread] zookeeper.ZooKeeperWatcher(591): replicationLogCleaner-0x15a652bf9a60004 connected
2017-02-22 10:34:25,831 DEBUG [RS:0;192.168.1.25:51911] regionserver.HRegionServer(2214): Master is not running yet
2017-02-22 10:34:25,831 WARN  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(900): reportForDuty failed; sleeping and then retrying.
2017-02-22 10:34:25,835 DEBUG [M:0;192.168.1.25:51909] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-02-22 10:34:25,835 DEBUG [M:0;192.168.1.25:51909] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-02-22 10:34:25,835 DEBUG [M:0;192.168.1.25:51909] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-02-22 10:34:25,836 DEBUG [M:0;192.168.1.25:51909] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-02-22 10:34:25,836 DEBUG [M:0;192.168.1.25:51909] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-02-22 10:34:25,836 INFO  [M:0;192.168.1.25:51909] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:27,386 INFO  [M:0;192.168.1.25:51909] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 1550 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:28,304 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 4 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:28,306 DEBUG [FifoRpcScheduler.handler1-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 8 bytes.
2017-02-22 10:34:28,306 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 4, totalSize: 4 bytes
2017-02-22 10:34:28,836 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,51909,1487756065220 with port=51911, startcode=1487756065280
2017-02-22 10:34:28,836 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 1 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:34:28,843 INFO  [FifoRpcScheduler.handler4-thread-2] master.ServerManager(423): Registering server=192.168.1.25,51911,1487756065280
2017-02-22 10:34:28,845 DEBUG [FifoRpcScheduler.handler4-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 184 bytes.
2017-02-22 10:34:28,845 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 1, totalSize: 180 bytes
2017-02-22 10:34:28,845 DEBUG [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1323): Config from master: hbase.rootdir=file:///var/tmp/test-data/cluster2/root
2017-02-22 10:34:28,845 DEBUG [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1323): Config from master: fs.default.name=file:/
2017-02-22 10:34:28,845 DEBUG [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1323): Config from master: hbase.master.info.port=-1
2017-02-22 10:34:28,848 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:34:28,849 DEBUG [RS:0;192.168.1.25:51911] zookeeper.ZKUtil(366): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51911,1487756065280
2017-02-22 10:34:28,850 INFO  [RS:0;192.168.1.25:51911] regionserver.RegionServerCoprocessorHost(66): System coprocessor loading is enabled
2017-02-22 10:34:28,850 INFO  [RS:0;192.168.1.25:51911] regionserver.RegionServerCoprocessorHost(67): Table coprocessor loading is enabled
2017-02-22 10:34:28,850 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51911,1487756065280
2017-02-22 10:34:28,850 WARN  [RS:0;192.168.1.25:51911] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:34:28,851 DEBUG [RS:0;192.168.1.25:51911] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:34:28,852 DEBUG [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1605): logdir=file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,51911,1487756065280
2017-02-22 10:34:28,852 DEBUG [main-EventThread] zookeeper.RegionServerTracker(95): Added tracking of RS /hbase/rs/192.168.1.25,51911,1487756065280
2017-02-22 10:34:28,860 DEBUG [RS:0;192.168.1.25:51911] regionserver.Replication(141): ReplicationStatisticsThread 300
2017-02-22 10:34:28,861 INFO  [RS:0;192.168.1.25:51911] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:28,872 INFO  [M:0;192.168.1.25:51909] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 3036 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:28,877 INFO  [RS:0;192.168.1.25:51911] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster2/root/WALs/192.168.1.25,51911,1487756065280/192.168.1.25%2C51911%2C1487756065280.1487756068861
2017-02-22 10:34:28,877 INFO  [RS:0;192.168.1.25:51911] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:28,877 INFO  [RS:0;192.168.1.25:51911] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:28,878 INFO  [RS:0;192.168.1.25:51911] regionserver.MetricsRegionServerWrapperImpl(101): Computing regionserver metrics every 5000 milliseconds
2017-02-22 10:34:28,878 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsSystemImpl(220): RegionServer,sub=Server-1, Metrics about HBase RegionServer
2017-02-22 10:34:28,878 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:28,878 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Server-1
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Server-1 registered.
2017-02-22 10:34:28,879 DEBUG [RS:0;192.168.1.25:51911] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Server-1
2017-02-22 10:34:28,880 DEBUG [RS:0;192.168.1.25:51911] executor.ExecutorService(100): Starting executor service name=RS_OPEN_REGION-192.168.1.25:51911, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:28,880 DEBUG [RS:0;192.168.1.25:51911] executor.ExecutorService(100): Starting executor service name=RS_OPEN_META-192.168.1.25:51911, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:28,880 DEBUG [RS:0;192.168.1.25:51911] executor.ExecutorService(100): Starting executor service name=RS_OPEN_PRIORITY_REGION-192.168.1.25:51911, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:28,880 DEBUG [RS:0;192.168.1.25:51911] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_REGION-192.168.1.25:51911, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:28,880 DEBUG [RS:0;192.168.1.25:51911] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_META-192.168.1.25:51911, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:28,880 DEBUG [RS:0;192.168.1.25:51911] executor.ExecutorService(100): Starting executor service name=RS_LOG_REPLAY_OPS-192.168.1.25:51911, corePoolSize=2, maxPoolSize=2
2017-02-22 10:34:28,884 DEBUG [RS:0;192.168.1.25:51911] zookeeper.ZKUtil(366): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51911,1487756065280
2017-02-22 10:34:28,884 INFO  [RS:0;192.168.1.25:51911] regionserver.ReplicationSourceManager(226): Current list of replicators: [192.168.1.25,51911,1487756065280] other RSs: [192.168.1.25,51911,1487756065280]
2017-02-22 10:34:28,900 INFO  [RS:0;192.168.1.25:51911] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:34:28,900 INFO  [RS:0;192.168.1.25:51911] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:34:28,901 INFO  [RS:0;192.168.1.25:51911] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:28,903 INFO  [RS:0;192.168.1.25:51911] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x69112497 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:34:28,909 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x691124970x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:28,910 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x69112497-0x15a652bf9a60005 connected
2017-02-22 10:34:28,913 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3c15707e, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:28,914 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:34:28,915 INFO  [RpcServer.listener,port=51911] ipc.RpcServer$Listener(783): RpcServer.listener,port=51911: starting
2017-02-22 10:34:28,915 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=0 queue=0
2017-02-22 10:34:28,916 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=1 queue=1
2017-02-22 10:34:28,916 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=2 queue=2
2017-02-22 10:34:28,917 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=3 queue=0
2017-02-22 10:34:28,917 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=4 queue=1
2017-02-22 10:34:28,918 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=5 queue=2
2017-02-22 10:34:28,918 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=6 queue=0
2017-02-22 10:34:28,919 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=7 queue=1
2017-02-22 10:34:28,919 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=8 queue=2
2017-02-22 10:34:28,919 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=9 queue=0
2017-02-22 10:34:28,919 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=10 queue=1
2017-02-22 10:34:28,920 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=11 queue=2
2017-02-22 10:34:28,920 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=12 queue=0
2017-02-22 10:34:28,920 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=13 queue=1
2017-02-22 10:34:28,920 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=14 queue=2
2017-02-22 10:34:28,921 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=15 queue=0
2017-02-22 10:34:28,921 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=16 queue=1
2017-02-22 10:34:28,921 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=17 queue=2
2017-02-22 10:34:28,921 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=18 queue=0
2017-02-22 10:34:28,922 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=19 queue=1
2017-02-22 10:34:28,922 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=20 queue=2
2017-02-22 10:34:28,922 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=21 queue=0
2017-02-22 10:34:28,922 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=22 queue=1
2017-02-22 10:34:28,922 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=23 queue=2
2017-02-22 10:34:28,923 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=24 queue=0
2017-02-22 10:34:28,923 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=25 queue=1
2017-02-22 10:34:28,923 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=26 queue=2
2017-02-22 10:34:28,923 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=27 queue=0
2017-02-22 10:34:28,923 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=28 queue=1
2017-02-22 10:34:28,923 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): B.Default Start Handler index=29 queue=2
2017-02-22 10:34:28,924 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=0 queue=0
2017-02-22 10:34:28,924 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=1 queue=0
2017-02-22 10:34:28,924 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=2 queue=0
2017-02-22 10:34:28,924 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=3 queue=0
2017-02-22 10:34:28,924 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=4 queue=0
2017-02-22 10:34:28,925 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=5 queue=0
2017-02-22 10:34:28,925 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=6 queue=0
2017-02-22 10:34:28,925 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=7 queue=0
2017-02-22 10:34:28,925 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=8 queue=0
2017-02-22 10:34:28,926 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Priority Start Handler index=9 queue=0
2017-02-22 10:34:28,926 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Replication Start Handler index=0 queue=0
2017-02-22 10:34:28,926 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Replication Start Handler index=1 queue=0
2017-02-22 10:34:28,926 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcExecutor(115): Replication Start Handler index=2 queue=0
2017-02-22 10:34:28,942 INFO  [RS:0;192.168.1.25:51911] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:34:28,942 INFO  [RS:0;192.168.1.25:51911] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:34:28,942 INFO  [RS:0;192.168.1.25:51911] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:28,943 INFO  [SplitLogWorker-192.168.1.25,51911,1487756065280] regionserver.SplitLogWorker(176): SplitLogWorker 192.168.1.25,51911,1487756065280 starting
2017-02-22 10:34:28,943 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1367): Serving as 192.168.1.25,51911,1487756065280, RpcServer on 192.168.1.25/192.168.1.25:51911, sessionid=0x15a652bf9a60003
2017-02-22 10:34:28,943 INFO  [RS:0;192.168.1.25:51911] procedure.RegionServerProcedureManagerHost(51): Procedure online-snapshot is starting
2017-02-22 10:34:28,944 DEBUG [RS:0;192.168.1.25:51911] snapshot.RegionServerSnapshotManager(124): Start Snapshot Manager 192.168.1.25,51911,1487756065280
2017-02-22 10:34:28,944 DEBUG [RS:0;192.168.1.25:51911] procedure.ZKProcedureMemberRpcs(340): Starting procedure member '192.168.1.25,51911,1487756065280'
2017-02-22 10:34:28,944 DEBUG [RS:0;192.168.1.25:51911] procedure.ZKProcedureMemberRpcs(136): Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2017-02-22 10:34:28,945 INFO  [SplitLogWorker-192.168.1.25,51911,1487756065280] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x56d7edd4 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:34:28,946 DEBUG [RS:0;192.168.1.25:51911] procedure.ZKProcedureMemberRpcs(152): Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2017-02-22 10:34:28,948 INFO  [RS:0;192.168.1.25:51911] procedure.RegionServerProcedureManagerHost(53): Procedure online-snapshot is started
2017-02-22 10:34:28,949 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 2 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:28,952 DEBUG [FifoRpcScheduler.handler4-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 8 bytes.
2017-02-22 10:34:28,952 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 2, totalSize: 4 bytes
2017-02-22 10:34:28,953 DEBUG [SplitLogWorker-192.168.1.25,51911,1487756065280-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x56d7edd40x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:28,954 DEBUG [SplitLogWorker-192.168.1.25,51911,1487756065280-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x56d7edd4-0x15a652bf9a60006 connected
2017-02-22 10:34:28,957 DEBUG [SplitLogWorker-192.168.1.25,51911,1487756065280] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5c2f86a4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:30,421 INFO  [M:0;192.168.1.25:51909] master.ServerManager(918): Finished waiting for region servers count to settle; checked in 1, slept for 4585 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-02-22 10:34:30,422 INFO  [M:0;192.168.1.25:51909] master.MasterFileSystem(260): Log folder file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,51911,1487756065280 belongs to an existing region server
2017-02-22 10:34:31,254 INFO  [M:0;192.168.1.25:51909] zookeeper.MetaRegionTracker(184): Unsetting hbase:meta region location in ZooKeeper
2017-02-22 10:34:31,255 DEBUG [M:0;192.168.1.25:51909] zookeeper.RecoverableZooKeeper(188): Node /hbase/meta-region-server already deleted, retry=false
2017-02-22 10:34:31,255 DEBUG [M:0;192.168.1.25:51909] master.AssignmentManager(2461): No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=192.168.1.25,51911,1487756065280; 1 (online=1, available=1) available servers, forceNewPlan=false
2017-02-22 10:34:31,256 INFO  [M:0;192.168.1.25:51909] master.AssignmentManager(2089): Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:31,256 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKAssign(206): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-02-22 10:34:31,259 DEBUG [M:0;192.168.1.25:51909] master.AssignmentManager(2105): Setting table hbase:meta to ENABLED state.
2017-02-22 10:34:31,264 INFO  [M:0;192.168.1.25:51909] master.AssignmentManager(2120): Assigning hbase:meta,,1.1588230740 to 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,264 INFO  [M:0;192.168.1.25:51909] master.RegionStates(894): Transition {1588230740 state=OFFLINE, ts=1487756071256, server=null} to {1588230740 state=PENDING_OPEN, ts=1487756071264, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,264 DEBUG [M:0;192.168.1.25:51909] master.ServerManager(836): New admin connection to 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,264 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:34:31,264 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51911
2017-02-22 10:34:31,266 DEBUG [RpcServer.listener,port=51911] ipc.RpcServer$Listener(885): RpcServer.listener,port=51911: connection from 192.168.1.25:51919; # active connections: 1
2017-02-22 10:34:31,266 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: starting, connections 1
2017-02-22 10:34:31,267 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 0 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:34:31,269 DEBUG [RpcServer.reader=1,port=51911] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:31,270 INFO  [PriorityRpcServer.handler=0,queue=0,port=51911] regionserver.HRegionServer(4011): Open hbase:meta,,1.1588230740
2017-02-22 10:34:31,271 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] zookeeper.ZKAssign(832): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:31,272 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:34:31,272 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:34:31,272 INFO  [M:0;192.168.1.25:51909] master.ServerManager(618): AssignmentManager hasn't finished failover cleanup; waiting
2017-02-22 10:34:31,276 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:31,276 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] zookeeper.ZKAssign(907): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:31,276 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] regionserver.HRegionServer(1622): logdir=file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,276 INFO  [RS_OPEN_META-192.168.1.25:51911-0] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:31,277 DEBUG [AM.ZK.Worker-pool13-t1] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51911,1487756065280, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1487756071264, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,278 INFO  [AM.ZK.Worker-pool13-t1] master.RegionStates(894): Transition {1588230740 state=PENDING_OPEN, ts=1487756071264, server=192.168.1.25,51911,1487756065280} to {1588230740 state=OPENING, ts=1487756071278, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,297 INFO  [RS_OPEN_META-192.168.1.25:51911-0] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster2/root/WALs/192.168.1.25,51911,1487756065280/192.168.1.25%2C51911%2C1487756065280.1487756071277.meta
2017-02-22 10:34:31,297 INFO  [RS_OPEN_META-192.168.1.25:51911-0] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:31,297 INFO  [RS_OPEN_META-192.168.1.25:51911-0] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:31,299 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] regionserver.HRegion(4915): Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:31,301 INFO  [RS_OPEN_META-192.168.1.25:51911-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:34:31,301 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] coprocessor.CoprocessorHost(226): Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2017-02-22 10:34:31,302 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] regionserver.HRegion(6103): Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2017-02-22 10:34:31,302 INFO  [RS_OPEN_META-192.168.1.25:51911-0] regionserver.RegionCoprocessorHost(373): Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2017-02-22 10:34:31,303 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table meta 1588230740
2017-02-22 10:34:31,303 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:34:31,305 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:31,305 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:31,307 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740
2017-02-22 10:34:31,308 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 5 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:31,308 INFO  [RS_OPEN_META-192.168.1.25:51911-0] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:34:31,308 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] zookeeper.ZKAssign(644): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2017-02-22 10:34:31,311 DEBUG [FifoRpcScheduler.handler1-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 8 bytes.
2017-02-22 10:34:31,311 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 5, totalSize: 4 bytes
2017-02-22 10:34:31,311 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:meta,,1.1588230740
2017-02-22 10:34:31,311 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1911): Updating zk with meta location
2017-02-22 10:34:31,312 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaRegionTracker(142): Setting hbase:meta region location in ZooKeeper as 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,313 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:34:31,314 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:34:31,316 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:meta,,1.1588230740
2017-02-22 10:34:31,317 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] zookeeper.ZKAssign(832): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:31,322 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:31,323 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] zookeeper.ZKAssign(907): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:31,323 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] handler.OpenRegionHandler(403): Transitioned 1588230740 to OPENED in zk on 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,323 DEBUG [RS_OPEN_META-192.168.1.25:51911-0] handler.OpenRegionHandler(189): Opened hbase:meta,,1.1588230740 on 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,324 DEBUG [AM.ZK.Worker-pool13-t2] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51911,1487756065280, region=1588230740, current_state={1588230740 state=OPENING, ts=1487756071278, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,324 INFO  [AM.ZK.Worker-pool13-t2] master.RegionStates(894): Transition {1588230740 state=OPENING, ts=1487756071278, server=192.168.1.25,51911,1487756065280} to {1588230740 state=OPEN, ts=1487756071324, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,324 INFO  [AM.ZK.Worker-pool13-t2] handler.OpenedRegionHandler(147): Handling OPENED of 1588230740 from 192.168.1.25,51911,1487756065280; deleting unassigned node
2017-02-22 10:34:31,327 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:31,328 DEBUG [AM.ZK.Worker-pool13-t2] zookeeper.ZKAssign(480): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:34:31,329 DEBUG [AM.ZK.Worker-pool13-t3] master.AssignmentManager$4(1316): Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1487756071324, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,329 INFO  [AM.ZK.Worker-pool13-t3] master.RegionStates(397): Onlined 1588230740 on 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,331 INFO  [M:0;192.168.1.25:51909] master.HMaster(1162): hbase:meta assigned=1, rit=false, location=192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,333 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:34:31,334 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51911
2017-02-22 10:34:31,337 DEBUG [RpcServer.listener,port=51911] ipc.RpcServer$Listener(885): RpcServer.listener,port=51911: connection from 192.168.1.25:51920; # active connections: 2
2017-02-22 10:34:31,338 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: starting, connections 2
2017-02-22 10:34:31,339 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 1 method_name: "Scan" request_param: true
2017-02-22 10:34:31,341 DEBUG [RpcServer.reader=2,port=51911] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:31,344 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 16 bytes.
2017-02-22 10:34:31,344 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 1, totalSize: 12 bytes
2017-02-22 10:34:31,345 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,346 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 18 bytes.
2017-02-22 10:34:31,346 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 2, totalSize: 14 bytes
2017-02-22 10:34:31,347 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,348 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 12 bytes.
2017-02-22 10:34:31,348 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 3, totalSize: 8 bytes
2017-02-22 10:34:31,348 INFO  [M:0;192.168.1.25:51909] catalog.MetaMigrationConvertingToPB(166): hbase:meta doesn't have any entries to update.
2017-02-22 10:34:31,348 INFO  [M:0;192.168.1.25:51909] catalog.MetaMigrationConvertingToPB(132): META already up-to date with PB serialization
2017-02-22 10:34:31,353 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true
2017-02-22 10:34:31,355 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 16 bytes.
2017-02-22 10:34:31,355 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 4, totalSize: 12 bytes
2017-02-22 10:34:31,356 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,357 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 18 bytes.
2017-02-22 10:34:31,357 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 5, totalSize: 14 bytes
2017-02-22 10:34:31,357 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,358 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 12 bytes.
2017-02-22 10:34:31,358 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 6, totalSize: 8 bytes
2017-02-22 10:34:31,362 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKAssign(498): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Deleting any existing unassigned nodes
2017-02-22 10:34:31,363 INFO  [M:0;192.168.1.25:51909] master.AssignmentManager(646): Clean cluster startup. Assigning user regions
2017-02-22 10:34:31,363 INFO  [M:0;192.168.1.25:51909] master.SnapshotOfRegionAssignmentFromMeta(95): Start to scan the hbase:meta for the current region assignment snappshot
2017-02-22 10:34:31,364 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true
2017-02-22 10:34:31,365 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 16 bytes.
2017-02-22 10:34:31,366 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 7, totalSize: 12 bytes
2017-02-22 10:34:31,366 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,367 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 18 bytes.
2017-02-22 10:34:31,367 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 8, totalSize: 14 bytes
2017-02-22 10:34:31,368 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,369 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 12 bytes.
2017-02-22 10:34:31,369 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 9, totalSize: 8 bytes
2017-02-22 10:34:31,369 INFO  [M:0;192.168.1.25:51909] master.SnapshotOfRegionAssignmentFromMeta(138): Finished to scan the hbase:meta for the current region assignmentsnapshot
2017-02-22 10:34:31,372 INFO  [M:0;192.168.1.25:51909] master.AssignmentManager(511): Joined the cluster in 24ms, failover=false
2017-02-22 10:34:31,374 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true
2017-02-22 10:34:31,376 DEBUG [CatalogJanitor-192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 11 method_name: "Scan" request_param: true
2017-02-22 10:34:31,376 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 16 bytes.
2017-02-22 10:34:31,377 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 16 bytes.
2017-02-22 10:34:31,377 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 10, totalSize: 12 bytes
2017-02-22 10:34:31,377 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 11, totalSize: 12 bytes
2017-02-22 10:34:31,377 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,377 DEBUG [CatalogJanitor-192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 13 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,377 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 18 bytes.
2017-02-22 10:34:31,378 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 12, totalSize: 14 bytes
2017-02-22 10:34:31,378 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:34:31,378 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:34:31,378 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 14 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,378 DEBUG [CatalogJanitor-192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 15 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,379 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 12 bytes.
2017-02-22 10:34:31,379 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 15, totalSize: 8 bytes
2017-02-22 10:34:31,379 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 12 bytes.
2017-02-22 10:34:31,379 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 14, totalSize: 8 bytes
2017-02-22 10:34:31,379 INFO  [M:0;192.168.1.25:51909] master.TableNamespaceManager(85): Namespace table not found. Creating...
2017-02-22 10:34:31,388 DEBUG [M:0;192.168.1.25:51909] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:519090000000000
2017-02-22 10:34:31,388 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 16 method_name: "Scan" request_param: true
2017-02-22 10:34:31,389 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 16 bytes.
2017-02-22 10:34:31,389 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 16, totalSize: 12 bytes
2017-02-22 10:34:31,389 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 17 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,389 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 18 bytes.
2017-02-22 10:34:31,390 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 17, totalSize: 14 bytes
2017-02-22 10:34:31,390 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 18 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,390 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 12 bytes.
2017-02-22 10:34:31,390 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 18, totalSize: 8 bytes
2017-02-22 10:34:31,391 WARN  [M:0;192.168.1.25:51909] zookeeper.ZKTable(133): Moving table hbase:namespace state to enabling but was not first in disabled state: null
2017-02-22 10:34:31,395 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.CreateTableHandler(165): Create table hbase:namespace
2017-02-22 10:34:31,409 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster2/root/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2017-02-22 10:34:31,410 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(4729): creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster2/root/.tmp Table name == hbase:namespace
2017-02-22 10:34:31,424 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:34:31,424 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.: disabling compactions & flushes
2017-02-22 10:34:31,424 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:34:31,424 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:34:31,426 DEBUG [htable-pool20-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 19 method_name: "Multi" request_param: true cell_block_meta { length: 141 } priority: 100
2017-02-22 10:34:31,429 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 18 bytes.
2017-02-22 10:34:31,429 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 19, totalSize: 14 bytes
2017-02-22 10:34:31,430 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:34:31,432 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,432 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] zookeeper.ZKAssign(175): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Async create of unassigned node 27f513717656a2c439f2478fb0dfb75f with OFFLINE state
2017-02-22 10:34:31,433 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:34:31,433 DEBUG [main-EventThread] master.OfflineCallback(69): rs={27f513717656a2c439f2478fb0dfb75f state=OFFLINE, ts=1487756071432, server=null}, server=192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,435 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={27f513717656a2c439f2478fb0dfb75f state=OFFLINE, ts=1487756071432, server=null}, server=192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,438 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.AssignmentManager(1673): 192.168.1.25,51911,1487756065280 unassigned znodes=1 of total=1
2017-02-22 10:34:31,438 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.RegionStates(894): Transition {27f513717656a2c439f2478fb0dfb75f state=OFFLINE, ts=1487756071432, server=null} to {27f513717656a2c439f2478fb0dfb75f state=PENDING_OPEN, ts=1487756071438, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,439 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 20 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:34:31,440 INFO  [PriorityRpcServer.handler=0,queue=0,port=51911] regionserver.HRegionServer(4011): Open hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:34:31,442 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 10 bytes.
2017-02-22 10:34:31,442 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(832): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioning 27f513717656a2c439f2478fb0dfb75f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:31,442 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 20, totalSize: 6 bytes
2017-02-22 10:34:31,442 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,446 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/27f513717656a2c439f2478fb0dfb75f
2017-02-22 10:34:31,446 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(907): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioned node 27f513717656a2c439f2478fb0dfb75f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:31,447 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] regionserver.HRegion(4915): Opening region: {ENCODED => 27f513717656a2c439f2478fb0dfb75f, NAME => 'hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:31,448 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:34:31,448 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table namespace 27f513717656a2c439f2478fb0dfb75f
2017-02-22 10:34:31,449 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:34:31,464 DEBUG [AM.ZK.Worker-pool13-t5] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51911,1487756065280, region=27f513717656a2c439f2478fb0dfb75f, current_state={27f513717656a2c439f2478fb0dfb75f state=PENDING_OPEN, ts=1487756071438, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,465 INFO  [AM.ZK.Worker-pool13-t5] master.RegionStates(894): Transition {27f513717656a2c439f2478fb0dfb75f state=PENDING_OPEN, ts=1487756071438, server=192.168.1.25,51911,1487756065280} to {27f513717656a2c439f2478fb0dfb75f state=OPENING, ts=1487756071464, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,465 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/hbase:namespace/write-master:519090000000000
2017-02-22 10:34:31,465 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:34:31,465 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:34:31,475 INFO  [StoreOpener-27f513717656a2c439f2478fb0dfb75f-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:31,475 INFO  [StoreOpener-27f513717656a2c439f2478fb0dfb75f-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:31,476 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/27f513717656a2c439f2478fb0dfb75f
2017-02-22 10:34:31,476 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] regionserver.HRegion(826): Onlined 27f513717656a2c439f2478fb0dfb75f; next sequenceid=1
2017-02-22 10:34:31,476 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(644): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Attempting to retransition opening state of node 27f513717656a2c439f2478fb0dfb75f
2017-02-22 10:34:31,478 INFO  [PostOpenDeployTasks:27f513717656a2c439f2478fb0dfb75f] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:34:31,479 DEBUG [htable-pool21-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 21 method_name: "Multi" request_param: true cell_block_meta { length: 347 } priority: 100
2017-02-22 10:34:31,480 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 18 bytes.
2017-02-22 10:34:31,480 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 21, totalSize: 14 bytes
2017-02-22 10:34:31,481 INFO  [PostOpenDeployTasks:27f513717656a2c439f2478fb0dfb75f] catalog.MetaEditor(523): Updated row hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f. with server=192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,481 INFO  [PostOpenDeployTasks:27f513717656a2c439f2478fb0dfb75f] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:34:31,481 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(832): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioning 27f513717656a2c439f2478fb0dfb75f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:31,483 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/27f513717656a2c439f2478fb0dfb75f
2017-02-22 10:34:31,483 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(907): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioned node 27f513717656a2c439f2478fb0dfb75f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:31,484 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] handler.OpenRegionHandler(403): Transitioned 27f513717656a2c439f2478fb0dfb75f to OPENED in zk on 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,484 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51911-0] handler.OpenRegionHandler(189): Opened hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f. on 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,484 DEBUG [AM.ZK.Worker-pool13-t6] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51911,1487756065280, region=27f513717656a2c439f2478fb0dfb75f, current_state={27f513717656a2c439f2478fb0dfb75f state=OPENING, ts=1487756071464, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,485 INFO  [AM.ZK.Worker-pool13-t6] master.RegionStates(894): Transition {27f513717656a2c439f2478fb0dfb75f state=OPENING, ts=1487756071464, server=192.168.1.25,51911,1487756065280} to {27f513717656a2c439f2478fb0dfb75f state=OPEN, ts=1487756071485, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,485 DEBUG [AM.ZK.Worker-pool13-t6] handler.OpenedRegionHandler(149): Handling OPENED of 27f513717656a2c439f2478fb0dfb75f from 192.168.1.25,51911,1487756065280; deleting unassigned node
2017-02-22 10:34:31,487 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/27f513717656a2c439f2478fb0dfb75f
2017-02-22 10:34:31,487 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:34:31,487 DEBUG [AM.ZK.Worker-pool13-t6] zookeeper.ZKAssign(480): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Deleted unassigned node 27f513717656a2c439f2478fb0dfb75f in expected state RS_ZK_REGION_OPENED
2017-02-22 10:34:31,488 DEBUG [AM.ZK.Worker-pool13-t8] master.AssignmentManager$4(1316): Znode hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f. deleted, state: {27f513717656a2c439f2478fb0dfb75f state=OPEN, ts=1487756071485, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:34:31,488 INFO  [AM.ZK.Worker-pool13-t8] master.RegionStates(397): Onlined 27f513717656a2c439f2478fb0dfb75f on 192.168.1.25,51911,1487756065280
2017-02-22 10:34:31,498 DEBUG [M:0;192.168.1.25:51909] zookeeper.ZKUtil(368): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/namespace
2017-02-22 10:34:31,499 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:31,500 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 22 method_name: "Get" request_param: true
2017-02-22 10:34:31,501 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 481 bytes.
2017-02-22 10:34:31,501 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 22, totalSize: 477 bytes
2017-02-22 10:34:31,502 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 23 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,502 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 509 bytes.
2017-02-22 10:34:31,503 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 23 cell_block_meta { length: 488 }, totalSize: 505 bytes
2017-02-22 10:34:31,503 DEBUG [M:0;192.168.1.25:51909] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:31,504 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 24 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:31,505 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 12 bytes.
2017-02-22 10:34:31,505 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 24, totalSize: 8 bytes
2017-02-22 10:34:31,505 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:31,507 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 12 bytes.
2017-02-22 10:34:31,507 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 25, totalSize: 8 bytes
2017-02-22 10:34:31,508 DEBUG [htable-pool22-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 26 method_name: "Multi" request_param: true cell_block_meta { length: 45 } priority: 100
2017-02-22 10:34:31,511 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 18 bytes.
2017-02-22 10:34:31,512 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 26, totalSize: 14 bytes
2017-02-22 10:34:31,513 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:31,515 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 27 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:31,515 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:34:31,516 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 12 bytes.
2017-02-22 10:34:31,516 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 27, totalSize: 8 bytes
2017-02-22 10:34:31,517 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:31,517 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 12 bytes.
2017-02-22 10:34:31,518 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 28, totalSize: 8 bytes
2017-02-22 10:34:31,518 DEBUG [htable-pool22-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 29 method_name: "Multi" request_param: true cell_block_meta { length: 41 } priority: 100
2017-02-22 10:34:31,521 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 18 bytes.
2017-02-22 10:34:31,521 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 29, totalSize: 14 bytes
2017-02-22 10:34:31,522 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:31,524 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 30 method_name: "Scan" request_param: true
2017-02-22 10:34:31,525 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:34:31,525 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-02-22 10:34:31,525 DEBUG [B.DefaultRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 16 bytes.
2017-02-22 10:34:31,525 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 30, totalSize: 12 bytes
2017-02-22 10:34:31,525 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 31 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,527 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 112 bytes.
2017-02-22 10:34:31,527 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 31 cell_block_meta { length: 86 }, totalSize: 108 bytes
2017-02-22 10:34:31,527 DEBUG [M:0;192.168.1.25:51909] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 32 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:31,528 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 12 bytes.
2017-02-22 10:34:31,528 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 32, totalSize: 8 bytes
2017-02-22 10:34:31,529 INFO  [M:0;192.168.1.25:51909] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:34:31,530 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:34:31,531 INFO  [M:0;192.168.1.25:51909] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:34:31,532 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:34:31,532 INFO  [M:0;192.168.1.25:51909] master.HMaster(1043): Master has completed initialization
2017-02-22 10:34:31,532 INFO  [M:0;192.168.1.25:51909] zookeeper.ZooKeeperWatcher(236): not a secure deployment, proceeding
2017-02-22 10:34:31,647 INFO  [main] zookeeper.MiniZooKeeperCluster(200): Started MiniZK Cluster and connect 1 ZK server on client port: 36262
2017-02-22 10:34:31,649 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:34:31,656 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:31,657 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x47db5fa5-0x15a652c12db0000 connected
2017-02-22 10:34:31,657 INFO  [main] client.ZooKeeperRegistry(85): ClusterId read in ZooKeeper is null
2017-02-22 10:34:31,657 DEBUG [main] client.HConnectionManager$HConnectionImplementation(932): clusterid came back null, using default default-cluster
2017-02-22 10:34:31,658 DEBUG [main] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@41813449, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:31,659 DEBUG [main] client.HConnectionManager(2976): master//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:34:31,661 INFO  [main] ipc.RpcServer$Listener(649): master//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:34:31,662 INFO  [main] master.HMaster(547): hbase.rootdir=file:/var/tmp/test-data/cluster3/root, hbase.cluster.distributed=false
2017-02-22 10:34:31,662 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=master:51923 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:34:31,668 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:519230x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:31,669 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): master:51923-0x15a652c12db0001 connected
2017-02-22 10:34:31,685 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:34:31,686 INFO  [RpcServer.listener,port=51923] ipc.RpcServer$Listener(783): RpcServer.listener,port=51923: starting
2017-02-22 10:34:31,698 DEBUG [main] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:34:31,698 DEBUG [main] client.HConnectionManager(2976): regionserver//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:34:31,699 INFO  [main] ipc.SimpleRpcScheduler(86): Using default user call queue, count=3
2017-02-22 10:34:31,701 INFO  [main] ipc.RpcServer$Listener(649): regionserver//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:34:31,702 INFO  [main] hfile.CacheConfig(215): Created cacheConfig: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:31,707 INFO  [main] http.HttpServer(525): Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-02-22 10:34:31,708 INFO  [main] http.HttpServer(503): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2017-02-22 10:34:31,709 INFO  [main] http.HttpServer(510): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-02-22 10:34:31,721 INFO  [main] http.HttpServer(687): Jetty bound to port 51926
2017-02-22 10:34:31,954 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 3 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:31,955 DEBUG [FifoRpcScheduler.handler4-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 8 bytes.
2017-02-22 10:34:31,955 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 3, totalSize: 4 bytes
2017-02-22 10:34:32,029 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKUtil(368): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:34:32,030 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKUtil(368): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:34:32,032 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2017-02-22 10:34:32,034 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKUtil(366): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:32,034 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:32,034 DEBUG [main-EventThread] master.ActiveMasterManager(119): A master is now available
2017-02-22 10:34:32,034 WARN  [M:0;192.168.1.25:51923] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:34:32,035 INFO  [M:0;192.168.1.25:51923] master.ActiveMasterManager(170): Registered Active Master=192.168.1.25,51923,1487756071661
2017-02-22 10:34:32,037 INFO  [M:0;192.168.1.25:51923] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:32,052 INFO  [M:0;192.168.1.25:51923] util.FSUtils(696): Created version file at file:/var/tmp/test-data/cluster3/root with version=8
2017-02-22 10:34:32,066 DEBUG [M:0;192.168.1.25:51923] util.FSUtils(848): Created cluster ID file at file:/var/tmp/test-data/cluster3/root/hbase.id with ID: f7784a7f-fbc9-4cb3-9ef4-c5a7d415eb0e
2017-02-22 10:34:32,067 INFO  [M:0;192.168.1.25:51923] master.MasterFileSystem(550): BOOTSTRAP: creating hbase:meta region
2017-02-22 10:34:32,067 INFO  [M:0;192.168.1.25:51923] regionserver.HRegion(4729): creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster3/root Table name == hbase:meta
2017-02-22 10:34:32,082 INFO  [M:0;192.168.1.25:51923] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:32,096 INFO  [M:0;192.168.1.25:51923] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/WALs/hlog.1487756072082
2017-02-22 10:34:32,096 INFO  [M:0;192.168.1.25:51923] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:32,096 INFO  [M:0;192.168.1.25:51923] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:32,097 DEBUG [M:0;192.168.1.25:51923] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:34:32,099 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:32,099 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:32,100 DEBUG [M:0;192.168.1.25:51923] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740
2017-02-22 10:34:32,100 INFO  [M:0;192.168.1.25:51923] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:34:32,100 DEBUG [M:0;192.168.1.25:51923] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:34:32,100 DEBUG [M:0;192.168.1.25:51923] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:34:32,101 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:34:32,101 INFO  [M:0;192.168.1.25:51923] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:34:32,101 DEBUG [M:0;192.168.1.25:51923-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): M:0;192.168.1.25:51923-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:34:32,101 INFO  [M:0;192.168.1.25:51923-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): M:0;192.168.1.25:51923-WAL.AsyncNotifier exiting
2017-02-22 10:34:32,101 DEBUG [M:0;192.168.1.25:51923-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51923-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:32,101 INFO  [M:0;192.168.1.25:51923-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51923-WAL.AsyncSyncer0 exiting
2017-02-22 10:34:32,101 DEBUG [M:0;192.168.1.25:51923-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51923-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:32,101 INFO  [M:0;192.168.1.25:51923-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51923-WAL.AsyncSyncer1 exiting
2017-02-22 10:34:32,101 DEBUG [M:0;192.168.1.25:51923-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51923-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:32,101 INFO  [M:0;192.168.1.25:51923-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51923-WAL.AsyncSyncer2 exiting
2017-02-22 10:34:32,101 DEBUG [M:0;192.168.1.25:51923-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51923-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:32,101 INFO  [M:0;192.168.1.25:51923-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51923-WAL.AsyncSyncer3 exiting
2017-02-22 10:34:32,102 DEBUG [M:0;192.168.1.25:51923-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:51923-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:34:32,102 INFO  [M:0;192.168.1.25:51923-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:51923-WAL.AsyncSyncer4 exiting
2017-02-22 10:34:32,102 DEBUG [M:0;192.168.1.25:51923-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): M:0;192.168.1.25:51923-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:34:32,102 INFO  [M:0;192.168.1.25:51923-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): M:0;192.168.1.25:51923-WAL.AsyncWriter exiting
2017-02-22 10:34:32,102 DEBUG [M:0;192.168.1.25:51923] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/WALs
2017-02-22 10:34:32,102 DEBUG [M:0;192.168.1.25:51923] wal.FSHLog(892): Moved 1 WAL file(s) to /var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/oldWALs
2017-02-22 10:34:32,117 DEBUG [M:0;192.168.1.25:51923] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster3/root/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-02-22 10:34:32,118 DEBUG [M:0;192.168.1.25:51923] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:34:32,118 DEBUG [M:0;192.168.1.25:51923] master.SplitLogManager(1360): Distributed log replay=false, hfile.format.version=2
2017-02-22 10:34:32,119 INFO  [M:0;192.168.1.25:51923] master.SplitLogManager(224): Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-02-22 10:34:32,120 INFO  [M:0;192.168.1.25:51923] master.SplitLogManager(1100): Found 0 orphan tasks and 0 rescan nodes
2017-02-22 10:34:32,120 DEBUG [M:0;192.168.1.25:51923] util.FSTableDescriptors(208): Fetching table descriptors from the filesystem.
2017-02-22 10:34:32,123 INFO  [M:0;192.168.1.25:51923] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x3a6b6aba connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:34:32,128 DEBUG [M:0;192.168.1.25:51923-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x3a6b6aba0x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:32,129 DEBUG [M:0;192.168.1.25:51923-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x3a6b6aba-0x15a652c12db0002 connected
2017-02-22 10:34:32,129 INFO  [main] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RS:0;192.168.1.25:51925
2017-02-22 10:34:32,130 DEBUG [RS:0;192.168.1.25:51925] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:339)
2017-02-22 10:34:32,131 INFO  [RS:0;192.168.1.25:51925] zookeeper.RecoverableZooKeeper(120): Process identifier=regionserver:51925 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:34:32,132 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@b1b54b5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:32,134 DEBUG [M:0;192.168.1.25:51923] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3b1b0696
2017-02-22 10:34:32,136 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKUtil(368): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:34:32,137 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:519250x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:32,138 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(591): regionserver:51925-0x15a652c12db0003 connected
2017-02-22 10:34:32,139 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKUtil(368): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/balancer
2017-02-22 10:34:32,139 DEBUG [RS:0;192.168.1.25:51925] zookeeper.ZKUtil(366): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:34:32,140 DEBUG [RS:0;192.168.1.25:51925] zookeeper.ZKUtil(368): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:34:32,142 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:34:32,143 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:34:32,144 DEBUG [RS:0;192.168.1.25:51925] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@107901f7
2017-02-22 10:34:32,145 INFO  [M:0;192.168.1.25:51923] master.HMaster(801): Server active/primary master=192.168.1.25,51923,1487756071661, sessionid=0x15a652c12db0001, setting cluster-up flag (Was=false)
2017-02-22 10:34:32,145 DEBUG [RS:0;192.168.1.25:51925] zookeeper.ZKUtil(368): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:34:32,147 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(805): ClusterId : f7784a7f-fbc9-4cb3-9ef4-c5a7d415eb0e
2017-02-22 10:34:32,148 INFO  [RS:0;192.168.1.25:51925] procedure.RegionServerProcedureManagerHost(43): Procedure online-snapshot is initializing
2017-02-22 10:34:32,149 INFO  [RS:0;192.168.1.25:51925] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:34:32,152 INFO  [M:0;192.168.1.25:51923] procedure.ZKProcedureUtil(270): Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-02-22 10:34:32,152 INFO  [RS:0;192.168.1.25:51925] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/abort already exists and this is not a retry
2017-02-22 10:34:32,153 INFO  [RS:0;192.168.1.25:51925] procedure.RegionServerProcedureManagerHost(45): Procedure online-snapshot is initialized
2017-02-22 10:34:32,153 INFO  [RS:0;192.168.1.25:51925] regionserver.MemStoreFlusher(119): globalMemStoreLimit=1.4 G, globalMemStoreLimitLowMark=1.4 G, maxHeap=3.6 G
2017-02-22 10:34:32,153 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer$CompactionChecker(1508): CompactionChecker runs every 10sec
2017-02-22 10:34:32,154 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@14468720, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=192.168.1.25/192.168.1.25:0
2017-02-22 10:34:32,154 DEBUG [M:0;192.168.1.25:51923] procedure.ZKProcedureCoordinatorRpcs(195): Starting the controller for procedure member:192.168.1.25,51923,1487756071661
2017-02-22 10:34:32,155 INFO  [M:0;192.168.1.25:51923] master.MasterCoprocessorHost(85): System coprocessor loading is enabled
2017-02-22 10:34:32,155 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,51923,1487756071661 with port=51925, startcode=1487756071702
2017-02-22 10:34:32,155 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service RegionServerStatusService, sasl=false
2017-02-22 10:34:32,155 DEBUG [M:0;192.168.1.25:51923] executor.ExecutorService(100): Starting executor service name=MASTER_OPEN_REGION-192.168.1.25:51923, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:32,155 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51923
2017-02-22 10:34:32,155 DEBUG [M:0;192.168.1.25:51923] executor.ExecutorService(100): Starting executor service name=MASTER_CLOSE_REGION-192.168.1.25:51923, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:32,155 DEBUG [M:0;192.168.1.25:51923] executor.ExecutorService(100): Starting executor service name=MASTER_SERVER_OPERATIONS-192.168.1.25:51923, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:32,156 DEBUG [M:0;192.168.1.25:51923] executor.ExecutorService(100): Starting executor service name=MASTER_META_SERVER_OPERATIONS-192.168.1.25:51923, corePoolSize=5, maxPoolSize=5
2017-02-22 10:34:32,156 DEBUG [M:0;192.168.1.25:51923] executor.ExecutorService(100): Starting executor service name=M_LOG_REPLAY_OPS-192.168.1.25:51923, corePoolSize=10, maxPoolSize=10
2017-02-22 10:34:32,156 DEBUG [M:0;192.168.1.25:51923] executor.ExecutorService(100): Starting executor service name=MASTER_TABLE_OPERATIONS-192.168.1.25:51923, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:32,156 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 0 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:34:32,156 DEBUG [M:0;192.168.1.25:51923] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-02-22 10:34:32,157 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: starting, connections 1
2017-02-22 10:34:32,158 DEBUG [RpcServer.listener,port=51923] ipc.RpcServer$Listener(885): RpcServer.listener,port=51923: connection from 192.168.1.25:51929; # active connections: 1
2017-02-22 10:34:32,158 INFO  [M:0;192.168.1.25:51923] zookeeper.RecoverableZooKeeper(120): Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:34:32,159 DEBUG [RpcServer.reader=1,port=51923] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "RegionServerStatusService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:32,160 DEBUG [FifoRpcScheduler.handler7-thread-1] ipc.CallRunner(107): FifoRpcScheduler.handler7-thread-1: callId: 0 service: RegionServerStatusService methodName: RegionServerStartup size: 47 connection: 192.168.1.25:51929
org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.25/192.168.1.25:51923 is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:97)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-02-22 10:34:32,162 DEBUG [FifoRpcScheduler.handler7-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 685 bytes.
2017-02-22 10:34:32,163 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 0 exception { exception_class_name: "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException" stack_trace: "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.25/192.168.1.25:51923 is not running yet\n\tat org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:97)\n\tat org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n" do_not_retry: false }, totalSize: 681 bytes
2017-02-22 10:34:32,164 DEBUG [RS:0;192.168.1.25:51925] regionserver.HRegionServer(2214): Master is not running yet
2017-02-22 10:34:32,164 WARN  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(900): reportForDuty failed; sleeping and then retrying.
2017-02-22 10:34:32,167 DEBUG [M:0;192.168.1.25:51923-EventThread] zookeeper.ZooKeeperWatcher(528): replicationLogCleaner0x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:32,167 DEBUG [M:0;192.168.1.25:51923-EventThread] zookeeper.ZooKeeperWatcher(591): replicationLogCleaner-0x15a652c12db0004 connected
2017-02-22 10:34:32,171 DEBUG [M:0;192.168.1.25:51923] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-02-22 10:34:32,172 DEBUG [M:0;192.168.1.25:51923] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-02-22 10:34:32,172 DEBUG [M:0;192.168.1.25:51923] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-02-22 10:34:32,172 DEBUG [M:0;192.168.1.25:51923] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-02-22 10:34:32,172 DEBUG [M:0;192.168.1.25:51923] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-02-22 10:34:32,173 INFO  [M:0;192.168.1.25:51923] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:33,698 INFO  [M:0;192.168.1.25:51923] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 1525 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:34,318 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 6 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:34,319 DEBUG [FifoRpcScheduler.handler1-thread-7] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 8 bytes.
2017-02-22 10:34:34,319 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 6, totalSize: 4 bytes
2017-02-22 10:34:34,933 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: closed
2017-02-22 10:34:34,933 DEBUG [RpcServer.reader=1,port=51897] ipc.RpcServer$Listener(910): RpcServer.listener,port=51897: DISCONNECTING client 192.168.1.25:51905 because read count=-1. Number of active connections: 2
2017-02-22 10:34:34,933 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: stopped, connections 1
2017-02-22 10:34:34,957 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 4 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:34,958 DEBUG [FifoRpcScheduler.handler4-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 8 bytes.
2017-02-22 10:34:34,958 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 4, totalSize: 4 bytes
2017-02-22 10:34:35,036 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: closed
2017-02-22 10:34:35,036 DEBUG [RpcServer.reader=2,port=51897] ipc.RpcServer$Listener(910): RpcServer.listener,port=51897: DISCONNECTING client 192.168.1.25:51906 because read count=-1. Number of active connections: 1
2017-02-22 10:34:35,036 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: stopped, connections 0
2017-02-22 10:34:35,169 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,51923,1487756071661 with port=51925, startcode=1487756071702
2017-02-22 10:34:35,169 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 1 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:34:35,171 INFO  [FifoRpcScheduler.handler7-thread-2] master.ServerManager(423): Registering server=192.168.1.25,51925,1487756071702
2017-02-22 10:34:35,172 DEBUG [FifoRpcScheduler.handler7-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 184 bytes.
2017-02-22 10:34:35,172 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 1, totalSize: 180 bytes
2017-02-22 10:34:35,172 DEBUG [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1323): Config from master: hbase.rootdir=file:///var/tmp/test-data/cluster3/root
2017-02-22 10:34:35,173 DEBUG [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1323): Config from master: fs.default.name=file:/
2017-02-22 10:34:35,173 DEBUG [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1323): Config from master: hbase.master.info.port=-1
2017-02-22 10:34:35,176 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:34:35,177 DEBUG [RS:0;192.168.1.25:51925] zookeeper.ZKUtil(366): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51925,1487756071702
2017-02-22 10:34:35,177 INFO  [RS:0;192.168.1.25:51925] regionserver.RegionServerCoprocessorHost(66): System coprocessor loading is enabled
2017-02-22 10:34:35,177 INFO  [RS:0;192.168.1.25:51925] regionserver.RegionServerCoprocessorHost(67): Table coprocessor loading is enabled
2017-02-22 10:34:35,177 WARN  [RS:0;192.168.1.25:51925] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:34:35,177 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51925,1487756071702
2017-02-22 10:34:35,178 DEBUG [RS:0;192.168.1.25:51925] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:34:35,179 DEBUG [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1605): logdir=file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,51925,1487756071702
2017-02-22 10:34:35,179 DEBUG [main-EventThread] zookeeper.RegionServerTracker(95): Added tracking of RS /hbase/rs/192.168.1.25,51925,1487756071702
2017-02-22 10:34:35,185 DEBUG [RS:0;192.168.1.25:51925] regionserver.Replication(141): ReplicationStatisticsThread 300
2017-02-22 10:34:35,185 INFO  [RS:0;192.168.1.25:51925] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:35,188 INFO  [M:0;192.168.1.25:51923] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 3015 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:34:35,199 INFO  [RS:0;192.168.1.25:51925] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster3/root/WALs/192.168.1.25,51925,1487756071702/192.168.1.25%2C51925%2C1487756071702.1487756075186
2017-02-22 10:34:35,199 INFO  [RS:0;192.168.1.25:51925] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:35,199 INFO  [RS:0;192.168.1.25:51925] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:35,200 INFO  [RS:0;192.168.1.25:51925] regionserver.MetricsRegionServerWrapperImpl(101): Computing regionserver metrics every 5000 milliseconds
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsSystemImpl(220): RegionServer,sub=Server-2, Metrics about HBase RegionServer
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:34:35,200 DEBUG [RS:0;192.168.1.25:51925] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Server-2
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Server-2 registered.
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Server-2
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] executor.ExecutorService(100): Starting executor service name=RS_OPEN_REGION-192.168.1.25:51925, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] executor.ExecutorService(100): Starting executor service name=RS_OPEN_META-192.168.1.25:51925, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] executor.ExecutorService(100): Starting executor service name=RS_OPEN_PRIORITY_REGION-192.168.1.25:51925, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:35,201 DEBUG [RS:0;192.168.1.25:51925] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_REGION-192.168.1.25:51925, corePoolSize=3, maxPoolSize=3
2017-02-22 10:34:35,202 DEBUG [RS:0;192.168.1.25:51925] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_META-192.168.1.25:51925, corePoolSize=1, maxPoolSize=1
2017-02-22 10:34:35,202 DEBUG [RS:0;192.168.1.25:51925] executor.ExecutorService(100): Starting executor service name=RS_LOG_REPLAY_OPS-192.168.1.25:51925, corePoolSize=2, maxPoolSize=2
2017-02-22 10:34:35,204 DEBUG [RS:0;192.168.1.25:51925] zookeeper.ZKUtil(366): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,51925,1487756071702
2017-02-22 10:34:35,204 INFO  [RS:0;192.168.1.25:51925] regionserver.ReplicationSourceManager(226): Current list of replicators: [192.168.1.25,51925,1487756071702] other RSs: [192.168.1.25,51925,1487756071702]
2017-02-22 10:34:35,214 INFO  [RS:0;192.168.1.25:51925] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:34:35,215 INFO  [RS:0;192.168.1.25:51925] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:34:35,215 INFO  [RS:0;192.168.1.25:51925] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:35,216 INFO  [RS:0;192.168.1.25:51925] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0xca4cdae connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:34:35,222 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0xca4cdae0x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:35,223 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0xca4cdae-0x15a652c12db0005 connected
2017-02-22 10:34:35,225 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@339bc4e9, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:35,227 INFO  [RpcServer.listener,port=51925] ipc.RpcServer$Listener(783): RpcServer.listener,port=51925: starting
2017-02-22 10:34:35,227 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:34:35,227 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=0 queue=0
2017-02-22 10:34:35,228 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=1 queue=1
2017-02-22 10:34:35,229 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=2 queue=2
2017-02-22 10:34:35,229 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=3 queue=0
2017-02-22 10:34:35,229 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=4 queue=1
2017-02-22 10:34:35,229 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=5 queue=2
2017-02-22 10:34:35,229 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=6 queue=0
2017-02-22 10:34:35,230 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=7 queue=1
2017-02-22 10:34:35,230 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=8 queue=2
2017-02-22 10:34:35,230 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=9 queue=0
2017-02-22 10:34:35,230 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=10 queue=1
2017-02-22 10:34:35,230 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=11 queue=2
2017-02-22 10:34:35,231 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=12 queue=0
2017-02-22 10:34:35,231 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=13 queue=1
2017-02-22 10:34:35,231 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=14 queue=2
2017-02-22 10:34:35,231 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=15 queue=0
2017-02-22 10:34:35,231 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=16 queue=1
2017-02-22 10:34:35,231 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=17 queue=2
2017-02-22 10:34:35,232 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=18 queue=0
2017-02-22 10:34:35,232 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=19 queue=1
2017-02-22 10:34:35,232 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=20 queue=2
2017-02-22 10:34:35,232 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=21 queue=0
2017-02-22 10:34:35,232 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=22 queue=1
2017-02-22 10:34:35,232 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=23 queue=2
2017-02-22 10:34:35,233 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=24 queue=0
2017-02-22 10:34:35,233 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=25 queue=1
2017-02-22 10:34:35,233 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=26 queue=2
2017-02-22 10:34:35,233 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=27 queue=0
2017-02-22 10:34:35,233 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=28 queue=1
2017-02-22 10:34:35,233 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): B.Default Start Handler index=29 queue=2
2017-02-22 10:34:35,233 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=0 queue=0
2017-02-22 10:34:35,234 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=1 queue=0
2017-02-22 10:34:35,234 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=2 queue=0
2017-02-22 10:34:35,234 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=3 queue=0
2017-02-22 10:34:35,234 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=4 queue=0
2017-02-22 10:34:35,234 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=5 queue=0
2017-02-22 10:34:35,235 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=6 queue=0
2017-02-22 10:34:35,235 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=7 queue=0
2017-02-22 10:34:35,235 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=8 queue=0
2017-02-22 10:34:35,235 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Priority Start Handler index=9 queue=0
2017-02-22 10:34:35,235 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Replication Start Handler index=0 queue=0
2017-02-22 10:34:35,235 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Replication Start Handler index=1 queue=0
2017-02-22 10:34:35,236 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcExecutor(115): Replication Start Handler index=2 queue=0
2017-02-22 10:34:35,248 INFO  [RS:0;192.168.1.25:51925] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:34:35,248 INFO  [RS:0;192.168.1.25:51925] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:34:35,248 INFO  [RS:0;192.168.1.25:51925] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:34:35,249 INFO  [SplitLogWorker-192.168.1.25,51925,1487756071702] regionserver.SplitLogWorker(176): SplitLogWorker 192.168.1.25,51925,1487756071702 starting
2017-02-22 10:34:35,249 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1367): Serving as 192.168.1.25,51925,1487756071702, RpcServer on 192.168.1.25/192.168.1.25:51925, sessionid=0x15a652c12db0003
2017-02-22 10:34:35,249 INFO  [RS:0;192.168.1.25:51925] procedure.RegionServerProcedureManagerHost(51): Procedure online-snapshot is starting
2017-02-22 10:34:35,250 DEBUG [RS:0;192.168.1.25:51925] snapshot.RegionServerSnapshotManager(124): Start Snapshot Manager 192.168.1.25,51925,1487756071702
2017-02-22 10:34:35,250 DEBUG [RS:0;192.168.1.25:51925] procedure.ZKProcedureMemberRpcs(340): Starting procedure member '192.168.1.25,51925,1487756071702'
2017-02-22 10:34:35,250 DEBUG [RS:0;192.168.1.25:51925] procedure.ZKProcedureMemberRpcs(136): Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2017-02-22 10:34:35,251 INFO  [SplitLogWorker-192.168.1.25,51925,1487756071702] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x7d1da7b1 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:34:35,251 DEBUG [RS:0;192.168.1.25:51925] procedure.ZKProcedureMemberRpcs(152): Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2017-02-22 10:34:35,255 INFO  [RS:0;192.168.1.25:51925] procedure.RegionServerProcedureManagerHost(53): Procedure online-snapshot is started
2017-02-22 10:34:35,256 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 2 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:35,258 DEBUG [FifoRpcScheduler.handler7-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 8 bytes.
2017-02-22 10:34:35,258 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 2, totalSize: 4 bytes
2017-02-22 10:34:35,258 DEBUG [SplitLogWorker-192.168.1.25,51925,1487756071702-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x7d1da7b10x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:34:35,259 DEBUG [SplitLogWorker-192.168.1.25,51925,1487756071702-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x7d1da7b1-0x15a652c12db0006 connected
2017-02-22 10:34:35,260 DEBUG [SplitLogWorker-192.168.1.25,51925,1487756071702] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@77e5ccc1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:34:36,725 INFO  [M:0;192.168.1.25:51923] master.ServerManager(918): Finished waiting for region servers count to settle; checked in 1, slept for 4552 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-02-22 10:34:36,728 INFO  [M:0;192.168.1.25:51923] master.MasterFileSystem(260): Log folder file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,51925,1487756071702 belongs to an existing region server
2017-02-22 10:34:37,321 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 7 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:37,322 DEBUG [FifoRpcScheduler.handler1-thread-8] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 8 bytes.
2017-02-22 10:34:37,322 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 7, totalSize: 4 bytes
2017-02-22 10:34:37,558 INFO  [M:0;192.168.1.25:51923] zookeeper.MetaRegionTracker(184): Unsetting hbase:meta region location in ZooKeeper
2017-02-22 10:34:37,560 DEBUG [M:0;192.168.1.25:51923] zookeeper.RecoverableZooKeeper(188): Node /hbase/meta-region-server already deleted, retry=false
2017-02-22 10:34:37,560 DEBUG [M:0;192.168.1.25:51923] master.AssignmentManager(2461): No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=192.168.1.25,51925,1487756071702; 1 (online=1, available=1) available servers, forceNewPlan=false
2017-02-22 10:34:37,561 INFO  [M:0;192.168.1.25:51923] master.AssignmentManager(2089): Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:37,561 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKAssign(206): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-02-22 10:34:37,564 DEBUG [M:0;192.168.1.25:51923] master.AssignmentManager(2105): Setting table hbase:meta to ENABLED state.
2017-02-22 10:34:37,569 INFO  [M:0;192.168.1.25:51923] master.AssignmentManager(2120): Assigning hbase:meta,,1.1588230740 to 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,569 INFO  [M:0;192.168.1.25:51923] master.RegionStates(894): Transition {1588230740 state=OFFLINE, ts=1487756077561, server=null} to {1588230740 state=PENDING_OPEN, ts=1487756077569, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,569 DEBUG [M:0;192.168.1.25:51923] master.ServerManager(836): New admin connection to 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,569 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:34:37,569 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51925
2017-02-22 10:34:37,571 DEBUG [RpcServer.listener,port=51925] ipc.RpcServer$Listener(885): RpcServer.listener,port=51925: connection from 192.168.1.25:51933; # active connections: 1
2017-02-22 10:34:37,571 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: starting, connections 1
2017-02-22 10:34:37,572 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 0 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:34:37,574 DEBUG [RpcServer.reader=1,port=51925] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:37,575 INFO  [PriorityRpcServer.handler=0,queue=0,port=51925] regionserver.HRegionServer(4011): Open hbase:meta,,1.1588230740
2017-02-22 10:34:37,576 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:34:37,576 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] zookeeper.ZKAssign(832): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:37,576 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:34:37,576 INFO  [M:0;192.168.1.25:51923] master.ServerManager(618): AssignmentManager hasn't finished failover cleanup; waiting
2017-02-22 10:34:37,581 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:37,581 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] zookeeper.ZKAssign(907): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:37,581 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] regionserver.HRegionServer(1622): logdir=file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,582 INFO  [RS_OPEN_META-192.168.1.25:51925-0] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:34:37,583 DEBUG [AM.ZK.Worker-pool24-t1] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51925,1487756071702, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1487756077569, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,584 INFO  [AM.ZK.Worker-pool24-t1] master.RegionStates(894): Transition {1588230740 state=PENDING_OPEN, ts=1487756077569, server=192.168.1.25,51925,1487756071702} to {1588230740 state=OPENING, ts=1487756077584, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,605 INFO  [RS_OPEN_META-192.168.1.25:51925-0] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster3/root/WALs/192.168.1.25,51925,1487756071702/192.168.1.25%2C51925%2C1487756071702.1487756077583.meta
2017-02-22 10:34:37,605 INFO  [RS_OPEN_META-192.168.1.25:51925-0] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:37,606 INFO  [RS_OPEN_META-192.168.1.25:51925-0] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:34:37,607 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] regionserver.HRegion(4915): Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:37,608 INFO  [RS_OPEN_META-192.168.1.25:51925-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:34:37,609 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] coprocessor.CoprocessorHost(226): Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2017-02-22 10:34:37,609 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] regionserver.HRegion(6103): Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2017-02-22 10:34:37,609 INFO  [RS_OPEN_META-192.168.1.25:51925-0] regionserver.RegionCoprocessorHost(373): Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2017-02-22 10:34:37,609 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table meta 1588230740
2017-02-22 10:34:37,609 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:34:37,611 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:37,611 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:37,612 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740
2017-02-22 10:34:37,613 INFO  [RS_OPEN_META-192.168.1.25:51925-0] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:34:37,613 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] zookeeper.ZKAssign(644): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2017-02-22 10:34:37,614 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:meta,,1.1588230740
2017-02-22 10:34:37,614 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1911): Updating zk with meta location
2017-02-22 10:34:37,614 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaRegionTracker(142): Setting hbase:meta region location in ZooKeeper as 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,616 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:34:37,616 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:34:37,618 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:meta,,1.1588230740
2017-02-22 10:34:37,618 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] zookeeper.ZKAssign(832): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:37,620 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:37,620 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] zookeeper.ZKAssign(907): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:37,620 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] handler.OpenRegionHandler(403): Transitioned 1588230740 to OPENED in zk on 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,620 DEBUG [RS_OPEN_META-192.168.1.25:51925-0] handler.OpenRegionHandler(189): Opened hbase:meta,,1.1588230740 on 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,621 DEBUG [AM.ZK.Worker-pool24-t2] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51925,1487756071702, region=1588230740, current_state={1588230740 state=OPENING, ts=1487756077584, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,621 INFO  [AM.ZK.Worker-pool24-t2] master.RegionStates(894): Transition {1588230740 state=OPENING, ts=1487756077584, server=192.168.1.25,51925,1487756071702} to {1588230740 state=OPEN, ts=1487756077621, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,621 INFO  [AM.ZK.Worker-pool24-t2] handler.OpenedRegionHandler(147): Handling OPENED of 1588230740 from 192.168.1.25,51925,1487756071702; deleting unassigned node
2017-02-22 10:34:37,623 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:34:37,623 DEBUG [AM.ZK.Worker-pool24-t2] zookeeper.ZKAssign(480): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:34:37,624 DEBUG [AM.ZK.Worker-pool24-t3] master.AssignmentManager$4(1316): Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1487756077621, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,624 INFO  [AM.ZK.Worker-pool24-t3] master.RegionStates(397): Onlined 1588230740 on 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,626 INFO  [M:0;192.168.1.25:51923] master.HMaster(1162): hbase:meta assigned=1, rit=false, location=192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,628 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:34:37,628 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51925
2017-02-22 10:34:37,630 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: starting, connections 2
2017-02-22 10:34:37,630 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 1 method_name: "Scan" request_param: true
2017-02-22 10:34:37,632 DEBUG [RpcServer.listener,port=51925] ipc.RpcServer$Listener(885): RpcServer.listener,port=51925: connection from 192.168.1.25:51934; # active connections: 2
2017-02-22 10:34:37,633 DEBUG [RpcServer.reader=2,port=51925] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:34:37,634 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 16 bytes.
2017-02-22 10:34:37,634 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 1, totalSize: 12 bytes
2017-02-22 10:34:37,634 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,636 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 18 bytes.
2017-02-22 10:34:37,636 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 2, totalSize: 14 bytes
2017-02-22 10:34:37,637 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,637 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 12 bytes.
2017-02-22 10:34:37,637 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 3, totalSize: 8 bytes
2017-02-22 10:34:37,637 INFO  [M:0;192.168.1.25:51923] catalog.MetaMigrationConvertingToPB(166): hbase:meta doesn't have any entries to update.
2017-02-22 10:34:37,637 INFO  [M:0;192.168.1.25:51923] catalog.MetaMigrationConvertingToPB(132): META already up-to date with PB serialization
2017-02-22 10:34:37,642 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true
2017-02-22 10:34:37,645 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 16 bytes.
2017-02-22 10:34:37,645 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 4, totalSize: 12 bytes
2017-02-22 10:34:37,645 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,645 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 18 bytes.
2017-02-22 10:34:37,646 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 5, totalSize: 14 bytes
2017-02-22 10:34:37,646 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,646 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 12 bytes.
2017-02-22 10:34:37,646 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 6, totalSize: 8 bytes
2017-02-22 10:34:37,649 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKAssign(498): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Deleting any existing unassigned nodes
2017-02-22 10:34:37,650 INFO  [M:0;192.168.1.25:51923] master.AssignmentManager(646): Clean cluster startup. Assigning user regions
2017-02-22 10:34:37,650 INFO  [M:0;192.168.1.25:51923] master.SnapshotOfRegionAssignmentFromMeta(95): Start to scan the hbase:meta for the current region assignment snappshot
2017-02-22 10:34:37,651 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true
2017-02-22 10:34:37,651 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 16 bytes.
2017-02-22 10:34:37,651 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 7, totalSize: 12 bytes
2017-02-22 10:34:37,652 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,652 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 18 bytes.
2017-02-22 10:34:37,652 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 8, totalSize: 14 bytes
2017-02-22 10:34:37,652 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,653 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 12 bytes.
2017-02-22 10:34:37,653 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 9, totalSize: 8 bytes
2017-02-22 10:34:37,653 INFO  [M:0;192.168.1.25:51923] master.SnapshotOfRegionAssignmentFromMeta(138): Finished to scan the hbase:meta for the current region assignmentsnapshot
2017-02-22 10:34:37,655 INFO  [M:0;192.168.1.25:51923] master.AssignmentManager(511): Joined the cluster in 18ms, failover=false
2017-02-22 10:34:37,659 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true
2017-02-22 10:34:37,661 DEBUG [CatalogJanitor-192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 11 method_name: "Scan" request_param: true
2017-02-22 10:34:37,661 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 16 bytes.
2017-02-22 10:34:37,661 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 10, totalSize: 12 bytes
2017-02-22 10:34:37,662 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 16 bytes.
2017-02-22 10:34:37,662 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 11, totalSize: 12 bytes
2017-02-22 10:34:37,662 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,662 DEBUG [CatalogJanitor-192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 13 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,662 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:34:37,662 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:34:37,662 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 18 bytes.
2017-02-22 10:34:37,663 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 12, totalSize: 14 bytes
2017-02-22 10:34:37,663 DEBUG [CatalogJanitor-192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 14 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,663 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 12 bytes.
2017-02-22 10:34:37,663 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 14, totalSize: 8 bytes
2017-02-22 10:34:37,663 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 15 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,663 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 12 bytes.
2017-02-22 10:34:37,664 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 15, totalSize: 8 bytes
2017-02-22 10:34:37,664 INFO  [M:0;192.168.1.25:51923] master.TableNamespaceManager(85): Namespace table not found. Creating...
2017-02-22 10:34:37,670 DEBUG [M:0;192.168.1.25:51923] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:519230000000000
2017-02-22 10:34:37,671 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 16 method_name: "Scan" request_param: true
2017-02-22 10:34:37,674 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 16 bytes.
2017-02-22 10:34:37,674 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 16, totalSize: 12 bytes
2017-02-22 10:34:37,675 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 17 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,675 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 18 bytes.
2017-02-22 10:34:37,676 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 17, totalSize: 14 bytes
2017-02-22 10:34:37,676 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 18 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,676 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 12 bytes.
2017-02-22 10:34:37,677 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 18, totalSize: 8 bytes
2017-02-22 10:34:37,677 WARN  [M:0;192.168.1.25:51923] zookeeper.ZKTable(133): Moving table hbase:namespace state to enabling but was not first in disabled state: null
2017-02-22 10:34:37,680 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.CreateTableHandler(165): Create table hbase:namespace
2017-02-22 10:34:37,694 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster3/root/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2017-02-22 10:34:37,694 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(4729): creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster3/root/.tmp Table name == hbase:namespace
2017-02-22 10:34:37,709 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:34:37,709 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.: disabling compactions & flushes
2017-02-22 10:34:37,709 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:34:37,709 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:34:37,711 DEBUG [htable-pool31-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 19 method_name: "Multi" request_param: true cell_block_meta { length: 141 } priority: 100
2017-02-22 10:34:37,716 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 18 bytes.
2017-02-22 10:34:37,716 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 19, totalSize: 14 bytes
2017-02-22 10:34:37,717 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:34:37,718 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,718 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] zookeeper.ZKAssign(175): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Async create of unassigned node 7bfc107b17904a0cce41388d3ef6cf42 with OFFLINE state
2017-02-22 10:34:37,720 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:34:37,720 DEBUG [main-EventThread] master.OfflineCallback(69): rs={7bfc107b17904a0cce41388d3ef6cf42 state=OFFLINE, ts=1487756077718, server=null}, server=192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,721 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={7bfc107b17904a0cce41388d3ef6cf42 state=OFFLINE, ts=1487756077718, server=null}, server=192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,725 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.AssignmentManager(1673): 192.168.1.25,51925,1487756071702 unassigned znodes=1 of total=1
2017-02-22 10:34:37,725 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.RegionStates(894): Transition {7bfc107b17904a0cce41388d3ef6cf42 state=OFFLINE, ts=1487756077718, server=null} to {7bfc107b17904a0cce41388d3ef6cf42 state=PENDING_OPEN, ts=1487756077725, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,728 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 20 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:34:37,728 INFO  [PriorityRpcServer.handler=0,queue=0,port=51925] regionserver.HRegionServer(4011): Open hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:34:37,730 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 10 bytes.
2017-02-22 10:34:37,731 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 20, totalSize: 6 bytes
2017-02-22 10:34:37,731 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(832): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioning 7bfc107b17904a0cce41388d3ef6cf42 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:37,732 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,734 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/7bfc107b17904a0cce41388d3ef6cf42
2017-02-22 10:34:37,735 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(907): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioned node 7bfc107b17904a0cce41388d3ef6cf42 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:34:37,735 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] regionserver.HRegion(4915): Opening region: {ENCODED => 7bfc107b17904a0cce41388d3ef6cf42, NAME => 'hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:37,736 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:34:37,736 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table namespace 7bfc107b17904a0cce41388d3ef6cf42
2017-02-22 10:34:37,738 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:34:37,740 DEBUG [AM.ZK.Worker-pool24-t5] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51925,1487756071702, region=7bfc107b17904a0cce41388d3ef6cf42, current_state={7bfc107b17904a0cce41388d3ef6cf42 state=PENDING_OPEN, ts=1487756077725, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,740 INFO  [AM.ZK.Worker-pool24-t5] master.RegionStates(894): Transition {7bfc107b17904a0cce41388d3ef6cf42 state=PENDING_OPEN, ts=1487756077725, server=192.168.1.25,51925,1487756071702} to {7bfc107b17904a0cce41388d3ef6cf42 state=OPENING, ts=1487756077740, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,741 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/hbase:namespace/write-master:519230000000000
2017-02-22 10:34:37,741 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:34:37,741 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:34:37,746 INFO  [StoreOpener-7bfc107b17904a0cce41388d3ef6cf42-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:34:37,746 INFO  [StoreOpener-7bfc107b17904a0cce41388d3ef6cf42-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:34:37,747 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/7bfc107b17904a0cce41388d3ef6cf42
2017-02-22 10:34:37,747 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] regionserver.HRegion(826): Onlined 7bfc107b17904a0cce41388d3ef6cf42; next sequenceid=1
2017-02-22 10:34:37,748 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(644): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Attempting to retransition opening state of node 7bfc107b17904a0cce41388d3ef6cf42
2017-02-22 10:34:37,749 INFO  [PostOpenDeployTasks:7bfc107b17904a0cce41388d3ef6cf42] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:34:37,750 DEBUG [htable-pool32-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 21 method_name: "Multi" request_param: true cell_block_meta { length: 347 } priority: 100
2017-02-22 10:34:37,752 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 18 bytes.
2017-02-22 10:34:37,753 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 21, totalSize: 14 bytes
2017-02-22 10:34:37,753 INFO  [PostOpenDeployTasks:7bfc107b17904a0cce41388d3ef6cf42] catalog.MetaEditor(523): Updated row hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42. with server=192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,753 INFO  [PostOpenDeployTasks:7bfc107b17904a0cce41388d3ef6cf42] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:34:37,754 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(832): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioning 7bfc107b17904a0cce41388d3ef6cf42 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:37,756 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/7bfc107b17904a0cce41388d3ef6cf42
2017-02-22 10:34:37,756 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(907): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioned node 7bfc107b17904a0cce41388d3ef6cf42 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:34:37,756 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] handler.OpenRegionHandler(403): Transitioned 7bfc107b17904a0cce41388d3ef6cf42 to OPENED in zk on 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,756 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:51925-0] handler.OpenRegionHandler(189): Opened hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42. on 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,756 DEBUG [AM.ZK.Worker-pool24-t6] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51925,1487756071702, region=7bfc107b17904a0cce41388d3ef6cf42, current_state={7bfc107b17904a0cce41388d3ef6cf42 state=OPENING, ts=1487756077740, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,757 INFO  [AM.ZK.Worker-pool24-t6] master.RegionStates(894): Transition {7bfc107b17904a0cce41388d3ef6cf42 state=OPENING, ts=1487756077740, server=192.168.1.25,51925,1487756071702} to {7bfc107b17904a0cce41388d3ef6cf42 state=OPEN, ts=1487756077757, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,757 DEBUG [AM.ZK.Worker-pool24-t6] handler.OpenedRegionHandler(149): Handling OPENED of 7bfc107b17904a0cce41388d3ef6cf42 from 192.168.1.25,51925,1487756071702; deleting unassigned node
2017-02-22 10:34:37,758 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/7bfc107b17904a0cce41388d3ef6cf42
2017-02-22 10:34:37,758 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:34:37,758 DEBUG [AM.ZK.Worker-pool24-t6] zookeeper.ZKAssign(480): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Deleted unassigned node 7bfc107b17904a0cce41388d3ef6cf42 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:34:37,759 DEBUG [AM.ZK.Worker-pool24-t8] master.AssignmentManager$4(1316): Znode hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42. deleted, state: {7bfc107b17904a0cce41388d3ef6cf42 state=OPEN, ts=1487756077757, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:34:37,759 INFO  [AM.ZK.Worker-pool24-t8] master.RegionStates(397): Onlined 7bfc107b17904a0cce41388d3ef6cf42 on 192.168.1.25,51925,1487756071702
2017-02-22 10:34:37,785 DEBUG [M:0;192.168.1.25:51923] zookeeper.ZKUtil(368): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/namespace
2017-02-22 10:34:37,787 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:37,788 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 22 method_name: "Get" request_param: true
2017-02-22 10:34:37,790 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 481 bytes.
2017-02-22 10:34:37,790 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 22, totalSize: 477 bytes
2017-02-22 10:34:37,790 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 23 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,791 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 509 bytes.
2017-02-22 10:34:37,792 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 23 cell_block_meta { length: 488 }, totalSize: 505 bytes
2017-02-22 10:34:37,792 DEBUG [M:0;192.168.1.25:51923] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:34:37,792 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 24 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:37,793 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 12 bytes.
2017-02-22 10:34:37,794 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 24, totalSize: 8 bytes
2017-02-22 10:34:37,794 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:37,797 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 12 bytes.
2017-02-22 10:34:37,797 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 25, totalSize: 8 bytes
2017-02-22 10:34:37,800 DEBUG [htable-pool33-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 26 method_name: "Multi" request_param: true cell_block_meta { length: 45 } priority: 100
2017-02-22 10:34:37,802 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 18 bytes.
2017-02-22 10:34:37,802 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 26, totalSize: 14 bytes
2017-02-22 10:34:37,803 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:37,805 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 27 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:37,805 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:34:37,805 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 12 bytes.
2017-02-22 10:34:37,805 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 27, totalSize: 8 bytes
2017-02-22 10:34:37,806 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 100
2017-02-22 10:34:37,806 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 12 bytes.
2017-02-22 10:34:37,806 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 28, totalSize: 8 bytes
2017-02-22 10:34:37,807 DEBUG [htable-pool33-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 29 method_name: "Multi" request_param: true cell_block_meta { length: 41 } priority: 100
2017-02-22 10:34:37,809 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 18 bytes.
2017-02-22 10:34:37,809 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 29, totalSize: 14 bytes
2017-02-22 10:34:37,811 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/namespace
2017-02-22 10:34:37,812 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 30 method_name: "Scan" request_param: true
2017-02-22 10:34:37,812 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:34:37,812 DEBUG [main-EventThread] hbase.ZKNamespaceManager(196): Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-02-22 10:34:37,813 DEBUG [B.DefaultRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 16 bytes.
2017-02-22 10:34:37,813 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 30, totalSize: 12 bytes
2017-02-22 10:34:37,813 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 31 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,815 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 112 bytes.
2017-02-22 10:34:37,815 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 31 cell_block_meta { length: 86 }, totalSize: 108 bytes
2017-02-22 10:34:37,815 DEBUG [M:0;192.168.1.25:51923] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 32 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:34:37,815 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 12 bytes.
2017-02-22 10:34:37,815 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 32, totalSize: 8 bytes
2017-02-22 10:34:37,817 INFO  [M:0;192.168.1.25:51923] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:34:37,818 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:34:37,820 INFO  [M:0;192.168.1.25:51923] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:34:37,822 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:34:37,822 INFO  [M:0;192.168.1.25:51923] master.HMaster(1043): Master has completed initialization
2017-02-22 10:34:37,822 INFO  [M:0;192.168.1.25:51923] zookeeper.ZooKeeperWatcher(236): not a secure deployment, proceeding
2017-02-22 10:34:37,964 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 5 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:37,965 DEBUG [FifoRpcScheduler.handler4-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 8 bytes.
2017-02-22 10:34:37,965 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 5, totalSize: 4 bytes
2017-02-22 10:34:38,262 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 3 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:38,263 DEBUG [FifoRpcScheduler.handler7-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 8 bytes.
2017-02-22 10:34:38,263 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 3, totalSize: 4 bytes
2017-02-22 10:34:40,324 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 8 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:40,325 DEBUG [FifoRpcScheduler.handler1-thread-9] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 8 bytes.
2017-02-22 10:34:40,325 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 8, totalSize: 4 bytes
2017-02-22 10:34:40,971 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 6 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:40,972 DEBUG [FifoRpcScheduler.handler4-thread-7] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 8 bytes.
2017-02-22 10:34:40,972 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 6, totalSize: 4 bytes
2017-02-22 10:34:41,269 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 4 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:41,270 DEBUG [FifoRpcScheduler.handler7-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 8 bytes.
2017-02-22 10:34:41,270 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 4, totalSize: 4 bytes
2017-02-22 10:34:41,444 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: closed
2017-02-22 10:34:41,444 DEBUG [RpcServer.reader=1,port=51911] ipc.RpcServer$Listener(910): RpcServer.listener,port=51911: DISCONNECTING client 192.168.1.25:51919 because read count=-1. Number of active connections: 2
2017-02-22 10:34:41,444 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: stopped, connections 1
2017-02-22 10:34:41,532 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: closed
2017-02-22 10:34:41,532 DEBUG [RpcServer.reader=2,port=51911] ipc.RpcServer$Listener(910): RpcServer.listener,port=51911: DISCONNECTING client 192.168.1.25:51920 because read count=-1. Number of active connections: 1
2017-02-22 10:34:41,533 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: stopped, connections 0
2017-02-22 10:34:43,328 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 9 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:43,330 DEBUG [FifoRpcScheduler.handler1-thread-10] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 8 bytes.
2017-02-22 10:34:43,330 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 9, totalSize: 4 bytes
2017-02-22 10:34:43,978 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 7 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:43,979 DEBUG [FifoRpcScheduler.handler4-thread-8] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 8 bytes.
2017-02-22 10:34:43,980 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 7, totalSize: 4 bytes
2017-02-22 10:34:44,274 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 5 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:44,274 DEBUG [FifoRpcScheduler.handler7-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 8 bytes.
2017-02-22 10:34:44,275 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 5, totalSize: 4 bytes
2017-02-22 10:34:46,335 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 10 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:46,336 DEBUG [FifoRpcScheduler.handler1-thread-11] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 8 bytes.
2017-02-22 10:34:46,336 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 10, totalSize: 4 bytes
2017-02-22 10:34:46,985 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 8 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:46,986 DEBUG [FifoRpcScheduler.handler4-thread-9] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 8 bytes.
2017-02-22 10:34:46,987 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 8, totalSize: 4 bytes
2017-02-22 10:34:47,280 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 6 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:47,281 DEBUG [FifoRpcScheduler.handler7-thread-7] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 8 bytes.
2017-02-22 10:34:47,281 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 6, totalSize: 4 bytes
2017-02-22 10:34:47,727 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: closed
2017-02-22 10:34:47,727 DEBUG [RpcServer.reader=1,port=51925] ipc.RpcServer$Listener(910): RpcServer.listener,port=51925: DISCONNECTING client 192.168.1.25:51933 because read count=-1. Number of active connections: 2
2017-02-22 10:34:47,728 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: stopped, connections 1
2017-02-22 10:34:47,819 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: closed
2017-02-22 10:34:47,819 DEBUG [RpcServer.reader=2,port=51925] ipc.RpcServer$Listener(910): RpcServer.listener,port=51925: DISCONNECTING client 192.168.1.25:51934 because read count=-1. Number of active connections: 1
2017-02-22 10:34:47,819 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: stopped, connections 0
2017-02-22 10:34:49,338 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 11 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:49,340 DEBUG [FifoRpcScheduler.handler1-thread-12] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 8 bytes.
2017-02-22 10:34:49,341 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 11, totalSize: 4 bytes
2017-02-22 10:34:49,992 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 9 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:49,994 DEBUG [FifoRpcScheduler.handler4-thread-10] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 8 bytes.
2017-02-22 10:34:49,995 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 9, totalSize: 4 bytes
2017-02-22 10:34:50,284 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 7 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:50,285 DEBUG [FifoRpcScheduler.handler7-thread-8] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 8 bytes.
2017-02-22 10:34:50,285 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 7, totalSize: 4 bytes
2017-02-22 10:34:52,343 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 12 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:52,344 DEBUG [FifoRpcScheduler.handler1-thread-13] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 8 bytes.
2017-02-22 10:34:52,344 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 12, totalSize: 4 bytes
2017-02-22 10:34:52,999 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 10 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:53,001 DEBUG [FifoRpcScheduler.handler4-thread-11] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 8 bytes.
2017-02-22 10:34:53,001 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 10, totalSize: 4 bytes
2017-02-22 10:34:53,290 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 8 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:53,291 DEBUG [FifoRpcScheduler.handler7-thread-9] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 8 bytes.
2017-02-22 10:34:53,291 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 8, totalSize: 4 bytes
2017-02-22 10:34:55,345 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 13 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:55,346 DEBUG [FifoRpcScheduler.handler1-thread-14] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 8 bytes.
2017-02-22 10:34:55,346 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 13, totalSize: 4 bytes
2017-02-22 10:34:56,006 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 11 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:56,007 DEBUG [FifoRpcScheduler.handler4-thread-12] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 8 bytes.
2017-02-22 10:34:56,007 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 11, totalSize: 4 bytes
2017-02-22 10:34:56,297 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 9 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:56,297 DEBUG [FifoRpcScheduler.handler7-thread-10] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 8 bytes.
2017-02-22 10:34:56,298 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 9, totalSize: 4 bytes
2017-02-22 10:34:58,352 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 14 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:58,353 DEBUG [FifoRpcScheduler.handler1-thread-15] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 8 bytes.
2017-02-22 10:34:58,354 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 14, totalSize: 4 bytes
2017-02-22 10:34:59,014 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 12 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:59,015 DEBUG [FifoRpcScheduler.handler4-thread-13] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 8 bytes.
2017-02-22 10:34:59,015 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 12, totalSize: 4 bytes
2017-02-22 10:34:59,304 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 10 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:34:59,305 DEBUG [FifoRpcScheduler.handler7-thread-11] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 8 bytes.
2017-02-22 10:34:59,305 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 10, totalSize: 4 bytes
2017-02-22 10:35:01,359 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 15 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:01,360 DEBUG [FifoRpcScheduler.handler1-thread-16] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 8 bytes.
2017-02-22 10:35:01,360 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 15, totalSize: 4 bytes
2017-02-22 10:35:02,021 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 13 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:02,022 DEBUG [FifoRpcScheduler.handler4-thread-14] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 8 bytes.
2017-02-22 10:35:02,022 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 13, totalSize: 4 bytes
2017-02-22 10:35:02,311 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 11 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:02,312 DEBUG [FifoRpcScheduler.handler7-thread-12] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 8 bytes.
2017-02-22 10:35:02,312 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 11, totalSize: 4 bytes
2017-02-22 10:35:04,366 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 16 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:04,367 DEBUG [FifoRpcScheduler.handler1-thread-17] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 8 bytes.
2017-02-22 10:35:04,367 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 16, totalSize: 4 bytes
2017-02-22 10:35:05,028 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 14 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:05,029 DEBUG [FifoRpcScheduler.handler4-thread-15] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 8 bytes.
2017-02-22 10:35:05,029 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 14, totalSize: 4 bytes
2017-02-22 10:35:05,318 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 12 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:05,319 DEBUG [FifoRpcScheduler.handler7-thread-13] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 8 bytes.
2017-02-22 10:35:05,319 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 12, totalSize: 4 bytes
2017-02-22 10:35:07,373 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 17 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:07,374 DEBUG [FifoRpcScheduler.handler1-thread-18] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 8 bytes.
2017-02-22 10:35:07,374 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 17, totalSize: 4 bytes
2017-02-22 10:35:08,035 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 15 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:08,036 DEBUG [FifoRpcScheduler.handler4-thread-16] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 8 bytes.
2017-02-22 10:35:08,036 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 15, totalSize: 4 bytes
2017-02-22 10:35:08,321 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 13 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:08,323 DEBUG [FifoRpcScheduler.handler7-thread-14] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 8 bytes.
2017-02-22 10:35:08,323 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 13, totalSize: 4 bytes
2017-02-22 10:35:10,381 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 18 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:10,382 DEBUG [FifoRpcScheduler.handler1-thread-19] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 8 bytes.
2017-02-22 10:35:10,382 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 18, totalSize: 4 bytes
2017-02-22 10:35:11,042 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 16 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:11,043 DEBUG [FifoRpcScheduler.handler4-thread-17] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 8 bytes.
2017-02-22 10:35:11,043 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 16, totalSize: 4 bytes
2017-02-22 10:35:11,328 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 14 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:11,329 DEBUG [FifoRpcScheduler.handler7-thread-15] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 8 bytes.
2017-02-22 10:35:11,329 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 14, totalSize: 4 bytes
2017-02-22 10:35:13,389 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 19 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:13,390 DEBUG [FifoRpcScheduler.handler1-thread-20] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 8 bytes.
2017-02-22 10:35:13,391 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 19, totalSize: 4 bytes
2017-02-22 10:35:14,049 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 17 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:14,050 DEBUG [FifoRpcScheduler.handler4-thread-18] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 8 bytes.
2017-02-22 10:35:14,050 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 17, totalSize: 4 bytes
2017-02-22 10:35:14,330 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 15 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:14,331 DEBUG [FifoRpcScheduler.handler7-thread-16] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 8 bytes.
2017-02-22 10:35:14,331 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 15, totalSize: 4 bytes
2017-02-22 10:35:16,395 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 20 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:16,396 DEBUG [FifoRpcScheduler.handler1-thread-21] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 8 bytes.
2017-02-22 10:35:16,397 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 20, totalSize: 4 bytes
2017-02-22 10:35:17,052 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 18 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:17,054 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 18, totalSize: 4 bytes
2017-02-22 10:35:17,053 DEBUG [FifoRpcScheduler.handler4-thread-19] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 8 bytes.
2017-02-22 10:35:17,337 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 16 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:17,339 DEBUG [FifoRpcScheduler.handler7-thread-17] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 8 bytes.
2017-02-22 10:35:17,339 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 16, totalSize: 4 bytes
2017-02-22 10:35:19,403 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 21 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:19,405 DEBUG [FifoRpcScheduler.handler1-thread-22] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 8 bytes.
2017-02-22 10:35:19,405 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 21, totalSize: 4 bytes
2017-02-22 10:35:20,061 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 19 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:20,062 DEBUG [FifoRpcScheduler.handler4-thread-20] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 8 bytes.
2017-02-22 10:35:20,062 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 19, totalSize: 4 bytes
2017-02-22 10:35:20,343 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 17 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:20,344 DEBUG [FifoRpcScheduler.handler7-thread-18] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 8 bytes.
2017-02-22 10:35:20,345 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 17, totalSize: 4 bytes
2017-02-22 10:35:22,409 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 22 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:22,411 DEBUG [FifoRpcScheduler.handler1-thread-23] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 8 bytes.
2017-02-22 10:35:22,411 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 22, totalSize: 4 bytes
2017-02-22 10:35:23,065 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 20 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:23,066 DEBUG [FifoRpcScheduler.handler4-thread-21] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 8 bytes.
2017-02-22 10:35:23,066 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 20, totalSize: 4 bytes
2017-02-22 10:35:23,349 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 18 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:23,350 DEBUG [FifoRpcScheduler.handler7-thread-19] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 8 bytes.
2017-02-22 10:35:23,350 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 18, totalSize: 4 bytes
2017-02-22 10:35:25,416 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 23 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:25,417 DEBUG [FifoRpcScheduler.handler1-thread-24] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 8 bytes.
2017-02-22 10:35:25,417 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 23, totalSize: 4 bytes
2017-02-22 10:35:26,072 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 21 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:26,073 DEBUG [FifoRpcScheduler.handler4-thread-22] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 8 bytes.
2017-02-22 10:35:26,073 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 21, totalSize: 4 bytes
2017-02-22 10:35:26,356 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 19 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:26,357 DEBUG [FifoRpcScheduler.handler7-thread-20] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 8 bytes.
2017-02-22 10:35:26,357 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 19, totalSize: 4 bytes
2017-02-22 10:35:28,422 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 24 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:28,423 DEBUG [FifoRpcScheduler.handler1-thread-25] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 8 bytes.
2017-02-22 10:35:28,423 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 24, totalSize: 4 bytes
2017-02-22 10:35:29,076 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 22 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:29,077 DEBUG [FifoRpcScheduler.handler4-thread-23] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 8 bytes.
2017-02-22 10:35:29,077 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 22, totalSize: 4 bytes
2017-02-22 10:35:29,364 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 20 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:29,365 DEBUG [FifoRpcScheduler.handler7-thread-21] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 8 bytes.
2017-02-22 10:35:29,365 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 20, totalSize: 4 bytes
2017-02-22 10:35:31,428 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 25 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:31,430 DEBUG [FifoRpcScheduler.handler1-thread-26] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 8 bytes.
2017-02-22 10:35:31,430 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 25, totalSize: 4 bytes
2017-02-22 10:35:32,078 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 23 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:32,079 DEBUG [FifoRpcScheduler.handler4-thread-24] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 8 bytes.
2017-02-22 10:35:32,079 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 23, totalSize: 4 bytes
2017-02-22 10:35:32,371 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 21 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:32,373 DEBUG [FifoRpcScheduler.handler7-thread-22] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 8 bytes.
2017-02-22 10:35:32,373 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 21, totalSize: 4 bytes
2017-02-22 10:35:34,432 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 26 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:34,433 DEBUG [FifoRpcScheduler.handler1-thread-27] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 8 bytes.
2017-02-22 10:35:34,433 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 26, totalSize: 4 bytes
2017-02-22 10:35:35,083 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 24 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:35,084 DEBUG [FifoRpcScheduler.handler4-thread-25] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 8 bytes.
2017-02-22 10:35:35,084 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 24, totalSize: 4 bytes
2017-02-22 10:35:35,378 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 22 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:35,379 DEBUG [FifoRpcScheduler.handler7-thread-23] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 8 bytes.
2017-02-22 10:35:35,379 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 22, totalSize: 4 bytes
2017-02-22 10:35:37,435 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 27 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:37,438 DEBUG [FifoRpcScheduler.handler1-thread-28] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 8 bytes.
2017-02-22 10:35:37,438 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 27, totalSize: 4 bytes
2017-02-22 10:35:38,010 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service MasterService, sasl=false
2017-02-22 10:35:38,011 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51895
2017-02-22 10:35:38,014 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:38,014 DEBUG [RpcServer.listener,port=51895] ipc.RpcServer$Listener(885): RpcServer.listener,port=51895: connection from 192.168.1.25:51942; # active connections: 2
2017-02-22 10:35:38,014 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: starting, connections 1
2017-02-22 10:35:38,015 DEBUG [RpcServer.reader=2,port=51895] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "MasterService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,018 DEBUG [FifoRpcScheduler.handler1-thread-29] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:35:38,018 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:35:38,034 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 1 method_name: "CreateTable" request_param: true priority: 0
2017-02-22 10:35:38,044 INFO  [FifoRpcScheduler.handler1-thread-30] master.HMaster(1887): Client=roger//192.168.1.25 create 'EqualTable', {NAME => 'columns', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}
2017-02-22 10:35:38,066 DEBUG [FifoRpcScheduler.handler1-thread-30] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/EqualTable/write-master:518950000000000
2017-02-22 10:35:38,067 DEBUG [FifoRpcScheduler.handler1-thread-30] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:35:38,067 DEBUG [FifoRpcScheduler.handler1-thread-30] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51897
2017-02-22 10:35:38,067 DEBUG [RpcServer.listener,port=51897] ipc.RpcServer$Listener(885): RpcServer.listener,port=51897: connection from 192.168.1.25:51943; # active connections: 1
2017-02-22 10:35:38,068 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: starting, connections 1
2017-02-22 10:35:38,068 DEBUG [FifoRpcScheduler.handler1-thread-30] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 33 method_name: "Scan" request_param: true
2017-02-22 10:35:38,080 DEBUG [RpcServer.reader=3,port=51897] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,082 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 16 bytes.
2017-02-22 10:35:38,082 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 33, totalSize: 12 bytes
2017-02-22 10:35:38,083 DEBUG [FifoRpcScheduler.handler1-thread-30] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 34 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,086 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 34 wrote 513 bytes.
2017-02-22 10:35:38,087 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 34 cell_block_meta { length: 488 }, totalSize: 509 bytes
2017-02-22 10:35:38,089 DEBUG [FifoRpcScheduler.handler1-thread-30] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 35 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,090 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 25 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:38,090 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 35 wrote 12 bytes.
2017-02-22 10:35:38,091 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 35, totalSize: 8 bytes
2017-02-22 10:35:38,092 DEBUG [FifoRpcScheduler.handler4-thread-26] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 8 bytes.
2017-02-22 10:35:38,092 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 25, totalSize: 4 bytes
2017-02-22 10:35:38,096 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.CreateTableHandler(165): Create table EqualTable
2017-02-22 10:35:38,098 DEBUG [FifoRpcScheduler.handler1-thread-30] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:35:38,098 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:35:38,101 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:35:38,102 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51897
2017-02-22 10:35:38,102 DEBUG [RpcServer.listener,port=51897] ipc.RpcServer$Listener(885): RpcServer.listener,port=51897: connection from 192.168.1.25:51944; # active connections: 2
2017-02-22 10:35:38,104 DEBUG [RpcServer.reader=4,port=51897] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,104 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: starting, connections 2
2017-02-22 10:35:38,105 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 16 bytes.
2017-02-22 10:35:38,106 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 2, totalSize: 12 bytes
2017-02-22 10:35:38,106 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true
2017-02-22 10:35:38,107 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,110 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 513 bytes.
2017-02-22 10:35:38,110 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 3 cell_block_meta { length: 488 }, totalSize: 509 bytes
2017-02-22 10:35:38,113 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 12 bytes.
2017-02-22 10:35:38,114 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 4, totalSize: 8 bytes
2017-02-22 10:35:38,114 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,120 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster1/root/.tmp/data/default/EqualTable/.tabledesc/.tableinfo.0000000001
2017-02-22 10:35:38,121 INFO  [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(4729): creating HRegion EqualTable HTD == 'EqualTable', {NAME => 'columns', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster1/root/.tmp Table name == EqualTable
2017-02-22 10:35:38,137 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(718): Instantiated EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:38,137 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1224): Closing EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.: disabling compactions & flushes
2017-02-22 10:35:38,137 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1251): Updates disabled for region EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:38,137 INFO  [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1340): Closed EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:38,142 DEBUG [htable-pool35-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 36 method_name: "Multi" request_param: true cell_block_meta { length: 139 } priority: 100
2017-02-22 10:35:38,142 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 36 wrote 18 bytes.
2017-02-22 10:35:38,142 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 36, totalSize: 14 bytes
2017-02-22 10:35:38,143 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:35:38,144 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,144 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] zookeeper.ZKAssign(175): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Async create of unassigned node b3578370bacd3c9a30ad3712c9fb8be2 with OFFLINE state
2017-02-22 10:35:38,145 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:38,146 DEBUG [main-EventThread] master.OfflineCallback(69): rs={b3578370bacd3c9a30ad3712c9fb8be2 state=OFFLINE, ts=1487756138144, server=null}, server=192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,146 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={b3578370bacd3c9a30ad3712c9fb8be2 state=OFFLINE, ts=1487756138144, server=null}, server=192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,151 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.AssignmentManager(1673): 192.168.1.25,51897,1487756057911 unassigned znodes=1 of total=1
2017-02-22 10:35:38,151 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.RegionStates(894): Transition {b3578370bacd3c9a30ad3712c9fb8be2 state=OFFLINE, ts=1487756138144, server=null} to {b3578370bacd3c9a30ad3712c9fb8be2 state=PENDING_OPEN, ts=1487756138151, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:38,151 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:35:38,152 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51897
2017-02-22 10:35:38,152 DEBUG [RpcServer.listener,port=51897] ipc.RpcServer$Listener(885): RpcServer.listener,port=51897: connection from 192.168.1.25:51945; # active connections: 3
2017-02-22 10:35:38,153 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: starting, connections 2
2017-02-22 10:35:38,153 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 37 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:35:38,153 DEBUG [RpcServer.reader=5,port=51897] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,154 INFO  [PriorityRpcServer.handler=9,queue=0,port=51897] regionserver.HRegionServer(4011): Open EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:38,157 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 37 wrote 10 bytes.
2017-02-22 10:35:38,157 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(832): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioning b3578370bacd3c9a30ad3712c9fb8be2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:35:38,157 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 37, totalSize: 6 bytes
2017-02-22 10:35:38,157 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,159 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:38,160 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(907): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioned node b3578370bacd3c9a30ad3712c9fb8be2 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:35:38,161 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] regionserver.HRegion(4915): Opening region: {ENCODED => b3578370bacd3c9a30ad3712c9fb8be2, NAME => 'EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:35:38,162 INFO  [RS_OPEN_REGION-192.168.1.25:51897-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:35:38,162 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table EqualTable b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:38,162 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51897,1487756057911, region=b3578370bacd3c9a30ad3712c9fb8be2, current_state={b3578370bacd3c9a30ad3712c9fb8be2 state=PENDING_OPEN, ts=1487756138151, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:38,163 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates(894): Transition {b3578370bacd3c9a30ad3712c9fb8be2 state=PENDING_OPEN, ts=1487756138151, server=192.168.1.25,51897,1487756057911} to {b3578370bacd3c9a30ad3712c9fb8be2 state=OPENING, ts=1487756138163, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:38,163 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] regionserver.HRegion(718): Instantiated EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:38,164 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/EqualTable/write-master:518950000000000
2017-02-22 10:35:38,164 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:35:38,165 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:35:38,172 INFO  [StoreOpener-b3578370bacd3c9a30ad3712c9fb8be2-1] hfile.CacheConfig(192): Created cacheConfig for columns: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:35:38,172 INFO  [StoreOpener-b3578370bacd3c9a30ad3712c9fb8be2-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:35:38,173 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster1/root/data/default/EqualTable/b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:38,173 INFO  [RS_OPEN_REGION-192.168.1.25:51897-0] regionserver.HRegion(826): Onlined b3578370bacd3c9a30ad3712c9fb8be2; next sequenceid=1
2017-02-22 10:35:38,173 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(644): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Attempting to retransition opening state of node b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:38,175 INFO  [PostOpenDeployTasks:b3578370bacd3c9a30ad3712c9fb8be2] regionserver.HRegionServer(1892): Post open deploy tasks for region=EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:38,176 DEBUG [htable-pool36-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 38 method_name: "Multi" request_param: true cell_block_meta { length: 332 } priority: 100
2017-02-22 10:35:38,177 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 38 wrote 18 bytes.
2017-02-22 10:35:38,177 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 38, totalSize: 14 bytes
2017-02-22 10:35:38,178 INFO  [PostOpenDeployTasks:b3578370bacd3c9a30ad3712c9fb8be2] catalog.MetaEditor(523): Updated row EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2. with server=192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,178 INFO  [PostOpenDeployTasks:b3578370bacd3c9a30ad3712c9fb8be2] regionserver.HRegionServer(1927): Finished post open deploy task for EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:38,179 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(832): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioning b3578370bacd3c9a30ad3712c9fb8be2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:35:38,181 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:38,181 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(907): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioned node b3578370bacd3c9a30ad3712c9fb8be2 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:35:38,181 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] handler.OpenRegionHandler(403): Transitioned b3578370bacd3c9a30ad3712c9fb8be2 to OPENED in zk on 192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,181 DEBUG [RS_OPEN_REGION-192.168.1.25:51897-0] handler.OpenRegionHandler(189): Opened EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2. on 192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,182 DEBUG [AM.ZK.Worker-pool2-t11] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51897,1487756057911, region=b3578370bacd3c9a30ad3712c9fb8be2, current_state={b3578370bacd3c9a30ad3712c9fb8be2 state=OPENING, ts=1487756138163, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:38,182 INFO  [AM.ZK.Worker-pool2-t11] master.RegionStates(894): Transition {b3578370bacd3c9a30ad3712c9fb8be2 state=OPENING, ts=1487756138163, server=192.168.1.25,51897,1487756057911} to {b3578370bacd3c9a30ad3712c9fb8be2 state=OPEN, ts=1487756138182, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:38,182 DEBUG [AM.ZK.Worker-pool2-t11] handler.OpenedRegionHandler(149): Handling OPENED of b3578370bacd3c9a30ad3712c9fb8be2 from 192.168.1.25,51897,1487756057911; deleting unassigned node
2017-02-22 10:35:38,184 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:38,184 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:38,184 DEBUG [AM.ZK.Worker-pool2-t11] zookeeper.ZKAssign(480): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Deleted unassigned node b3578370bacd3c9a30ad3712c9fb8be2 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:35:38,185 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager$4(1316): Znode EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2. deleted, state: {b3578370bacd3c9a30ad3712c9fb8be2 state=OPEN, ts=1487756138182, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:38,185 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates(397): Onlined b3578370bacd3c9a30ad3712c9fb8be2 on 192.168.1.25,51897,1487756057911
2017-02-22 10:35:38,219 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true
2017-02-22 10:35:38,220 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 16 bytes.
2017-02-22 10:35:38,220 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 5, totalSize: 12 bytes
2017-02-22 10:35:38,221 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,223 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 986 bytes.
2017-02-22 10:35:38,223 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 6 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:38,223 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,223 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 12 bytes.
2017-02-22 10:35:38,223 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 7, totalSize: 8 bytes
2017-02-22 10:35:38,224 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:35:38,226 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6ca0256d
2017-02-22 10:35:38,235 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:38,236 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd7820007 connected
2017-02-22 10:35:38,237 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd7820007, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:38,240 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true
2017-02-22 10:35:38,241 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 16 bytes.
2017-02-22 10:35:38,242 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 8, totalSize: 12 bytes
2017-02-22 10:35:38,242 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,243 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 986 bytes.
2017-02-22 10:35:38,244 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 9 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:38,244 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,244 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 12 bytes.
2017-02-22 10:35:38,244 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 10, totalSize: 8 bytes
2017-02-22 10:35:38,245 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6ca0256d
2017-02-22 10:35:38,253 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service MasterService, sasl=false
2017-02-22 10:35:38,254 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51909
2017-02-22 10:35:38,256 DEBUG [RpcServer.listener,port=51909] ipc.RpcServer$Listener(885): RpcServer.listener,port=51909: connection from 192.168.1.25:51947; # active connections: 2
2017-02-22 10:35:38,257 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: starting, connections 1
2017-02-22 10:35:38,257 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:38,257 DEBUG [RpcServer.reader=2,port=51909] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "MasterService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,258 DEBUG [FifoRpcScheduler.handler4-thread-27] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:35:38,258 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:35:38,259 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 1 method_name: "CreateTable" request_param: true priority: 0
2017-02-22 10:35:38,261 INFO  [FifoRpcScheduler.handler4-thread-28] master.HMaster(1887): Client=roger//192.168.1.25 create 'EqualTable', {NAME => 'columns', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}
2017-02-22 10:35:38,266 DEBUG [FifoRpcScheduler.handler4-thread-28] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/EqualTable/write-master:519090000000000
2017-02-22 10:35:38,267 DEBUG [FifoRpcScheduler.handler4-thread-28] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:35:38,268 DEBUG [FifoRpcScheduler.handler4-thread-28] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51911
2017-02-22 10:35:38,274 DEBUG [RpcServer.listener,port=51911] ipc.RpcServer$Listener(885): RpcServer.listener,port=51911: connection from 192.168.1.25:51948; # active connections: 1
2017-02-22 10:35:38,275 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: starting, connections 1
2017-02-22 10:35:38,275 DEBUG [FifoRpcScheduler.handler4-thread-28] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 33 method_name: "Scan" request_param: true
2017-02-22 10:35:38,275 DEBUG [RpcServer.reader=3,port=51911] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,276 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 16 bytes.
2017-02-22 10:35:38,276 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 33, totalSize: 12 bytes
2017-02-22 10:35:38,277 DEBUG [FifoRpcScheduler.handler4-thread-28] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 34 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,280 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 34 wrote 513 bytes.
2017-02-22 10:35:38,280 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 34 cell_block_meta { length: 488 }, totalSize: 509 bytes
2017-02-22 10:35:38,281 DEBUG [FifoRpcScheduler.handler4-thread-28] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 35 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,281 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 35 wrote 12 bytes.
2017-02-22 10:35:38,281 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 35, totalSize: 8 bytes
2017-02-22 10:35:38,285 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.CreateTableHandler(165): Create table EqualTable
2017-02-22 10:35:38,286 DEBUG [FifoRpcScheduler.handler4-thread-28] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:35:38,286 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:35:38,290 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:35:38,291 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51911
2017-02-22 10:35:38,293 DEBUG [RpcServer.listener,port=51911] ipc.RpcServer$Listener(885): RpcServer.listener,port=51911: connection from 192.168.1.25:51949; # active connections: 2
2017-02-22 10:35:38,294 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: starting, connections 2
2017-02-22 10:35:38,294 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true
2017-02-22 10:35:38,297 DEBUG [RpcServer.reader=4,port=51911] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,298 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 16 bytes.
2017-02-22 10:35:38,299 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 2, totalSize: 12 bytes
2017-02-22 10:35:38,299 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,302 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 513 bytes.
2017-02-22 10:35:38,302 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 3 cell_block_meta { length: 488 }, totalSize: 509 bytes
2017-02-22 10:35:38,302 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,303 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 12 bytes.
2017-02-22 10:35:38,303 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 4, totalSize: 8 bytes
2017-02-22 10:35:38,304 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster2/root/.tmp/data/default/EqualTable/.tabledesc/.tableinfo.0000000001
2017-02-22 10:35:38,329 INFO  [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(4729): creating HRegion EqualTable HTD == 'EqualTable', {NAME => 'columns', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster2/root/.tmp Table name == EqualTable
2017-02-22 10:35:38,347 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(718): Instantiated EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:38,347 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1224): Closing EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.: disabling compactions & flushes
2017-02-22 10:35:38,347 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1251): Updates disabled for region EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:38,348 INFO  [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1340): Closed EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:38,350 DEBUG [htable-pool39-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 36 method_name: "Multi" request_param: true cell_block_meta { length: 139 } priority: 100
2017-02-22 10:35:38,351 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 36 wrote 18 bytes.
2017-02-22 10:35:38,351 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 36, totalSize: 14 bytes
2017-02-22 10:35:38,351 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:35:38,352 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,352 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] zookeeper.ZKAssign(175): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Async create of unassigned node 91fd9027520ca204ce8bc389daf4ea08 with OFFLINE state
2017-02-22 10:35:38,353 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:38,354 DEBUG [main-EventThread] master.OfflineCallback(69): rs={91fd9027520ca204ce8bc389daf4ea08 state=OFFLINE, ts=1487756138352, server=null}, server=192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,355 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={91fd9027520ca204ce8bc389daf4ea08 state=OFFLINE, ts=1487756138352, server=null}, server=192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,359 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.AssignmentManager(1673): 192.168.1.25,51911,1487756065280 unassigned znodes=1 of total=1
2017-02-22 10:35:38,359 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.RegionStates(894): Transition {91fd9027520ca204ce8bc389daf4ea08 state=OFFLINE, ts=1487756138352, server=null} to {91fd9027520ca204ce8bc389daf4ea08 state=PENDING_OPEN, ts=1487756138359, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:38,359 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:35:38,360 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51911
2017-02-22 10:35:38,363 DEBUG [RpcServer.listener,port=51911] ipc.RpcServer$Listener(885): RpcServer.listener,port=51911: connection from 192.168.1.25:51950; # active connections: 3
2017-02-22 10:35:38,363 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: starting, connections 2
2017-02-22 10:35:38,364 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 37 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:35:38,364 DEBUG [RpcServer.reader=5,port=51911] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,365 INFO  [PriorityRpcServer.handler=9,queue=0,port=51911] regionserver.HRegionServer(4011): Open EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:38,367 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 37 wrote 10 bytes.
2017-02-22 10:35:38,367 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(832): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioning 91fd9027520ca204ce8bc389daf4ea08 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:35:38,367 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 37, totalSize: 6 bytes
2017-02-22 10:35:38,367 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,369 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:38,369 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(907): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioned node 91fd9027520ca204ce8bc389daf4ea08 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:35:38,370 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] regionserver.HRegion(4915): Opening region: {ENCODED => 91fd9027520ca204ce8bc389daf4ea08, NAME => 'EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:35:38,372 INFO  [RS_OPEN_REGION-192.168.1.25:51911-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:35:38,372 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table EqualTable 91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:38,373 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] regionserver.HRegion(718): Instantiated EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:38,373 DEBUG [AM.ZK.Worker-pool13-t10] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51911,1487756065280, region=91fd9027520ca204ce8bc389daf4ea08, current_state={91fd9027520ca204ce8bc389daf4ea08 state=PENDING_OPEN, ts=1487756138359, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:38,373 INFO  [AM.ZK.Worker-pool13-t10] master.RegionStates(894): Transition {91fd9027520ca204ce8bc389daf4ea08 state=PENDING_OPEN, ts=1487756138359, server=192.168.1.25,51911,1487756065280} to {91fd9027520ca204ce8bc389daf4ea08 state=OPENING, ts=1487756138373, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:38,374 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/EqualTable/write-master:519090000000000
2017-02-22 10:35:38,374 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:35:38,375 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:35:38,381 INFO  [StoreOpener-91fd9027520ca204ce8bc389daf4ea08-1] hfile.CacheConfig(192): Created cacheConfig for columns: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:35:38,381 INFO  [StoreOpener-91fd9027520ca204ce8bc389daf4ea08-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:35:38,382 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster2/root/data/default/EqualTable/91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:38,382 INFO  [RS_OPEN_REGION-192.168.1.25:51911-0] regionserver.HRegion(826): Onlined 91fd9027520ca204ce8bc389daf4ea08; next sequenceid=1
2017-02-22 10:35:38,382 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(644): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Attempting to retransition opening state of node 91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:38,383 INFO  [PostOpenDeployTasks:91fd9027520ca204ce8bc389daf4ea08] regionserver.HRegionServer(1892): Post open deploy tasks for region=EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:38,384 DEBUG [htable-pool40-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 38 method_name: "Multi" request_param: true cell_block_meta { length: 332 } priority: 100
2017-02-22 10:35:38,384 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 23 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:38,385 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 38 wrote 18 bytes.
2017-02-22 10:35:38,385 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 38, totalSize: 14 bytes
2017-02-22 10:35:38,385 DEBUG [FifoRpcScheduler.handler7-thread-24] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 8 bytes.
2017-02-22 10:35:38,386 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 23, totalSize: 4 bytes
2017-02-22 10:35:38,386 INFO  [PostOpenDeployTasks:91fd9027520ca204ce8bc389daf4ea08] catalog.MetaEditor(523): Updated row EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08. with server=192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,386 INFO  [PostOpenDeployTasks:91fd9027520ca204ce8bc389daf4ea08] regionserver.HRegionServer(1927): Finished post open deploy task for EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:38,386 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(832): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioning 91fd9027520ca204ce8bc389daf4ea08 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:35:38,390 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:38,390 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(907): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioned node 91fd9027520ca204ce8bc389daf4ea08 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:35:38,390 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] handler.OpenRegionHandler(403): Transitioned 91fd9027520ca204ce8bc389daf4ea08 to OPENED in zk on 192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,390 DEBUG [RS_OPEN_REGION-192.168.1.25:51911-0] handler.OpenRegionHandler(189): Opened EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08. on 192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,391 DEBUG [AM.ZK.Worker-pool13-t11] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51911,1487756065280, region=91fd9027520ca204ce8bc389daf4ea08, current_state={91fd9027520ca204ce8bc389daf4ea08 state=OPENING, ts=1487756138373, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:38,391 INFO  [AM.ZK.Worker-pool13-t11] master.RegionStates(894): Transition {91fd9027520ca204ce8bc389daf4ea08 state=OPENING, ts=1487756138373, server=192.168.1.25,51911,1487756065280} to {91fd9027520ca204ce8bc389daf4ea08 state=OPEN, ts=1487756138391, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:38,391 DEBUG [AM.ZK.Worker-pool13-t11] handler.OpenedRegionHandler(149): Handling OPENED of 91fd9027520ca204ce8bc389daf4ea08 from 192.168.1.25,51911,1487756065280; deleting unassigned node
2017-02-22 10:35:38,393 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:38,393 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:38,393 DEBUG [AM.ZK.Worker-pool13-t11] zookeeper.ZKAssign(480): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Deleted unassigned node 91fd9027520ca204ce8bc389daf4ea08 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:35:38,394 DEBUG [AM.ZK.Worker-pool13-t13] master.AssignmentManager$4(1316): Znode EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08. deleted, state: {91fd9027520ca204ce8bc389daf4ea08 state=OPEN, ts=1487756138391, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:38,394 INFO  [AM.ZK.Worker-pool13-t13] master.RegionStates(397): Onlined 91fd9027520ca204ce8bc389daf4ea08 on 192.168.1.25,51911,1487756065280
2017-02-22 10:35:38,408 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true
2017-02-22 10:35:38,409 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 16 bytes.
2017-02-22 10:35:38,409 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 5, totalSize: 12 bytes
2017-02-22 10:35:38,409 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,412 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 986 bytes.
2017-02-22 10:35:38,412 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 6 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:38,412 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,412 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 12 bytes.
2017-02-22 10:35:38,412 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 7, totalSize: 8 bytes
2017-02-22 10:35:38,413 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:35:38,414 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3ce3db41
2017-02-22 10:35:38,419 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:38,421 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a60007 connected
2017-02-22 10:35:38,423 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a60007, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:38,424 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true
2017-02-22 10:35:38,424 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 16 bytes.
2017-02-22 10:35:38,425 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 8, totalSize: 12 bytes
2017-02-22 10:35:38,425 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,426 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 986 bytes.
2017-02-22 10:35:38,427 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 9 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:38,427 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,428 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 12 bytes.
2017-02-22 10:35:38,428 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 10, totalSize: 8 bytes
2017-02-22 10:35:38,429 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3ce3db41
2017-02-22 10:35:38,434 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service MasterService, sasl=false
2017-02-22 10:35:38,434 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51923
2017-02-22 10:35:38,440 DEBUG [RpcServer.listener,port=51923] ipc.RpcServer$Listener(885): RpcServer.listener,port=51923: connection from 192.168.1.25:51952; # active connections: 2
2017-02-22 10:35:38,440 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: starting, connections 1
2017-02-22 10:35:38,440 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:38,441 DEBUG [RpcServer.reader=2,port=51923] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "MasterService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,441 DEBUG [FifoRpcScheduler.handler7-thread-25] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:35:38,441 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:35:38,442 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 1 method_name: "CreateTable" request_param: true priority: 0
2017-02-22 10:35:38,444 INFO  [FifoRpcScheduler.handler7-thread-26] master.HMaster(1887): Client=roger//192.168.1.25 create 'EqualTable', {NAME => 'columns', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}
2017-02-22 10:35:38,448 DEBUG [FifoRpcScheduler.handler7-thread-26] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/EqualTable/write-master:519230000000000
2017-02-22 10:35:38,449 DEBUG [FifoRpcScheduler.handler7-thread-26] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:35:38,450 DEBUG [FifoRpcScheduler.handler7-thread-26] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51925
2017-02-22 10:35:38,454 DEBUG [RpcServer.listener,port=51925] ipc.RpcServer$Listener(885): RpcServer.listener,port=51925: connection from 192.168.1.25:51953; # active connections: 1
2017-02-22 10:35:38,455 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: starting, connections 1
2017-02-22 10:35:38,455 DEBUG [FifoRpcScheduler.handler7-thread-26] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 33 method_name: "Scan" request_param: true
2017-02-22 10:35:38,456 DEBUG [RpcServer.reader=3,port=51925] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,456 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 16 bytes.
2017-02-22 10:35:38,456 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 33, totalSize: 12 bytes
2017-02-22 10:35:38,457 DEBUG [FifoRpcScheduler.handler7-thread-26] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 34 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,460 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 34 wrote 513 bytes.
2017-02-22 10:35:38,461 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 34 cell_block_meta { length: 488 }, totalSize: 509 bytes
2017-02-22 10:35:38,461 DEBUG [FifoRpcScheduler.handler7-thread-26] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 35 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,462 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 35 wrote 12 bytes.
2017-02-22 10:35:38,462 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 35, totalSize: 8 bytes
2017-02-22 10:35:38,465 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.CreateTableHandler(165): Create table EqualTable
2017-02-22 10:35:38,465 DEBUG [FifoRpcScheduler.handler7-thread-26] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:35:38,465 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:35:38,466 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:35:38,467 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51925
2017-02-22 10:35:38,469 DEBUG [RpcServer.listener,port=51925] ipc.RpcServer$Listener(885): RpcServer.listener,port=51925: connection from 192.168.1.25:51954; # active connections: 2
2017-02-22 10:35:38,469 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: starting, connections 2
2017-02-22 10:35:38,469 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true
2017-02-22 10:35:38,471 DEBUG [RpcServer.reader=4,port=51925] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,473 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 16 bytes.
2017-02-22 10:35:38,474 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 2, totalSize: 12 bytes
2017-02-22 10:35:38,474 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,476 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 513 bytes.
2017-02-22 10:35:38,478 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 3 cell_block_meta { length: 488 }, totalSize: 509 bytes
2017-02-22 10:35:38,479 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,479 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 12 bytes.
2017-02-22 10:35:38,479 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 4, totalSize: 8 bytes
2017-02-22 10:35:38,483 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster3/root/.tmp/data/default/EqualTable/.tabledesc/.tableinfo.0000000001
2017-02-22 10:35:38,484 INFO  [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(4729): creating HRegion EqualTable HTD == 'EqualTable', {NAME => 'columns', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster3/root/.tmp Table name == EqualTable
2017-02-22 10:35:38,496 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(718): Instantiated EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:38,497 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1224): Closing EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.: disabling compactions & flushes
2017-02-22 10:35:38,497 DEBUG [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1251): Updates disabled for region EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:38,497 INFO  [RegionOpenAndInitThread-EqualTable-1] regionserver.HRegion(1340): Closed EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:38,499 DEBUG [htable-pool43-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 36 method_name: "Multi" request_param: true cell_block_meta { length: 139 } priority: 100
2017-02-22 10:35:38,500 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 36 wrote 18 bytes.
2017-02-22 10:35:38,500 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 36, totalSize: 14 bytes
2017-02-22 10:35:38,500 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:35:38,501 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,501 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] zookeeper.ZKAssign(175): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Async create of unassigned node f182bbd36f0e1d9b9a564e9ea56ce8b1 with OFFLINE state
2017-02-22 10:35:38,502 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:38,503 DEBUG [main-EventThread] master.OfflineCallback(69): rs={f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OFFLINE, ts=1487756138501, server=null}, server=192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,503 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OFFLINE, ts=1487756138501, server=null}, server=192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,507 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.AssignmentManager(1673): 192.168.1.25,51925,1487756071702 unassigned znodes=1 of total=1
2017-02-22 10:35:38,508 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.RegionStates(894): Transition {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OFFLINE, ts=1487756138501, server=null} to {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=PENDING_OPEN, ts=1487756138508, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:38,508 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:35:38,511 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51925
2017-02-22 10:35:38,514 DEBUG [RpcServer.listener,port=51925] ipc.RpcServer$Listener(885): RpcServer.listener,port=51925: connection from 192.168.1.25:51955; # active connections: 3
2017-02-22 10:35:38,515 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: starting, connections 2
2017-02-22 10:35:38,515 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 37 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:35:38,515 DEBUG [RpcServer.reader=5,port=51925] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:35:38,515 INFO  [PriorityRpcServer.handler=9,queue=0,port=51925] regionserver.HRegionServer(4011): Open EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:38,518 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 37 wrote 10 bytes.
2017-02-22 10:35:38,518 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(832): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioning f182bbd36f0e1d9b9a564e9ea56ce8b1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:35:38,518 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 37, totalSize: 6 bytes
2017-02-22 10:35:38,518 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,520 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(907): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioned node f182bbd36f0e1d9b9a564e9ea56ce8b1 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:35:38,520 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:38,520 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] regionserver.HRegion(4915): Opening region: {ENCODED => f182bbd36f0e1d9b9a564e9ea56ce8b1, NAME => 'EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:35:38,521 INFO  [RS_OPEN_REGION-192.168.1.25:51925-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:35:38,521 DEBUG [AM.ZK.Worker-pool24-t10] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,51925,1487756071702, region=f182bbd36f0e1d9b9a564e9ea56ce8b1, current_state={f182bbd36f0e1d9b9a564e9ea56ce8b1 state=PENDING_OPEN, ts=1487756138508, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:38,521 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table EqualTable f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:38,521 INFO  [AM.ZK.Worker-pool24-t10] master.RegionStates(894): Transition {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=PENDING_OPEN, ts=1487756138508, server=192.168.1.25,51925,1487756071702} to {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OPENING, ts=1487756138521, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:38,521 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] regionserver.HRegion(718): Instantiated EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:38,522 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/EqualTable/write-master:519230000000000
2017-02-22 10:35:38,522 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:35:38,524 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:35:38,531 INFO  [StoreOpener-f182bbd36f0e1d9b9a564e9ea56ce8b1-1] hfile.CacheConfig(192): Created cacheConfig for columns: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:35:38,531 INFO  [StoreOpener-f182bbd36f0e1d9b9a564e9ea56ce8b1-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:35:38,532 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster3/root/data/default/EqualTable/f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:38,532 INFO  [RS_OPEN_REGION-192.168.1.25:51925-0] regionserver.HRegion(826): Onlined f182bbd36f0e1d9b9a564e9ea56ce8b1; next sequenceid=1
2017-02-22 10:35:38,532 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(644): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Attempting to retransition opening state of node f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:38,533 INFO  [PostOpenDeployTasks:f182bbd36f0e1d9b9a564e9ea56ce8b1] regionserver.HRegionServer(1892): Post open deploy tasks for region=EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:38,538 DEBUG [htable-pool44-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 38 method_name: "Multi" request_param: true cell_block_meta { length: 332 } priority: 100
2017-02-22 10:35:38,539 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 38 wrote 18 bytes.
2017-02-22 10:35:38,540 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 38, totalSize: 14 bytes
2017-02-22 10:35:38,540 INFO  [PostOpenDeployTasks:f182bbd36f0e1d9b9a564e9ea56ce8b1] catalog.MetaEditor(523): Updated row EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1. with server=192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,540 INFO  [PostOpenDeployTasks:f182bbd36f0e1d9b9a564e9ea56ce8b1] regionserver.HRegionServer(1927): Finished post open deploy task for EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:38,541 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(832): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioning f182bbd36f0e1d9b9a564e9ea56ce8b1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:35:38,543 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:38,543 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(907): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioned node f182bbd36f0e1d9b9a564e9ea56ce8b1 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:35:38,543 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] handler.OpenRegionHandler(403): Transitioned f182bbd36f0e1d9b9a564e9ea56ce8b1 to OPENED in zk on 192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,543 DEBUG [RS_OPEN_REGION-192.168.1.25:51925-0] handler.OpenRegionHandler(189): Opened EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1. on 192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,543 DEBUG [AM.ZK.Worker-pool24-t11] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,51925,1487756071702, region=f182bbd36f0e1d9b9a564e9ea56ce8b1, current_state={f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OPENING, ts=1487756138521, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:38,543 INFO  [AM.ZK.Worker-pool24-t11] master.RegionStates(894): Transition {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OPENING, ts=1487756138521, server=192.168.1.25,51925,1487756071702} to {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OPEN, ts=1487756138543, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:38,544 DEBUG [AM.ZK.Worker-pool24-t11] handler.OpenedRegionHandler(149): Handling OPENED of f182bbd36f0e1d9b9a564e9ea56ce8b1 from 192.168.1.25,51925,1487756071702; deleting unassigned node
2017-02-22 10:35:38,545 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:38,545 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:38,545 DEBUG [AM.ZK.Worker-pool24-t11] zookeeper.ZKAssign(480): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Deleted unassigned node f182bbd36f0e1d9b9a564e9ea56ce8b1 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:35:38,545 DEBUG [AM.ZK.Worker-pool24-t13] master.AssignmentManager$4(1316): Znode EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1. deleted, state: {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OPEN, ts=1487756138543, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:38,546 INFO  [AM.ZK.Worker-pool24-t13] master.RegionStates(397): Onlined f182bbd36f0e1d9b9a564e9ea56ce8b1 on 192.168.1.25,51925,1487756071702
2017-02-22 10:35:38,584 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true
2017-02-22 10:35:38,588 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 16 bytes.
2017-02-22 10:35:38,589 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 5, totalSize: 12 bytes
2017-02-22 10:35:38,594 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,602 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 986 bytes.
2017-02-22 10:35:38,602 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 6 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:38,606 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,609 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 12 bytes.
2017-02-22 10:35:38,610 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 7, totalSize: 8 bytes
2017-02-22 10:35:38,612 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:35:38,614 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2c3dec30
2017-02-22 10:35:38,633 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:38,638 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db0007 connected
2017-02-22 10:35:38,639 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db0007, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:38,644 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true
2017-02-22 10:35:38,646 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 16 bytes.
2017-02-22 10:35:38,646 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 8, totalSize: 12 bytes
2017-02-22 10:35:38,646 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,650 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 986 bytes.
2017-02-22 10:35:38,650 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 9 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:38,651 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,652 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 12 bytes.
2017-02-22 10:35:38,653 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 10, totalSize: 8 bytes
2017-02-22 10:35:38,654 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2c3dec30
2017-02-22 10:35:38,674 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 11 method_name: "Get" request_param: true
2017-02-22 10:35:38,677 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 464 bytes.
2017-02-22 10:35:38,678 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 11, totalSize: 460 bytes
2017-02-22 10:35:38,679 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,681 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 982 bytes.
2017-02-22 10:35:38,682 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 12 cell_block_meta { length: 959 }, totalSize: 978 bytes
2017-02-22 10:35:38,682 DEBUG [main] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:35:38,695 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 13 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,699 DEBUG [B.DefaultRpcServer.handler=5,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:35:38,699 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:35:38,700 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 11 method_name: "Get" request_param: true
2017-02-22 10:35:38,702 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 464 bytes.
2017-02-22 10:35:38,703 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 11, totalSize: 460 bytes
2017-02-22 10:35:38,704 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,709 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 982 bytes.
2017-02-22 10:35:38,709 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 12 cell_block_meta { length: 959 }, totalSize: 978 bytes
2017-02-22 10:35:38,710 DEBUG [main] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:35:38,728 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 13 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,729 DEBUG [B.DefaultRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:35:38,730 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:35:38,731 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 11 method_name: "Get" request_param: true
2017-02-22 10:35:38,733 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 464 bytes.
2017-02-22 10:35:38,734 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 11, totalSize: 460 bytes
2017-02-22 10:35:38,736 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:38,741 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 982 bytes.
2017-02-22 10:35:38,742 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 12 cell_block_meta { length: 959 }, totalSize: 978 bytes
2017-02-22 10:35:38,742 DEBUG [main] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:35:38,760 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 13 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,765 DEBUG [B.DefaultRpcServer.handler=1,queue=1,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:35:38,765 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:35:38,768 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 14 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,781 DEBUG [B.DefaultRpcServer.handler=1,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 18 bytes.
2017-02-22 10:35:38,781 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 14, totalSize: 14 bytes
2017-02-22 10:35:38,784 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 14 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,796 DEBUG [B.DefaultRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 18 bytes.
2017-02-22 10:35:38,797 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 14, totalSize: 14 bytes
2017-02-22 10:35:38,799 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 14 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,809 DEBUG [B.DefaultRpcServer.handler=2,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 18 bytes.
2017-02-22 10:35:38,809 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 14, totalSize: 14 bytes
2017-02-22 10:35:38,813 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 15 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,815 DEBUG [B.DefaultRpcServer.handler=4,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 18 bytes.
2017-02-22 10:35:38,815 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 15, totalSize: 14 bytes
2017-02-22 10:35:38,816 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 15 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,818 DEBUG [B.DefaultRpcServer.handler=1,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 18 bytes.
2017-02-22 10:35:38,818 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 15, totalSize: 14 bytes
2017-02-22 10:35:38,821 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 15 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,824 DEBUG [B.DefaultRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 18 bytes.
2017-02-22 10:35:38,824 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 15, totalSize: 14 bytes
2017-02-22 10:35:38,826 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 16 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,830 DEBUG [B.DefaultRpcServer.handler=7,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 18 bytes.
2017-02-22 10:35:38,830 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 16, totalSize: 14 bytes
2017-02-22 10:35:38,832 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 16 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,834 DEBUG [B.DefaultRpcServer.handler=4,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 18 bytes.
2017-02-22 10:35:38,835 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 16, totalSize: 14 bytes
2017-02-22 10:35:38,836 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 16 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,839 DEBUG [B.DefaultRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 18 bytes.
2017-02-22 10:35:38,839 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 16, totalSize: 14 bytes
2017-02-22 10:35:38,841 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 17 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,843 DEBUG [B.DefaultRpcServer.handler=10,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 18 bytes.
2017-02-22 10:35:38,845 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 17, totalSize: 14 bytes
2017-02-22 10:35:38,847 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 17 method_name: "Multi" request_param: true cell_block_meta { length: 90 } priority: 0
2017-02-22 10:35:38,851 DEBUG [B.DefaultRpcServer.handler=2,queue=2,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 18 bytes.
2017-02-22 10:35:38,854 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 17, totalSize: 14 bytes
2017-02-22 10:35:38,856 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 17 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,859 DEBUG [B.DefaultRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 18 bytes.
2017-02-22 10:35:38,859 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 17, totalSize: 14 bytes
2017-02-22 10:35:38,862 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 18 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,865 DEBUG [B.DefaultRpcServer.handler=8,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 18 bytes.
2017-02-22 10:35:38,866 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 18, totalSize: 14 bytes
2017-02-22 10:35:38,867 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 18 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,871 DEBUG [B.DefaultRpcServer.handler=5,queue=2,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 18 bytes.
2017-02-22 10:35:38,871 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 18, totalSize: 14 bytes
2017-02-22 10:35:38,873 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 18 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,875 DEBUG [B.DefaultRpcServer.handler=5,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 18 bytes.
2017-02-22 10:35:38,875 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 18, totalSize: 14 bytes
2017-02-22 10:35:38,877 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 19 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,880 DEBUG [B.DefaultRpcServer.handler=11,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 18 bytes.
2017-02-22 10:35:38,881 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 19, totalSize: 14 bytes
2017-02-22 10:35:38,884 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 19 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,890 DEBUG [B.DefaultRpcServer.handler=8,queue=2,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 18 bytes.
2017-02-22 10:35:38,890 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 19, totalSize: 14 bytes
2017-02-22 10:35:38,891 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 19 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,894 DEBUG [B.DefaultRpcServer.handler=8,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 18 bytes.
2017-02-22 10:35:38,895 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 19, totalSize: 14 bytes
2017-02-22 10:35:38,897 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 20 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,901 DEBUG [B.DefaultRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 18 bytes.
2017-02-22 10:35:38,902 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 20, totalSize: 14 bytes
2017-02-22 10:35:38,903 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 20 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,905 DEBUG [B.DefaultRpcServer.handler=7,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 18 bytes.
2017-02-22 10:35:38,906 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 20, totalSize: 14 bytes
2017-02-22 10:35:38,909 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 20 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,914 DEBUG [B.DefaultRpcServer.handler=12,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 18 bytes.
2017-02-22 10:35:38,914 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 20, totalSize: 14 bytes
2017-02-22 10:35:38,919 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 21 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,924 DEBUG [B.DefaultRpcServer.handler=14,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 18 bytes.
2017-02-22 10:35:38,925 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 21, totalSize: 14 bytes
2017-02-22 10:35:38,926 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 21 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,928 DEBUG [B.DefaultRpcServer.handler=10,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 18 bytes.
2017-02-22 10:35:38,929 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 21, totalSize: 14 bytes
2017-02-22 10:35:38,930 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 21 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,932 DEBUG [B.DefaultRpcServer.handler=11,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 18 bytes.
2017-02-22 10:35:38,932 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 21, totalSize: 14 bytes
2017-02-22 10:35:38,936 DEBUG [htable-pool46-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 22 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,940 DEBUG [B.DefaultRpcServer.handler=13,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 18 bytes.
2017-02-22 10:35:38,941 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 22, totalSize: 14 bytes
2017-02-22 10:35:38,943 DEBUG [htable-pool47-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 22 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,944 DEBUG [B.DefaultRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 18 bytes.
2017-02-22 10:35:38,945 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 22, totalSize: 14 bytes
2017-02-22 10:35:38,945 DEBUG [htable-pool48-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 22 method_name: "Multi" request_param: true cell_block_meta { length: 91 } priority: 0
2017-02-22 10:35:38,947 DEBUG [B.DefaultRpcServer.handler=15,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 18 bytes.
2017-02-22 10:35:38,947 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 22, totalSize: 14 bytes
2017-02-22 10:35:38,957 DEBUG [Thread-285] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 23 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:38,957 DEBUG [Thread-286] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 23 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:38,957 DEBUG [Thread-284] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 23 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,153 DEBUG [B.DefaultRpcServer.handler=11,queue=2,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 91 bytes.
2017-02-22 10:35:39,153 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 23, totalSize: 87 bytes
2017-02-22 10:35:39,157 DEBUG [B.DefaultRpcServer.handler=14,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 91 bytes.
2017-02-22 10:35:39,157 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 23, totalSize: 87 bytes
2017-02-22 10:35:39,157 DEBUG [B.DefaultRpcServer.handler=16,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 91 bytes.
2017-02-22 10:35:39,157 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 23, totalSize: 87 bytes
2017-02-22 10:35:39,161 DEBUG [Thread-288] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 24 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,162 DEBUG [Thread-289] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 24 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,162 DEBUG [Thread-287] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 24 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,347 DEBUG [B.DefaultRpcServer.handler=18,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 91 bytes.
2017-02-22 10:35:39,347 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 24, totalSize: 87 bytes
2017-02-22 10:35:39,348 DEBUG [B.DefaultRpcServer.handler=14,queue=2,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 91 bytes.
2017-02-22 10:35:39,348 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 24, totalSize: 87 bytes
2017-02-22 10:35:39,351 DEBUG [B.DefaultRpcServer.handler=19,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 91 bytes.
2017-02-22 10:35:39,351 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 24, totalSize: 87 bytes
2017-02-22 10:35:39,352 DEBUG [Thread-291] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,352 DEBUG [Thread-290] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,352 DEBUG [Thread-292] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,644 DEBUG [B.DefaultRpcServer.handler=21,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 91 bytes.
2017-02-22 10:35:39,645 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 25, totalSize: 87 bytes
2017-02-22 10:35:39,645 DEBUG [B.DefaultRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 91 bytes.
2017-02-22 10:35:39,645 DEBUG [B.DefaultRpcServer.handler=13,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 91 bytes.
2017-02-22 10:35:39,647 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 25, totalSize: 87 bytes
2017-02-22 10:35:39,647 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 25, totalSize: 87 bytes
2017-02-22 10:35:39,654 DEBUG [Thread-293] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 26 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,654 DEBUG [Thread-294] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 26 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,654 DEBUG [Thread-295] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 26 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,991 DEBUG [B.DefaultRpcServer.handler=24,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 91 bytes.
2017-02-22 10:35:39,991 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 26, totalSize: 87 bytes
2017-02-22 10:35:39,993 DEBUG [B.DefaultRpcServer.handler=16,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 91 bytes.
2017-02-22 10:35:39,993 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 26, totalSize: 87 bytes
2017-02-22 10:35:39,995 DEBUG [B.DefaultRpcServer.handler=17,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 91 bytes.
2017-02-22 10:35:39,995 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 26, totalSize: 87 bytes
2017-02-22 10:35:39,997 DEBUG [Thread-297] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 27 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,997 DEBUG [Thread-298] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 27 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:39,997 DEBUG [Thread-296] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 27 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:40,371 DEBUG [B.DefaultRpcServer.handler=17,queue=2,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 90 bytes.
2017-02-22 10:35:40,371 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 27, totalSize: 86 bytes
2017-02-22 10:35:40,372 DEBUG [B.DefaultRpcServer.handler=20,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 91 bytes.
2017-02-22 10:35:40,373 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 27, totalSize: 87 bytes
2017-02-22 10:35:40,373 DEBUG [B.DefaultRpcServer.handler=17,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 91 bytes.
2017-02-22 10:35:40,373 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 27, totalSize: 87 bytes
2017-02-22 10:35:40,374 DEBUG [Thread-299] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:40,374 DEBUG [Thread-301] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:40,374 DEBUG [Thread-300] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:40,441 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 28 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:40,442 DEBUG [FifoRpcScheduler.handler1-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 8 bytes.
2017-02-22 10:35:40,442 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 28, totalSize: 4 bytes
2017-02-22 10:35:40,778 DEBUG [B.DefaultRpcServer.handler=23,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 91 bytes.
2017-02-22 10:35:40,778 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 28, totalSize: 87 bytes
2017-02-22 10:35:40,779 DEBUG [B.DefaultRpcServer.handler=19,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 91 bytes.
2017-02-22 10:35:40,779 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 28, totalSize: 87 bytes
2017-02-22 10:35:40,779 DEBUG [B.DefaultRpcServer.handler=20,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 91 bytes.
2017-02-22 10:35:40,779 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 28, totalSize: 87 bytes
2017-02-22 10:35:40,780 DEBUG [Thread-303] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 29 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:40,780 DEBUG [Thread-302] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 29 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:40,780 DEBUG [Thread-304] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 29 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:41,102 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 26 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:41,103 DEBUG [FifoRpcScheduler.handler4-thread-29] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 8 bytes.
2017-02-22 10:35:41,103 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 26, totalSize: 4 bytes
2017-02-22 10:35:41,397 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 24 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:41,398 DEBUG [FifoRpcScheduler.handler7-thread-27] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 8 bytes.
2017-02-22 10:35:41,399 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 24, totalSize: 4 bytes
2017-02-22 10:35:41,635 DEBUG [B.DefaultRpcServer.handler=22,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 91 bytes.
2017-02-22 10:35:41,635 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 29, totalSize: 87 bytes
2017-02-22 10:35:41,641 DEBUG [B.DefaultRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 91 bytes.
2017-02-22 10:35:41,642 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 29, totalSize: 87 bytes
2017-02-22 10:35:41,642 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 29, totalSize: 87 bytes
2017-02-22 10:35:41,641 DEBUG [B.DefaultRpcServer.handler=23,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 91 bytes.
2017-02-22 10:35:41,644 DEBUG [Thread-305] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 30 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:41,644 DEBUG [Thread-306] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 30 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:41,644 DEBUG [Thread-307] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 30 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:42,481 DEBUG [B.DefaultRpcServer.handler=27,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 91 bytes.
2017-02-22 10:35:42,481 DEBUG [B.DefaultRpcServer.handler=25,queue=1,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 91 bytes.
2017-02-22 10:35:42,482 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 30, totalSize: 87 bytes
2017-02-22 10:35:42,482 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 30, totalSize: 87 bytes
2017-02-22 10:35:42,482 DEBUG [B.DefaultRpcServer.handler=26,queue=2,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 91 bytes.
2017-02-22 10:35:42,485 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 30, totalSize: 87 bytes
2017-02-22 10:35:42,489 DEBUG [Thread-309] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 31 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:42,489 DEBUG [Thread-310] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 31 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:42,489 DEBUG [Thread-308] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 31 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:43,078 DEBUG [B.DefaultRpcServer.handler=12,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 91 bytes.
2017-02-22 10:35:43,079 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 31, totalSize: 87 bytes
2017-02-22 10:35:43,079 DEBUG [B.DefaultRpcServer.handler=22,queue=1,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 91 bytes.
2017-02-22 10:35:43,079 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 31, totalSize: 87 bytes
2017-02-22 10:35:43,085 DEBUG [B.DefaultRpcServer.handler=26,queue=2,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 91 bytes.
2017-02-22 10:35:43,085 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 31, totalSize: 87 bytes
2017-02-22 10:35:43,088 DEBUG [Thread-312] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 32 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:43,088 DEBUG [Thread-313] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 32 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:43,088 DEBUG [Thread-311] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 32 method_name: "Get" request_param: true priority: 0
2017-02-22 10:35:43,445 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 29 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:43,446 DEBUG [FifoRpcScheduler.handler1-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 8 bytes.
2017-02-22 10:35:43,446 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 29, totalSize: 4 bytes
2017-02-22 10:35:43,972 DEBUG [B.DefaultRpcServer.handler=4,queue=1,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 12 bytes.
2017-02-22 10:35:43,972 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 32, totalSize: 8 bytes
2017-02-22 10:35:43,972 DEBUG [B.DefaultRpcServer.handler=15,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 12 bytes.
2017-02-22 10:35:43,972 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 32, totalSize: 8 bytes
2017-02-22 10:35:43,974 DEBUG [B.DefaultRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 12 bytes.
2017-02-22 10:35:43,974 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 32, totalSize: 8 bytes
2017-02-22 10:35:43,975 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 33 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:43,975 DEBUG [FifoRpcScheduler.handler1-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 10 bytes.
2017-02-22 10:35:43,975 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 33, totalSize: 6 bytes
2017-02-22 10:35:43,982 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 34 method_name: "GetTableDescriptors" request_param: true priority: 0
2017-02-22 10:35:43,983 DEBUG [FifoRpcScheduler.handler1-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 34 wrote 301 bytes.
2017-02-22 10:35:43,983 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 34, totalSize: 297 bytes
2017-02-22 10:35:43,984 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:35:43,985 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@533377b
2017-02-22 10:35:43,992 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:43,993 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd7820008 connected
2017-02-22 10:35:43,994 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd7820008, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:43,995 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 35 method_name: "Scan" request_param: true
2017-02-22 10:35:43,996 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 35 wrote 16 bytes.
2017-02-22 10:35:43,996 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 35, totalSize: 12 bytes
2017-02-22 10:35:43,996 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 36 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:43,998 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 36 wrote 986 bytes.
2017-02-22 10:35:43,998 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 36 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:43,998 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 37 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:43,998 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 37 wrote 12 bytes.
2017-02-22 10:35:43,998 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 37, totalSize: 8 bytes
2017-02-22 10:35:43,999 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@533377b
2017-02-22 10:35:44,004 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 38 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:44,004 DEBUG [FifoRpcScheduler.handler1-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 38 wrote 10 bytes.
2017-02-22 10:35:44,004 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 38, totalSize: 6 bytes
2017-02-22 10:35:44,004 INFO  [main] client.HBaseAdmin$7(980): Started disable of EqualTable
2017-02-22 10:35:44,007 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 39 method_name: "DisableTable" request_param: true priority: 0
2017-02-22 10:35:44,007 INFO  [FifoRpcScheduler.handler1-thread-6] master.HMaster(2334): Client=roger//192.168.1.25 disable EqualTable
2017-02-22 10:35:44,012 DEBUG [FifoRpcScheduler.handler1-thread-6] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/EqualTable/write-master:518950000000001
2017-02-22 10:35:44,013 DEBUG [FifoRpcScheduler.handler1-thread-6] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 39 method_name: "Scan" request_param: true
2017-02-22 10:35:44,014 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 39 wrote 16 bytes.
2017-02-22 10:35:44,014 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 39, totalSize: 12 bytes
2017-02-22 10:35:44,014 DEBUG [FifoRpcScheduler.handler1-thread-6] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 40 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,016 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 40 wrote 986 bytes.
2017-02-22 10:35:44,016 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 40 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:44,016 DEBUG [FifoRpcScheduler.handler1-thread-6] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 41 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,016 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 41 wrote 12 bytes.
2017-02-22 10:35:44,016 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 41, totalSize: 8 bytes
2017-02-22 10:35:44,021 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.DisableTableHandler(130): Attempting to disable table EqualTable
2017-02-22 10:35:44,022 DEBUG [FifoRpcScheduler.handler1-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 39 wrote 8 bytes.
2017-02-22 10:35:44,022 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 39, totalSize: 4 bytes
2017-02-22 10:35:44,022 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:35:44,022 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.DisableTableHandler(174): Offlining 1 regions.
2017-02-22 10:35:44,023 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4c6daf0
2017-02-22 10:35:44,029 DEBUG [192.168.1.25,51895,1487756057370-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager(2509): Starting unassign of EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2. (offlining), current state: {b3578370bacd3c9a30ad3712c9fb8be2 state=OPEN, ts=1487756138185, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:44,029 DEBUG [192.168.1.25,51895,1487756057370-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign(527): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Creating unassigned node b3578370bacd3c9a30ad3712c9fb8be2 in a CLOSING state
2017-02-22 10:35:44,032 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:44,034 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd7820009 connected
2017-02-22 10:35:44,034 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:44,035 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd7820009, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:44,037 INFO  [192.168.1.25,51895,1487756057370-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates(894): Transition {b3578370bacd3c9a30ad3712c9fb8be2 state=OPEN, ts=1487756138185, server=192.168.1.25,51897,1487756057911} to {b3578370bacd3c9a30ad3712c9fb8be2 state=PENDING_CLOSE, ts=1487756144037, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:44,187 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 40 method_name: "Scan" request_param: true
2017-02-22 10:35:44,188 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 27 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:44,191 DEBUG [FifoRpcScheduler.handler4-thread-30] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 8 bytes.
2017-02-22 10:35:44,193 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 40 wrote 16 bytes.
2017-02-22 10:35:44,193 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 27, totalSize: 4 bytes
2017-02-22 10:35:44,194 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 40, totalSize: 12 bytes
2017-02-22 10:35:44,195 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 41 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,200 DEBUG [192.168.1.25,51895,1487756057370-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 42 method_name: "CloseRegion" request_param: true priority: 0
2017-02-22 10:35:44,202 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 41 wrote 986 bytes.
2017-02-22 10:35:44,202 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 41 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:44,203 INFO  [PriorityRpcServer.handler=6,queue=0,port=51897] regionserver.HRegionServer(4151): Close b3578370bacd3c9a30ad3712c9fb8be2, via zk=yes, znode version=0, on null
2017-02-22 10:35:44,205 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 42 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,206 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 42 wrote 12 bytes.
2017-02-22 10:35:44,207 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 42, totalSize: 8 bytes
2017-02-22 10:35:44,207 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] handler.CloseRegionHandler(128): Processing close of EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:44,208 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4c6daf0
2017-02-22 10:35:44,208 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 42 wrote 10 bytes.
2017-02-22 10:35:44,211 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 42, totalSize: 6 bytes
2017-02-22 10:35:44,213 DEBUG [192.168.1.25,51895,1487756057370-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager(1853): Sent CLOSE to 192.168.1.25,51897,1487756057911 for region EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:44,218 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.HRegion(1224): Closing EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.: disabling compactions & flushes
2017-02-22 10:35:44,218 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.HRegion(1251): Updates disabled for region EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:44,219 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.HRegion(1819): Started memstore flush for EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2., current region memstore size 3.4 K
2017-02-22 10:35:44,226 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 100ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:44,334 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:35:44,337 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@659eef7
2017-02-22 10:35:44,378 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:44,389 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000a connected
2017-02-22 10:35:44,390 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000a, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:44,400 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 43 method_name: "Scan" request_param: true
2017-02-22 10:35:44,401 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 25 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:44,401 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 43 wrote 16 bytes.
2017-02-22 10:35:44,402 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 43, totalSize: 12 bytes
2017-02-22 10:35:44,402 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 44 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,402 DEBUG [FifoRpcScheduler.handler7-thread-28] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 8 bytes.
2017-02-22 10:35:44,403 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 25, totalSize: 4 bytes
2017-02-22 10:35:44,405 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 44 wrote 986 bytes.
2017-02-22 10:35:44,405 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 44 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:44,406 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 45 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,406 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=12, memsize=3.4 K, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster1/root/data/default/EqualTable/b3578370bacd3c9a30ad3712c9fb8be2/.tmp/f93b2fea3b92480ea29d186901210bca
2017-02-22 10:35:44,407 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 45 wrote 12 bytes.
2017-02-22 10:35:44,407 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 45, totalSize: 8 bytes
2017-02-22 10:35:44,407 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@659eef7
2017-02-22 10:35:44,412 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 200ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:44,492 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster1/root/data/default/EqualTable/b3578370bacd3c9a30ad3712c9fb8be2/.tmp/f93b2fea3b92480ea29d186901210bca as file:/var/tmp/test-data/cluster1/root/data/default/EqualTable/b3578370bacd3c9a30ad3712c9fb8be2/columns/f93b2fea3b92480ea29d186901210bca
2017-02-22 10:35:44,495 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster1/root/data/default/EqualTable/b3578370bacd3c9a30ad3712c9fb8be2/columns/f93b2fea3b92480ea29d186901210bca, entries=20, sequenceid=12, filesize=1.8 K
2017-02-22 10:35:44,496 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.HRegion(1986): Finished memstore flush of ~3.4 K/3440, currentsize=0/0 for region EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2. in 277ms, sequenceid=12, compaction requested=false
2017-02-22 10:35:44,501 INFO  [StoreCloserThread-EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.-1] regionserver.HStore(780): Closed columns
2017-02-22 10:35:44,503 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:44,505 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-0] regionserver.HRegion(1340): Closed EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:44,505 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(832): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioning b3578370bacd3c9a30ad3712c9fb8be2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2017-02-22 10:35:44,508 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:44,509 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] zookeeper.ZKAssign(907): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Transitioned node b3578370bacd3c9a30ad3712c9fb8be2 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2017-02-22 10:35:44,509 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] handler.CloseRegionHandler(174): Set closed state in zk for EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2. on 192.168.1.25,51897,1487756057911
2017-02-22 10:35:44,509 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-0] handler.CloseRegionHandler(182): Closed EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:44,510 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager(930): Handling RS_ZK_REGION_CLOSED, server=192.168.1.25,51897,1487756057911, region=b3578370bacd3c9a30ad3712c9fb8be2, current_state={b3578370bacd3c9a30ad3712c9fb8be2 state=PENDING_CLOSE, ts=1487756144037, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:44,511 DEBUG [AM.ZK.Worker-pool2-t15] handler.ClosedRegionHandler(92): Handling CLOSED event for b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:44,512 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager(1543): Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region EqualTable,,1487756138040.b3578370bacd3c9a30ad3712c9fb8be2.
2017-02-22 10:35:44,515 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/b3578370bacd3c9a30ad3712c9fb8be2
2017-02-22 10:35:44,516 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:44,516 DEBUG [AM.ZK.Worker-pool2-t15] zookeeper.ZKAssign(480): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Deleted unassigned node b3578370bacd3c9a30ad3712c9fb8be2 in expected state RS_ZK_REGION_CLOSED
2017-02-22 10:35:44,516 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates(894): Transition {b3578370bacd3c9a30ad3712c9fb8be2 state=PENDING_CLOSE, ts=1487756144037, server=192.168.1.25,51897,1487756057911} to {b3578370bacd3c9a30ad3712c9fb8be2 state=OFFLINE, ts=1487756144516, server=192.168.1.25,51897,1487756057911}
2017-02-22 10:35:44,516 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates(493): Offlined b3578370bacd3c9a30ad3712c9fb8be2 from 192.168.1.25,51897,1487756057911
2017-02-22 10:35:44,616 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:35:44,617 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2488b073
2017-02-22 10:35:44,626 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:44,628 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000b connected
2017-02-22 10:35:44,630 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000b, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:44,632 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 46 method_name: "Scan" request_param: true
2017-02-22 10:35:44,634 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 46 wrote 16 bytes.
2017-02-22 10:35:44,635 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 46, totalSize: 12 bytes
2017-02-22 10:35:44,637 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 47 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,643 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 47 wrote 986 bytes.
2017-02-22 10:35:44,644 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 47 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:44,644 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 48 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,646 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 48 wrote 12 bytes.
2017-02-22 10:35:44,646 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 48, totalSize: 8 bytes
2017-02-22 10:35:44,647 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2488b073
2017-02-22 10:35:44,656 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 300ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:44,957 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:35:44,958 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@55787112
2017-02-22 10:35:44,968 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:44,969 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000c connected
2017-02-22 10:35:44,970 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000c, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:44,971 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 49 method_name: "Scan" request_param: true
2017-02-22 10:35:44,971 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 49 wrote 16 bytes.
2017-02-22 10:35:44,971 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 49, totalSize: 12 bytes
2017-02-22 10:35:44,972 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 50 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,973 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 50 wrote 986 bytes.
2017-02-22 10:35:44,973 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 50 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:44,974 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 51 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:44,974 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 51 wrote 12 bytes.
2017-02-22 10:35:44,974 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 51, totalSize: 8 bytes
2017-02-22 10:35:44,975 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@55787112
2017-02-22 10:35:44,979 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 500ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:45,031 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.DisableTableHandler$BulkDisabler(230): Disable waiting until done; 300000 ms remaining; []
2017-02-22 10:35:45,034 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] handler.DisableTableHandler(190): Disabled table, EqualTable, is done=true
2017-02-22 10:35:45,036 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51895-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/EqualTable/write-master:518950000000001
2017-02-22 10:35:45,481 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x70e8f8e connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:35:45,482 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7db82169
2017-02-22 10:35:45,490 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x70e8f8e0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:45,491 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000d connected
2017-02-22 10:35:45,491 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x70e8f8e-0x15a652bd782000d, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:45,492 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 52 method_name: "Scan" request_param: true
2017-02-22 10:35:45,493 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 52 wrote 16 bytes.
2017-02-22 10:35:45,493 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 52, totalSize: 12 bytes
2017-02-22 10:35:45,493 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 53 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,495 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 53 wrote 986 bytes.
2017-02-22 10:35:45,495 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 53 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:45,495 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: wrote request header call_id: 54 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,496 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51897] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 54 wrote 12 bytes.
2017-02-22 10:35:45,496 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: got response header call_id: 54, totalSize: 8 bytes
2017-02-22 10:35:45,496 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7db82169
2017-02-22 10:35:45,499 INFO  [main] client.HBaseAdmin(1034): Disabled EqualTable
2017-02-22 10:35:45,499 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 33 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:45,499 DEBUG [FifoRpcScheduler.handler4-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 10 bytes.
2017-02-22 10:35:45,500 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 33, totalSize: 6 bytes
2017-02-22 10:35:45,500 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 34 method_name: "GetTableDescriptors" request_param: true priority: 0
2017-02-22 10:35:45,500 DEBUG [FifoRpcScheduler.handler4-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 34 wrote 301 bytes.
2017-02-22 10:35:45,500 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 34, totalSize: 297 bytes
2017-02-22 10:35:45,501 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:35:45,502 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@f74e835
2017-02-22 10:35:45,509 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:45,510 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a60008 connected
2017-02-22 10:35:45,510 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a60008, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:45,512 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 35 method_name: "Scan" request_param: true
2017-02-22 10:35:45,513 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 35 wrote 16 bytes.
2017-02-22 10:35:45,513 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 35, totalSize: 12 bytes
2017-02-22 10:35:45,513 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 36 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,515 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 36 wrote 986 bytes.
2017-02-22 10:35:45,515 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 36 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:45,515 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 37 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,516 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 37 wrote 12 bytes.
2017-02-22 10:35:45,516 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 37, totalSize: 8 bytes
2017-02-22 10:35:45,516 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@f74e835
2017-02-22 10:35:45,522 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 38 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:45,522 DEBUG [FifoRpcScheduler.handler4-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 38 wrote 10 bytes.
2017-02-22 10:35:45,522 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 38, totalSize: 6 bytes
2017-02-22 10:35:45,522 INFO  [main] client.HBaseAdmin$7(980): Started disable of EqualTable
2017-02-22 10:35:45,523 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 39 method_name: "DisableTable" request_param: true priority: 0
2017-02-22 10:35:45,523 INFO  [FifoRpcScheduler.handler4-thread-4] master.HMaster(2334): Client=roger//192.168.1.25 disable EqualTable
2017-02-22 10:35:45,525 DEBUG [FifoRpcScheduler.handler4-thread-4] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/EqualTable/write-master:519090000000001
2017-02-22 10:35:45,526 DEBUG [FifoRpcScheduler.handler4-thread-4] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 39 method_name: "Scan" request_param: true
2017-02-22 10:35:45,526 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 39 wrote 16 bytes.
2017-02-22 10:35:45,527 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 39, totalSize: 12 bytes
2017-02-22 10:35:45,527 DEBUG [FifoRpcScheduler.handler4-thread-4] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 40 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,530 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 40 wrote 986 bytes.
2017-02-22 10:35:45,530 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 40 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:45,531 DEBUG [FifoRpcScheduler.handler4-thread-4] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 41 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,531 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 41 wrote 12 bytes.
2017-02-22 10:35:45,531 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 41, totalSize: 8 bytes
2017-02-22 10:35:45,534 DEBUG [FifoRpcScheduler.handler4-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 39 wrote 8 bytes.
2017-02-22 10:35:45,533 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.DisableTableHandler(130): Attempting to disable table EqualTable
2017-02-22 10:35:45,534 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 39, totalSize: 4 bytes
2017-02-22 10:35:45,535 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:35:45,537 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3f28bd56
2017-02-22 10:35:45,537 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.DisableTableHandler(174): Offlining 1 regions.
2017-02-22 10:35:45,539 DEBUG [192.168.1.25,51909,1487756065220-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager(2509): Starting unassign of EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08. (offlining), current state: {91fd9027520ca204ce8bc389daf4ea08 state=OPEN, ts=1487756138394, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:45,539 DEBUG [192.168.1.25,51909,1487756065220-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign(527): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Creating unassigned node 91fd9027520ca204ce8bc389daf4ea08 in a CLOSING state
2017-02-22 10:35:45,541 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:45,543 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:45,545 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a60009 connected
2017-02-22 10:35:45,545 INFO  [192.168.1.25,51909,1487756065220-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates(894): Transition {91fd9027520ca204ce8bc389daf4ea08 state=OPEN, ts=1487756138394, server=192.168.1.25,51911,1487756065280} to {91fd9027520ca204ce8bc389daf4ea08 state=PENDING_CLOSE, ts=1487756145545, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:45,549 DEBUG [192.168.1.25,51909,1487756065220-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 42 method_name: "CloseRegion" request_param: true priority: 0
2017-02-22 10:35:45,549 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a60009, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:45,549 INFO  [PriorityRpcServer.handler=4,queue=0,port=51911] regionserver.HRegionServer(4151): Close 91fd9027520ca204ce8bc389daf4ea08, via zk=yes, znode version=0, on null
2017-02-22 10:35:45,549 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 42 wrote 10 bytes.
2017-02-22 10:35:45,550 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 42, totalSize: 6 bytes
2017-02-22 10:35:45,549 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] handler.CloseRegionHandler(128): Processing close of EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:45,550 DEBUG [192.168.1.25,51909,1487756065220-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager(1853): Sent CLOSE to 192.168.1.25,51911,1487756065280 for region EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:45,551 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 40 method_name: "Scan" request_param: true
2017-02-22 10:35:45,551 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 40 wrote 16 bytes.
2017-02-22 10:35:45,553 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 40, totalSize: 12 bytes
2017-02-22 10:35:45,553 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.HRegion(1224): Closing EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.: disabling compactions & flushes
2017-02-22 10:35:45,553 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.HRegion(1251): Updates disabled for region EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:45,553 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 41 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,553 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.HRegion(1819): Started memstore flush for EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08., current region memstore size 3.4 K
2017-02-22 10:35:45,555 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 41 wrote 986 bytes.
2017-02-22 10:35:45,556 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 41 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:45,557 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 42 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,558 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 42 wrote 12 bytes.
2017-02-22 10:35:45,558 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 42, totalSize: 8 bytes
2017-02-22 10:35:45,558 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3f28bd56
2017-02-22 10:35:45,564 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 100ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:45,584 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=12, memsize=3.4 K, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster2/root/data/default/EqualTable/91fd9027520ca204ce8bc389daf4ea08/.tmp/e9a5c1f2b919406ea052ab4353258a80
2017-02-22 10:35:45,585 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster2/root/data/default/EqualTable/91fd9027520ca204ce8bc389daf4ea08/.tmp/e9a5c1f2b919406ea052ab4353258a80 as file:/var/tmp/test-data/cluster2/root/data/default/EqualTable/91fd9027520ca204ce8bc389daf4ea08/columns/e9a5c1f2b919406ea052ab4353258a80
2017-02-22 10:35:45,587 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster2/root/data/default/EqualTable/91fd9027520ca204ce8bc389daf4ea08/columns/e9a5c1f2b919406ea052ab4353258a80, entries=20, sequenceid=12, filesize=1.8 K
2017-02-22 10:35:45,589 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.HRegion(1986): Finished memstore flush of ~3.4 K/3440, currentsize=0/0 for region EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08. in 34ms, sequenceid=12, compaction requested=false
2017-02-22 10:35:45,590 INFO  [StoreCloserThread-EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.-1] regionserver.HStore(780): Closed columns
2017-02-22 10:35:45,591 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:45,591 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-0] regionserver.HRegion(1340): Closed EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:45,591 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(832): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioning 91fd9027520ca204ce8bc389daf4ea08 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2017-02-22 10:35:45,593 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:45,593 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] zookeeper.ZKAssign(907): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Transitioned node 91fd9027520ca204ce8bc389daf4ea08 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2017-02-22 10:35:45,593 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] handler.CloseRegionHandler(174): Set closed state in zk for EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08. on 192.168.1.25,51911,1487756065280
2017-02-22 10:35:45,593 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-0] handler.CloseRegionHandler(182): Closed EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:45,594 DEBUG [AM.ZK.Worker-pool13-t15] master.AssignmentManager(930): Handling RS_ZK_REGION_CLOSED, server=192.168.1.25,51911,1487756065280, region=91fd9027520ca204ce8bc389daf4ea08, current_state={91fd9027520ca204ce8bc389daf4ea08 state=PENDING_CLOSE, ts=1487756145545, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:45,595 DEBUG [AM.ZK.Worker-pool13-t15] handler.ClosedRegionHandler(92): Handling CLOSED event for 91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:45,596 DEBUG [AM.ZK.Worker-pool13-t15] master.AssignmentManager(1543): Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region EqualTable,,1487756138260.91fd9027520ca204ce8bc389daf4ea08.
2017-02-22 10:35:45,598 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/91fd9027520ca204ce8bc389daf4ea08
2017-02-22 10:35:45,598 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:45,598 DEBUG [AM.ZK.Worker-pool13-t15] zookeeper.ZKAssign(480): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Deleted unassigned node 91fd9027520ca204ce8bc389daf4ea08 in expected state RS_ZK_REGION_CLOSED
2017-02-22 10:35:45,598 INFO  [AM.ZK.Worker-pool13-t15] master.RegionStates(894): Transition {91fd9027520ca204ce8bc389daf4ea08 state=PENDING_CLOSE, ts=1487756145545, server=192.168.1.25,51911,1487756065280} to {91fd9027520ca204ce8bc389daf4ea08 state=OFFLINE, ts=1487756145598, server=192.168.1.25,51911,1487756065280}
2017-02-22 10:35:45,598 INFO  [AM.ZK.Worker-pool13-t15] master.RegionStates(493): Offlined 91fd9027520ca204ce8bc389daf4ea08 from 192.168.1.25,51911,1487756065280
2017-02-22 10:35:45,668 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:35:45,670 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@19fe4644
2017-02-22 10:35:45,679 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:45,681 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000a connected
2017-02-22 10:35:45,681 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000a, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:45,682 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 43 method_name: "Scan" request_param: true
2017-02-22 10:35:45,683 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 43 wrote 16 bytes.
2017-02-22 10:35:45,683 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 43, totalSize: 12 bytes
2017-02-22 10:35:45,683 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 44 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,685 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 44 wrote 986 bytes.
2017-02-22 10:35:45,685 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 44 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:45,686 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 45 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,686 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 45 wrote 12 bytes.
2017-02-22 10:35:45,686 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 45, totalSize: 8 bytes
2017-02-22 10:35:45,687 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@19fe4644
2017-02-22 10:35:45,691 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 200ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:45,896 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:35:45,897 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@5be067de
2017-02-22 10:35:45,905 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:45,906 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000b connected
2017-02-22 10:35:45,906 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000b, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:45,907 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 46 method_name: "Scan" request_param: true
2017-02-22 10:35:45,908 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 46 wrote 16 bytes.
2017-02-22 10:35:45,908 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 46, totalSize: 12 bytes
2017-02-22 10:35:45,908 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 47 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,909 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 47 wrote 986 bytes.
2017-02-22 10:35:45,910 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 47 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:45,910 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 48 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:45,910 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 48 wrote 12 bytes.
2017-02-22 10:35:45,910 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 48, totalSize: 8 bytes
2017-02-22 10:35:45,911 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@5be067de
2017-02-22 10:35:45,920 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 300ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:46,222 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:35:46,223 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@18245eb0
2017-02-22 10:35:46,239 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:46,240 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000c connected
2017-02-22 10:35:46,240 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000c, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:46,241 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 49 method_name: "Scan" request_param: true
2017-02-22 10:35:46,242 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 49 wrote 16 bytes.
2017-02-22 10:35:46,243 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 49, totalSize: 12 bytes
2017-02-22 10:35:46,243 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 50 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,248 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 50 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:46,246 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 50 wrote 986 bytes.
2017-02-22 10:35:46,249 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 51 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,250 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 51, totalSize: 8 bytes
2017-02-22 10:35:46,250 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 51 wrote 12 bytes.
2017-02-22 10:35:46,251 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@18245eb0
2017-02-22 10:35:46,255 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 500ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:46,449 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: wrote request header call_id: 30 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:46,449 DEBUG [FifoRpcScheduler.handler1-thread-7] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 8 bytes.
2017-02-22 10:35:46,450 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: got response header call_id: 30, totalSize: 4 bytes
2017-02-22 10:35:46,543 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.DisableTableHandler$BulkDisabler(230): Disable waiting until done; 300000 ms remaining; []
2017-02-22 10:35:46,546 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] handler.DisableTableHandler(190): Disabled table, EqualTable, is done=true
2017-02-22 10:35:46,548 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51909-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/EqualTable/write-master:519090000000001
2017-02-22 10:35:46,756 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x774698ab connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:35:46,757 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@24fb6a80
2017-02-22 10:35:46,762 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x774698ab0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:46,764 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000d connected
2017-02-22 10:35:46,765 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x774698ab-0x15a652bf9a6000d, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:46,766 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 52 method_name: "Scan" request_param: true
2017-02-22 10:35:46,767 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 52 wrote 16 bytes.
2017-02-22 10:35:46,767 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 52, totalSize: 12 bytes
2017-02-22 10:35:46,767 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 53 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,768 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 53 wrote 986 bytes.
2017-02-22 10:35:46,769 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 53 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:46,769 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: wrote request header call_id: 54 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,769 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51911] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 54 wrote 12 bytes.
2017-02-22 10:35:46,769 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: got response header call_id: 54, totalSize: 8 bytes
2017-02-22 10:35:46,770 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@24fb6a80
2017-02-22 10:35:46,772 INFO  [main] client.HBaseAdmin(1034): Disabled EqualTable
2017-02-22 10:35:46,773 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 33 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:46,773 DEBUG [FifoRpcScheduler.handler7-thread-29] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 10 bytes.
2017-02-22 10:35:46,773 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 33, totalSize: 6 bytes
2017-02-22 10:35:46,773 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 34 method_name: "GetTableDescriptors" request_param: true priority: 0
2017-02-22 10:35:46,774 DEBUG [FifoRpcScheduler.handler7-thread-30] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 34 wrote 301 bytes.
2017-02-22 10:35:46,774 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 34, totalSize: 297 bytes
2017-02-22 10:35:46,774 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:35:46,775 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@72a85671
2017-02-22 10:35:46,779 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:46,780 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db0008 connected
2017-02-22 10:35:46,780 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db0008, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:46,782 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 35 method_name: "Scan" request_param: true
2017-02-22 10:35:46,782 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 35 wrote 16 bytes.
2017-02-22 10:35:46,782 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 35, totalSize: 12 bytes
2017-02-22 10:35:46,782 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 36 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,784 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 36 wrote 986 bytes.
2017-02-22 10:35:46,784 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 36 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:46,784 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 37 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,784 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 37 wrote 12 bytes.
2017-02-22 10:35:46,785 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 37, totalSize: 8 bytes
2017-02-22 10:35:46,785 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@72a85671
2017-02-22 10:35:46,791 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 38 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:35:46,792 DEBUG [FifoRpcScheduler.handler7-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 38 wrote 10 bytes.
2017-02-22 10:35:46,792 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 38, totalSize: 6 bytes
2017-02-22 10:35:46,792 INFO  [main] client.HBaseAdmin$7(980): Started disable of EqualTable
2017-02-22 10:35:46,792 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 39 method_name: "DisableTable" request_param: true priority: 0
2017-02-22 10:35:46,792 INFO  [FifoRpcScheduler.handler7-thread-2] master.HMaster(2334): Client=roger//192.168.1.25 disable EqualTable
2017-02-22 10:35:46,795 DEBUG [FifoRpcScheduler.handler7-thread-2] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/EqualTable/write-master:519230000000001
2017-02-22 10:35:46,796 DEBUG [FifoRpcScheduler.handler7-thread-2] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 39 method_name: "Scan" request_param: true
2017-02-22 10:35:46,797 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 39 wrote 16 bytes.
2017-02-22 10:35:46,797 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 39, totalSize: 12 bytes
2017-02-22 10:35:46,798 DEBUG [FifoRpcScheduler.handler7-thread-2] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 40 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,799 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 40 wrote 986 bytes.
2017-02-22 10:35:46,799 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 40 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:46,799 DEBUG [FifoRpcScheduler.handler7-thread-2] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 41 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,800 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 41 wrote 12 bytes.
2017-02-22 10:35:46,800 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 41, totalSize: 8 bytes
2017-02-22 10:35:46,801 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.DisableTableHandler(130): Attempting to disable table EqualTable
2017-02-22 10:35:46,802 DEBUG [FifoRpcScheduler.handler7-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 39 wrote 8 bytes.
2017-02-22 10:35:46,802 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 39, totalSize: 4 bytes
2017-02-22 10:35:46,803 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:35:46,804 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@18f20260
2017-02-22 10:35:46,806 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.DisableTableHandler(174): Offlining 1 regions.
2017-02-22 10:35:46,808 DEBUG [192.168.1.25,51923,1487756071661-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager(2509): Starting unassign of EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1. (offlining), current state: {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OPEN, ts=1487756138546, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:46,808 DEBUG [192.168.1.25,51923,1487756071661-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign(527): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Creating unassigned node f182bbd36f0e1d9b9a564e9ea56ce8b1 in a CLOSING state
2017-02-22 10:35:46,809 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:46,810 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db0009 connected
2017-02-22 10:35:46,811 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:46,811 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db0009, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:46,812 INFO  [192.168.1.25,51923,1487756071661-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates(894): Transition {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OPEN, ts=1487756138546, server=192.168.1.25,51925,1487756071702} to {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=PENDING_CLOSE, ts=1487756146812, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:46,813 DEBUG [192.168.1.25,51923,1487756071661-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 42 method_name: "CloseRegion" request_param: true priority: 0
2017-02-22 10:35:46,814 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 40 method_name: "Scan" request_param: true
2017-02-22 10:35:46,814 INFO  [PriorityRpcServer.handler=5,queue=0,port=51925] regionserver.HRegionServer(4151): Close f182bbd36f0e1d9b9a564e9ea56ce8b1, via zk=yes, znode version=0, on null
2017-02-22 10:35:46,815 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] handler.CloseRegionHandler(128): Processing close of EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:46,815 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 42 wrote 10 bytes.
2017-02-22 10:35:46,815 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 42, totalSize: 6 bytes
2017-02-22 10:35:46,815 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 40 wrote 16 bytes.
2017-02-22 10:35:46,815 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 40, totalSize: 12 bytes
2017-02-22 10:35:46,815 DEBUG [192.168.1.25,51923,1487756071661-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager(1853): Sent CLOSE to 192.168.1.25,51925,1487756071702 for region EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:46,816 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 41 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,818 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.HRegion(1224): Closing EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.: disabling compactions & flushes
2017-02-22 10:35:46,818 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.HRegion(1251): Updates disabled for region EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:46,818 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 41 wrote 986 bytes.
2017-02-22 10:35:46,818 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 41 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:46,818 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.HRegion(1819): Started memstore flush for EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1., current region memstore size 3.4 K
2017-02-22 10:35:46,819 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 42 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,819 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 42 wrote 12 bytes.
2017-02-22 10:35:46,819 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 42, totalSize: 8 bytes
2017-02-22 10:35:46,820 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@18f20260
2017-02-22 10:35:46,824 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 100ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:46,839 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=12, memsize=3.4 K, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster3/root/data/default/EqualTable/f182bbd36f0e1d9b9a564e9ea56ce8b1/.tmp/5064a8f7881341e7b704b4bb43f4b4ae
2017-02-22 10:35:46,840 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster3/root/data/default/EqualTable/f182bbd36f0e1d9b9a564e9ea56ce8b1/.tmp/5064a8f7881341e7b704b4bb43f4b4ae as file:/var/tmp/test-data/cluster3/root/data/default/EqualTable/f182bbd36f0e1d9b9a564e9ea56ce8b1/columns/5064a8f7881341e7b704b4bb43f4b4ae
2017-02-22 10:35:46,842 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster3/root/data/default/EqualTable/f182bbd36f0e1d9b9a564e9ea56ce8b1/columns/5064a8f7881341e7b704b4bb43f4b4ae, entries=20, sequenceid=12, filesize=1.8 K
2017-02-22 10:35:46,842 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.HRegion(1986): Finished memstore flush of ~3.4 K/3440, currentsize=0/0 for region EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1. in 24ms, sequenceid=12, compaction requested=false
2017-02-22 10:35:46,845 INFO  [StoreCloserThread-EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.-1] regionserver.HStore(780): Closed columns
2017-02-22 10:35:46,846 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:46,846 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-0] regionserver.HRegion(1340): Closed EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:46,846 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(832): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioning f182bbd36f0e1d9b9a564e9ea56ce8b1 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2017-02-22 10:35:46,848 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:46,849 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] zookeeper.ZKAssign(907): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Transitioned node f182bbd36f0e1d9b9a564e9ea56ce8b1 from M_ZK_REGION_CLOSING to RS_ZK_REGION_CLOSED
2017-02-22 10:35:46,849 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] handler.CloseRegionHandler(174): Set closed state in zk for EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1. on 192.168.1.25,51925,1487756071702
2017-02-22 10:35:46,849 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-0] handler.CloseRegionHandler(182): Closed EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:46,849 DEBUG [AM.ZK.Worker-pool24-t15] master.AssignmentManager(930): Handling RS_ZK_REGION_CLOSED, server=192.168.1.25,51925,1487756071702, region=f182bbd36f0e1d9b9a564e9ea56ce8b1, current_state={f182bbd36f0e1d9b9a564e9ea56ce8b1 state=PENDING_CLOSE, ts=1487756146812, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:46,849 DEBUG [AM.ZK.Worker-pool24-t15] handler.ClosedRegionHandler(92): Handling CLOSED event for f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:46,849 DEBUG [AM.ZK.Worker-pool24-t15] master.AssignmentManager(1543): Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region EqualTable,,1487756138443.f182bbd36f0e1d9b9a564e9ea56ce8b1.
2017-02-22 10:35:46,851 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/f182bbd36f0e1d9b9a564e9ea56ce8b1
2017-02-22 10:35:46,851 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:35:46,851 DEBUG [AM.ZK.Worker-pool24-t15] zookeeper.ZKAssign(480): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Deleted unassigned node f182bbd36f0e1d9b9a564e9ea56ce8b1 in expected state RS_ZK_REGION_CLOSED
2017-02-22 10:35:46,851 INFO  [AM.ZK.Worker-pool24-t15] master.RegionStates(894): Transition {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=PENDING_CLOSE, ts=1487756146812, server=192.168.1.25,51925,1487756071702} to {f182bbd36f0e1d9b9a564e9ea56ce8b1 state=OFFLINE, ts=1487756146851, server=192.168.1.25,51925,1487756071702}
2017-02-22 10:35:46,851 INFO  [AM.ZK.Worker-pool24-t15] master.RegionStates(493): Offlined f182bbd36f0e1d9b9a564e9ea56ce8b1 from 192.168.1.25,51925,1487756071702
2017-02-22 10:35:46,927 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:35:46,928 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7a48e6e2
2017-02-22 10:35:46,934 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:46,935 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000a connected
2017-02-22 10:35:46,936 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000a, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:46,937 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 43 method_name: "Scan" request_param: true
2017-02-22 10:35:46,937 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 43 wrote 16 bytes.
2017-02-22 10:35:46,938 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 43, totalSize: 12 bytes
2017-02-22 10:35:46,938 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 44 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,939 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 44 wrote 986 bytes.
2017-02-22 10:35:46,939 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 44 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:46,940 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 45 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:46,940 DEBUG [PriorityRpcServer.handler=1,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 45 wrote 12 bytes.
2017-02-22 10:35:46,940 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 45, totalSize: 8 bytes
2017-02-22 10:35:46,940 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7a48e6e2
2017-02-22 10:35:46,943 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 200ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:47,144 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:35:47,145 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3a94964
2017-02-22 10:35:47,151 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:47,152 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000b connected
2017-02-22 10:35:47,152 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000b, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:47,154 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 46 method_name: "Scan" request_param: true
2017-02-22 10:35:47,156 DEBUG [PriorityRpcServer.handler=3,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 46 wrote 16 bytes.
2017-02-22 10:35:47,156 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 46, totalSize: 12 bytes
2017-02-22 10:35:47,156 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 47 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:47,157 DEBUG [PriorityRpcServer.handler=2,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 47 wrote 986 bytes.
2017-02-22 10:35:47,158 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 47 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:47,158 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 48 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:47,158 DEBUG [PriorityRpcServer.handler=4,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 48 wrote 12 bytes.
2017-02-22 10:35:47,158 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 48, totalSize: 8 bytes
2017-02-22 10:35:47,159 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3a94964
2017-02-22 10:35:47,162 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 300ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:47,197 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: wrote request header call_id: 28 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:47,197 DEBUG [FifoRpcScheduler.handler4-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 8 bytes.
2017-02-22 10:35:47,198 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: got response header call_id: 28, totalSize: 4 bytes
2017-02-22 10:35:47,406 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 26 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:47,406 DEBUG [FifoRpcScheduler.handler7-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 8 bytes.
2017-02-22 10:35:47,407 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 26, totalSize: 4 bytes
2017-02-22 10:35:47,464 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:35:47,465 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6d0b5baf
2017-02-22 10:35:47,473 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:47,474 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000c connected
2017-02-22 10:35:47,474 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000c, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:47,476 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 49 method_name: "Scan" request_param: true
2017-02-22 10:35:47,476 DEBUG [PriorityRpcServer.handler=5,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 49 wrote 16 bytes.
2017-02-22 10:35:47,476 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 49, totalSize: 12 bytes
2017-02-22 10:35:47,477 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 50 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:47,478 DEBUG [PriorityRpcServer.handler=6,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 50 wrote 986 bytes.
2017-02-22 10:35:47,479 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 50 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:47,479 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 51 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:47,480 DEBUG [PriorityRpcServer.handler=7,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 51 wrote 12 bytes.
2017-02-22 10:35:47,480 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 51, totalSize: 8 bytes
2017-02-22 10:35:47,480 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6d0b5baf
2017-02-22 10:35:47,486 DEBUG [main] client.HBaseAdmin(1019): Sleeping= 500ms, waiting for all regions to be disabled in EqualTable
2017-02-22 10:35:47,812 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.DisableTableHandler$BulkDisabler(230): Disable waiting until done; 300000 ms remaining; []
2017-02-22 10:35:47,815 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] handler.DisableTableHandler(190): Disabled table, EqualTable, is done=true
2017-02-22 10:35:47,818 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:51923-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/EqualTable/write-master:519230000000001
2017-02-22 10:35:47,991 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=catalogtracker-on-hconnection-0x47db5fa5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:35:47,992 DEBUG [main] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2a3591c5
2017-02-22 10:35:48,001 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): catalogtracker-on-hconnection-0x47db5fa50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:35:48,002 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000d connected
2017-02-22 10:35:48,002 DEBUG [main] zookeeper.ZKUtil(366): catalogtracker-on-hconnection-0x47db5fa5-0x15a652c12db000d, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:35:48,004 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 52 method_name: "Scan" request_param: true
2017-02-22 10:35:48,005 DEBUG [PriorityRpcServer.handler=8,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 52 wrote 16 bytes.
2017-02-22 10:35:48,005 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 52, totalSize: 12 bytes
2017-02-22 10:35:48,006 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 53 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:48,007 DEBUG [PriorityRpcServer.handler=9,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 53 wrote 986 bytes.
2017-02-22 10:35:48,007 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 53 cell_block_meta { length: 959 }, totalSize: 982 bytes
2017-02-22 10:35:48,008 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: wrote request header call_id: 54 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:35:48,008 DEBUG [PriorityRpcServer.handler=0,queue=0,port=51925] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 54 wrote 12 bytes.
2017-02-22 10:35:48,008 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: got response header call_id: 54, totalSize: 8 bytes
2017-02-22 10:35:48,008 DEBUG [main] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2a3591c5
2017-02-22 10:35:48,013 INFO  [main] client.HBaseAdmin(1034): Disabled EqualTable
2017-02-22 10:35:48,013 DEBUG [main] util.JVMClusterUtil(241): Shutting down HBase Cluster
2017-02-22 10:35:48,013 INFO  [main] master.HMaster(2748): Cluster shutdown requested
2017-02-22 10:35:48,013 INFO  [M:0;192.168.1.25:51895] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51897,1487756057911
2017-02-22 10:35:48,013 INFO  [192.168.1.25,51895,1487756057370-BalancerChore] hbase.Chore(93): 192.168.1.25,51895,1487756057370-BalancerChore exiting
2017-02-22 10:35:48,013 INFO  [CatalogJanitor-192.168.1.25:51895] hbase.Chore(93): CatalogJanitor-192.168.1.25:51895 exiting
2017-02-22 10:35:48,013 INFO  [192.168.1.25,51895,1487756057370-ClusterStatusChore] hbase.Chore(93): 192.168.1.25,51895,1487756057370-ClusterStatusChore exiting
2017-02-22 10:35:48,014 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:35:48,014 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:35:48,014 INFO  [main] regionserver.HRegionServer(1865): STOPPED: Shutdown requested
2017-02-22 10:35:48,015 INFO  [RS:0;192.168.1.25:51897] ipc.RpcServer(2286): Stopping server on 51897
2017-02-22 10:35:48,015 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZKUtil(368): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:35:48,015 INFO  [RpcServer.listener,port=51897] ipc.RpcServer$Listener(823): RpcServer.listener,port=51897: stopping
2017-02-22 10:35:48,015 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:35:48,015 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:35:48,015 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:35:48,015 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:35:48,017 INFO  [RS:0;192.168.1.25:51897] regionserver.SplitLogWorker(604): Sending interrupt to stop the worker thread
2017-02-22 10:35:48,017 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(971): Stopping infoServer
2017-02-22 10:35:48,017 INFO  [SplitLogWorker-192.168.1.25,51897,1487756057911] regionserver.SplitLogWorker(295): SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2017-02-22 10:35:48,017 INFO  [SplitLogWorker-192.168.1.25,51897,1487756057911] regionserver.SplitLogWorker(212): SplitLogWorker 192.168.1.25,51897,1487756057911 exiting
2017-02-22 10:35:48,126 INFO  [192.168.1.25,51897,1487756057911-HeapMemoryChore] hbase.Chore(93): 192.168.1.25,51897,1487756057911-HeapMemoryChore exiting
2017-02-22 10:35:48,126 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.1 exiting
2017-02-22 10:35:48,126 INFO  [RS:0;192.168.1.25:51897.compactionChecker] hbase.Chore(93): RS:0;192.168.1.25:51897.compactionChecker exiting
2017-02-22 10:35:48,126 INFO  [RS_OPEN_META-192.168.1.25:51897-0-MetaLogRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:35:48,126 INFO  [RS:0;192.168.1.25:51897] snapshot.RegionServerSnapshotManager(136): Stopping RegionServerSnapshotManager gracefully.
2017-02-22 10:35:48,126 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.0 exiting
2017-02-22 10:35:48,126 INFO  [RS:0;192.168.1.25:51897.logRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:35:48,126 INFO  [RS:0;192.168.1.25:51897.nonceCleaner] hbase.Chore(93): RS:0;192.168.1.25:51897.nonceCleaner exiting
2017-02-22 10:35:48,127 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1018): stopping server 192.168.1.25,51897,1487756057911
2017-02-22 10:35:48,127 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-1] handler.CloseRegionHandler(128): Processing close of hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:35:48,127 DEBUG [RS:0;192.168.1.25:51897] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@369db2a0
2017-02-22 10:35:48,128 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.: disabling compactions & flushes
2017-02-22 10:35:48,129 INFO  [RS:0;192.168.1.25:51897] regionserver.CompactSplitThread(381): Waiting for Split Thread to finish...
2017-02-22 10:35:48,129 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:35:48,129 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.HRegion(1819): Started memstore flush for hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b., current region memstore size 344
2017-02-22 10:35:48,129 INFO  [RS:0;192.168.1.25:51897] regionserver.CompactSplitThread(381): Waiting for Merge Thread to finish...
2017-02-22 10:35:48,129 INFO  [RS:0;192.168.1.25:51897] regionserver.CompactSplitThread(381): Waiting for Large Compaction Thread to finish...
2017-02-22 10:35:48,129 INFO  [RS:0;192.168.1.25:51897] regionserver.CompactSplitThread(381): Waiting for Small Compaction Thread to finish...
2017-02-22 10:35:48,129 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1231): Waiting on 2 regions to close
2017-02-22 10:35:48,129 DEBUG [RS_CLOSE_META-192.168.1.25:51897-0] handler.CloseRegionHandler(128): Processing close of hbase:meta,,1.1588230740
2017-02-22 10:35:48,129 DEBUG [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1235): {80d0e76c1cadc7268bac2fe88eb7755b=hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b., 1588230740=hbase:meta,,1.1588230740}
2017-02-22 10:35:48,130 DEBUG [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:35:48,131 DEBUG [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:35:48,131 INFO  [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.HRegion(1819): Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.9 K
2017-02-22 10:35:48,154 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/80d0e76c1cadc7268bac2fe88eb7755b/.tmp/4a262ec7e7b544f98f318c5b23eba9c8
2017-02-22 10:35:48,156 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/80d0e76c1cadc7268bac2fe88eb7755b/.tmp/4a262ec7e7b544f98f318c5b23eba9c8 as file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/80d0e76c1cadc7268bac2fe88eb7755b/info/4a262ec7e7b544f98f318c5b23eba9c8
2017-02-22 10:35:48,157 INFO  [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=6, memsize=1.9 K, hasBloomFilter=false, into tmp file file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/.tmp/58bf1d5a8ff746cfb1cffc4a2fde3103
2017-02-22 10:35:48,158 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/80d0e76c1cadc7268bac2fe88eb7755b/info/4a262ec7e7b544f98f318c5b23eba9c8, entries=2, sequenceid=4, filesize=1.0 K
2017-02-22 10:35:48,158 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.HRegion(1986): Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b. in 29ms, sequenceid=4, compaction requested=false
2017-02-22 10:35:48,158 DEBUG [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/.tmp/58bf1d5a8ff746cfb1cffc4a2fde3103 as file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/info/58bf1d5a8ff746cfb1cffc4a2fde3103
2017-02-22 10:35:48,160 INFO  [StoreCloserThread-hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.-1] regionserver.HStore(780): Closed info
2017-02-22 10:35:48,160 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-1] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:48,160 INFO  [RS_CLOSE_REGION-192.168.1.25:51897-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:35:48,161 DEBUG [RS_CLOSE_REGION-192.168.1.25:51897-1] handler.CloseRegionHandler(182): Closed hbase:namespace,,1487756064725.80d0e76c1cadc7268bac2fe88eb7755b.
2017-02-22 10:35:48,161 INFO  [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/info/58bf1d5a8ff746cfb1cffc4a2fde3103, entries=8, sequenceid=6, filesize=1.8 K
2017-02-22 10:35:48,161 INFO  [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.HRegion(1986): Finished memstore flush of ~1.9 K/1976, currentsize=0/0 for region hbase:meta,,1.1588230740 in 30ms, sequenceid=6, compaction requested=false
2017-02-22 10:35:48,162 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:35:48,163 DEBUG [RS_CLOSE_META-192.168.1.25:51897-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:48,169 DEBUG [RS_CLOSE_META-192.168.1.25:51897-0] coprocessor.CoprocessorHost(316): Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2017-02-22 10:35:48,169 INFO  [RS_CLOSE_META-192.168.1.25:51897-0] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:35:48,169 DEBUG [RS_CLOSE_META-192.168.1.25:51897-0] handler.CloseRegionHandler(182): Closed hbase:meta,,1.1588230740
2017-02-22 10:35:48,197 INFO  [192.168.1.25,51895,1487756057370.splitLogManagerTimeoutMonitor] hbase.Chore(93): 192.168.1.25,51895,1487756057370.splitLogManagerTimeoutMonitor exiting
2017-02-22 10:35:48,334 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1037): stopping server 192.168.1.25,51897,1487756057911; all regions closed.
2017-02-22 10:35:48,335 DEBUG [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:35:48,335 INFO  [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncNotifier exiting
2017-02-22 10:35:48,335 DEBUG [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,335 INFO  [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer0 exiting
2017-02-22 10:35:48,336 DEBUG [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,336 INFO  [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer1 exiting
2017-02-22 10:35:48,336 DEBUG [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,336 INFO  [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer2 exiting
2017-02-22 10:35:48,336 DEBUG [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,336 INFO  [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer3 exiting
2017-02-22 10:35:48,337 DEBUG [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,337 INFO  [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncSyncer4 exiting
2017-02-22 10:35:48,337 DEBUG [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:35:48,337 INFO  [RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS_OPEN_META-192.168.1.25:51897-0-WAL.AsyncWriter exiting
2017-02-22 10:35:48,337 DEBUG [RS:0;192.168.1.25:51897] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,51897,1487756057911
2017-02-22 10:35:48,338 DEBUG [RS:0;192.168.1.25:51897-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS:0;192.168.1.25:51897-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:35:48,338 INFO  [RS:0;192.168.1.25:51897-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS:0;192.168.1.25:51897-WAL.AsyncNotifier exiting
2017-02-22 10:35:48,338 DEBUG [RS:0;192.168.1.25:51897-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51897-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,338 INFO  [RS:0;192.168.1.25:51897-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51897-WAL.AsyncSyncer0 exiting
2017-02-22 10:35:48,338 DEBUG [RS:0;192.168.1.25:51897-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51897-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,338 INFO  [RS:0;192.168.1.25:51897-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51897-WAL.AsyncSyncer1 exiting
2017-02-22 10:35:48,339 DEBUG [RS:0;192.168.1.25:51897-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51897-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,339 INFO  [RS:0;192.168.1.25:51897-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51897-WAL.AsyncSyncer2 exiting
2017-02-22 10:35:48,339 DEBUG [RS:0;192.168.1.25:51897-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51897-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,339 INFO  [RS:0;192.168.1.25:51897-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51897-WAL.AsyncSyncer3 exiting
2017-02-22 10:35:48,339 DEBUG [RS:0;192.168.1.25:51897-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51897-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:48,339 INFO  [RS:0;192.168.1.25:51897-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51897-WAL.AsyncSyncer4 exiting
2017-02-22 10:35:48,340 DEBUG [RS:0;192.168.1.25:51897-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS:0;192.168.1.25:51897-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:35:48,340 INFO  [RS:0;192.168.1.25:51897-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS:0;192.168.1.25:51897-WAL.AsyncWriter exiting
2017-02-22 10:35:48,340 DEBUG [RS:0;192.168.1.25:51897] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,51897,1487756057911
2017-02-22 10:35:48,342 DEBUG [RS:0;192.168.1.25:51897] wal.FSHLog(892): Moved 2 WAL file(s) to /var/tmp/test-data/cluster1/root/oldWALs
2017-02-22 10:35:48,342 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:48,343 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: closed
2017-02-22 10:35:48,343 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: stopped, connections 0
2017-02-22 10:35:48,343 DEBUG [RpcServer.reader=1,port=51895] ipc.RpcServer$Listener(910): RpcServer.listener,port=51895: DISCONNECTING client 192.168.1.25:51902 because read count=-1. Number of active connections: 2
2017-02-22 10:35:48,443 INFO  [RS:0;192.168.1.25:51897] regionserver.Leases(147): RS:0;192.168.1.25:51897 closing leases
2017-02-22 10:35:48,443 INFO  [RS:0;192.168.1.25:51897] regionserver.Leases(150): RS:0;192.168.1.25:51897 closed leases
2017-02-22 10:35:49,054 INFO  [M:0;192.168.1.25:51895] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51897,1487756057911
2017-02-22 10:35:49,187 INFO  [RS:0;192.168.1.25:51897.periodicFlusher] hbase.Chore(93): RS:0;192.168.1.25:51897.periodicFlusher exiting
2017-02-22 10:35:49,187 INFO  [RS:0;192.168.1.25:51897.leaseChecker] regionserver.Leases(147): RS:0;192.168.1.25:51897.leaseChecker closing leases
2017-02-22 10:35:49,188 INFO  [RS:0;192.168.1.25:51897.leaseChecker] regionserver.Leases(150): RS:0;192.168.1.25:51897.leaseChecker closed leases
2017-02-22 10:35:49,192 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/replication/rs/192.168.1.25,51897,1487756057911
2017-02-22 10:35:49,193 INFO  [RS:0;192.168.1.25:51897] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bd7820005
2017-02-22 10:35:49,194 DEBUG [RS:0;192.168.1.25:51897] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,195 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,51897,1487756057911
2017-02-22 10:35:49,195 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,51897,1487756057911
2017-02-22 10:35:49,195 INFO  [main-EventThread] zookeeper.RegionServerTracker(118): RegionServer ephemeral node deleted, processing expiration [192.168.1.25,51897,1487756057911]
2017-02-22 10:35:49,195 DEBUG [RS:0;192.168.1.25:51897-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51897-0x15a652bd7820002, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:35:49,196 INFO  [main-EventThread] master.ServerManager(550): Cluster shutdown set; 192.168.1.25,51897,1487756057911 expired; onlineServers=0
2017-02-22 10:35:49,196 DEBUG [M:0;192.168.1.25:51895] master.HMaster(1359): Stopping service threads
2017-02-22 10:35:49,196 INFO  [M:0;192.168.1.25:51895] ipc.RpcServer(2286): Stopping server on 51895
2017-02-22 10:35:49,196 INFO  [main-EventThread] master.HMaster(2748): Cluster shutdown set; onlineServer=0
2017-02-22 10:35:49,196 INFO  [RpcServer.listener,port=51895] ipc.RpcServer$Listener(823): RpcServer.listener,port=51895: stopping
2017-02-22 10:35:49,196 DEBUG [main-EventThread] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@42e065b0
2017-02-22 10:35:49,196 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:35:49,197 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:35:49,197 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:35:49,197 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:35:49,198 INFO  [M:0;192.168.1.25:51895.archivedHFileCleaner] hbase.Chore(93): M:0;192.168.1.25:51895.archivedHFileCleaner exiting
2017-02-22 10:35:49,198 INFO  [M:0;192.168.1.25:51895.oldLogCleaner] hbase.Chore(93): M:0;192.168.1.25:51895.oldLogCleaner exiting
2017-02-22 10:35:49,198 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1075): stopping server 192.168.1.25,51897,1487756057911; zookeeper connection closed.
2017-02-22 10:35:49,198 INFO  [RS:0;192.168.1.25:51897] regionserver.HRegionServer(1078): RS:0;192.168.1.25:51897 exiting
2017-02-22 10:35:49,198 INFO  [M:0;192.168.1.25:51895.oldLogCleaner] master.ReplicationLogCleaner(164): Stopping replicationLogCleaner-0x15a652bd7820004, quorum=localhost:16262, baseZNode=/hbase
2017-02-22 10:35:49,199 INFO  [Shutdown of org.apache.hadoop.hbase.fs.HFileSystem@67896c40] hbase.MiniHBaseCluster$SingleFileSystemShutdownThread(190): Hook closing fs=org.apache.hadoop.hbase.fs.HFileSystem@67896c40
2017-02-22 10:35:49,200 INFO  [main] util.JVMClusterUtil(325): Shutdown of 1 master(s) and 1 regionserver(s) complete
2017-02-22 10:35:49,200 INFO  [main] client.HConnectionManager$HConnectionImplementation(2322): Closing master protocol: MasterService
2017-02-22 10:35:49,200 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bd7820000
2017-02-22 10:35:49,201 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master
2017-02-22 10:35:49,202 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:51895-0x15a652bd7820001, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:35:49,203 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,204 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: closed
2017-02-22 10:35:49,204 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: closed
2017-02-22 10:35:49,204 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: stopped, connections 0
2017-02-22 10:35:49,204 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51895 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51895 from roger: stopped, connections 0
2017-02-22 10:35:49,304 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bf9a60006
2017-02-22 10:35:49,308 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,308 INFO  [main] client.HConnectionManager$HConnectionImplementation(2322): Closing master protocol: MasterService
2017-02-22 10:35:49,308 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652c12db0000
2017-02-22 10:35:49,310 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,312 DEBUG [RpcServer.reader=4,port=51925] ipc.RpcServer$Listener(910): RpcServer.listener,port=51925: DISCONNECTING client 192.168.1.25:51954 because read count=-1. Number of active connections: 3
2017-02-22 10:35:49,312 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: closed
2017-02-22 10:35:49,312 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: closed
2017-02-22 10:35:49,312 DEBUG [RpcServer.reader=2,port=51923] ipc.RpcServer$Listener(910): RpcServer.listener,port=51923: DISCONNECTING client 192.168.1.25:51952 because read count=-1. Number of active connections: 2
2017-02-22 10:35:49,312 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: stopped, connections 0
2017-02-22 10:35:49,312 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: stopped, connections 0
2017-02-22 10:35:49,410 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652c12db0006
2017-02-22 10:35:49,415 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,415 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bd7820006
2017-02-22 10:35:49,417 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,417 INFO  [main] client.HConnectionManager$HConnectionImplementation(2322): Closing master protocol: MasterService
2017-02-22 10:35:49,417 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bf9a60000
2017-02-22 10:35:49,422 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,423 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: closed
2017-02-22 10:35:49,423 DEBUG [RpcServer.reader=4,port=51911] ipc.RpcServer$Listener(910): RpcServer.listener,port=51911: DISCONNECTING client 192.168.1.25:51949 because read count=-1. Number of active connections: 3
2017-02-22 10:35:49,423 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: stopped, connections 0
2017-02-22 10:35:49,423 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: closed
2017-02-22 10:35:49,423 DEBUG [RpcServer.reader=2,port=51909] ipc.RpcServer$Listener(910): RpcServer.listener,port=51909: DISCONNECTING client 192.168.1.25:51947 because read count=-1. Number of active connections: 2
2017-02-22 10:35:49,424 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: stopped, connections 0
2017-02-22 10:35:49,523 DEBUG [main] util.JVMClusterUtil(241): Shutting down HBase Cluster
2017-02-22 10:35:49,524 INFO  [main] master.HMaster(2748): Cluster shutdown requested
2017-02-22 10:35:49,526 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:49,526 INFO  [192.168.1.25,51909,1487756065220-BalancerChore] hbase.Chore(93): 192.168.1.25,51909,1487756065220-BalancerChore exiting
2017-02-22 10:35:49,526 INFO  [192.168.1.25,51909,1487756065220-ClusterStatusChore] hbase.Chore(93): 192.168.1.25,51909,1487756065220-ClusterStatusChore exiting
2017-02-22 10:35:49,527 INFO  [CatalogJanitor-192.168.1.25:51909] hbase.Chore(93): CatalogJanitor-192.168.1.25:51909 exiting
2017-02-22 10:35:49,529 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:35:49,529 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:35:49,529 INFO  [main] regionserver.HRegionServer(1865): STOPPED: Shutdown requested
2017-02-22 10:35:49,529 INFO  [M:0;192.168.1.25:51895] master.HMaster(733): HMaster main thread exiting
2017-02-22 10:35:49,529 INFO  [RS:0;192.168.1.25:51911] ipc.RpcServer(2286): Stopping server on 51911
2017-02-22 10:35:49,529 INFO  [RpcServer.listener,port=51911] ipc.RpcServer$Listener(823): RpcServer.listener,port=51911: stopping
2017-02-22 10:35:49,529 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:35:49,530 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZKUtil(368): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:35:49,531 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:35:49,531 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:35:49,531 INFO  [RS:0;192.168.1.25:51911] regionserver.SplitLogWorker(604): Sending interrupt to stop the worker thread
2017-02-22 10:35:49,531 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:35:49,531 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(971): Stopping infoServer
2017-02-22 10:35:49,532 INFO  [SplitLogWorker-192.168.1.25,51911,1487756065280] regionserver.SplitLogWorker(295): SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2017-02-22 10:35:49,532 INFO  [SplitLogWorker-192.168.1.25,51911,1487756065280] regionserver.SplitLogWorker(212): SplitLogWorker 192.168.1.25,51911,1487756065280 exiting
2017-02-22 10:35:49,650 INFO  [RS:0;192.168.1.25:51911] snapshot.RegionServerSnapshotManager(136): Stopping RegionServerSnapshotManager gracefully.
2017-02-22 10:35:49,650 INFO  [RS:0;192.168.1.25:51911.logRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:35:49,650 INFO  [RS:0;192.168.1.25:51911.compactionChecker] hbase.Chore(93): RS:0;192.168.1.25:51911.compactionChecker exiting
2017-02-22 10:35:49,650 INFO  [192.168.1.25,51911,1487756065280-HeapMemoryChore] hbase.Chore(93): 192.168.1.25,51911,1487756065280-HeapMemoryChore exiting
2017-02-22 10:35:49,650 INFO  [RS:0;192.168.1.25:51911.nonceCleaner] hbase.Chore(93): RS:0;192.168.1.25:51911.nonceCleaner exiting
2017-02-22 10:35:49,650 INFO  [RS_OPEN_META-192.168.1.25:51911-0-MetaLogRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:35:49,650 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.1 exiting
2017-02-22 10:35:49,651 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1018): stopping server 192.168.1.25,51911,1487756065280
2017-02-22 10:35:49,651 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.0 exiting
2017-02-22 10:35:49,652 DEBUG [RS:0;192.168.1.25:51911] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3f2ab743
2017-02-22 10:35:49,651 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-1] handler.CloseRegionHandler(128): Processing close of hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:35:49,652 INFO  [RS:0;192.168.1.25:51911] regionserver.CompactSplitThread(381): Waiting for Split Thread to finish...
2017-02-22 10:35:49,652 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.: disabling compactions & flushes
2017-02-22 10:35:49,652 INFO  [RS:0;192.168.1.25:51911] regionserver.CompactSplitThread(381): Waiting for Merge Thread to finish...
2017-02-22 10:35:49,653 INFO  [RS:0;192.168.1.25:51911] regionserver.CompactSplitThread(381): Waiting for Large Compaction Thread to finish...
2017-02-22 10:35:49,653 INFO  [RS:0;192.168.1.25:51911] regionserver.CompactSplitThread(381): Waiting for Small Compaction Thread to finish...
2017-02-22 10:35:49,653 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:35:49,653 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.HRegion(1819): Started memstore flush for hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f., current region memstore size 344
2017-02-22 10:35:49,653 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1231): Waiting on 2 regions to close
2017-02-22 10:35:49,653 DEBUG [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1235): {27f513717656a2c439f2478fb0dfb75f=hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f., 1588230740=hbase:meta,,1.1588230740}
2017-02-22 10:35:49,653 DEBUG [RS_CLOSE_META-192.168.1.25:51911-0] handler.CloseRegionHandler(128): Processing close of hbase:meta,,1.1588230740
2017-02-22 10:35:49,654 DEBUG [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:35:49,654 DEBUG [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:35:49,654 INFO  [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.HRegion(1819): Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.9 K
2017-02-22 10:35:49,677 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/27f513717656a2c439f2478fb0dfb75f/.tmp/312480a50de447a083fff775a819c91a
2017-02-22 10:35:49,679 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/27f513717656a2c439f2478fb0dfb75f/.tmp/312480a50de447a083fff775a819c91a as file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/27f513717656a2c439f2478fb0dfb75f/info/312480a50de447a083fff775a819c91a
2017-02-22 10:35:49,680 INFO  [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=6, memsize=1.9 K, hasBloomFilter=false, into tmp file file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/.tmp/c5a06172ffb7428fbce60e1bd98d5877
2017-02-22 10:35:49,681 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/27f513717656a2c439f2478fb0dfb75f/info/312480a50de447a083fff775a819c91a, entries=2, sequenceid=4, filesize=1.0 K
2017-02-22 10:35:49,681 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.HRegion(1986): Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f. in 28ms, sequenceid=4, compaction requested=false
2017-02-22 10:35:49,682 DEBUG [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/.tmp/c5a06172ffb7428fbce60e1bd98d5877 as file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/info/c5a06172ffb7428fbce60e1bd98d5877
2017-02-22 10:35:49,682 INFO  [StoreCloserThread-hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.-1] regionserver.HStore(780): Closed info
2017-02-22 10:35:49,683 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-1] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:49,683 INFO  [RS_CLOSE_REGION-192.168.1.25:51911-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:35:49,683 DEBUG [RS_CLOSE_REGION-192.168.1.25:51911-1] handler.CloseRegionHandler(182): Closed hbase:namespace,,1487756071380.27f513717656a2c439f2478fb0dfb75f.
2017-02-22 10:35:49,684 INFO  [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/info/c5a06172ffb7428fbce60e1bd98d5877, entries=8, sequenceid=6, filesize=1.8 K
2017-02-22 10:35:49,684 INFO  [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.HRegion(1986): Finished memstore flush of ~1.9 K/1976, currentsize=0/0 for region hbase:meta,,1.1588230740 in 30ms, sequenceid=6, compaction requested=false
2017-02-22 10:35:49,685 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:35:49,685 DEBUG [RS_CLOSE_META-192.168.1.25:51911-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:49,690 DEBUG [RS_CLOSE_META-192.168.1.25:51911-0] coprocessor.CoprocessorHost(316): Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2017-02-22 10:35:49,690 INFO  [RS_CLOSE_META-192.168.1.25:51911-0] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:35:49,690 DEBUG [RS_CLOSE_META-192.168.1.25:51911-0] handler.CloseRegionHandler(182): Closed hbase:meta,,1.1588230740
2017-02-22 10:35:49,855 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1037): stopping server 192.168.1.25,51911,1487756065280; all regions closed.
2017-02-22 10:35:49,855 DEBUG [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:35:49,856 INFO  [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncNotifier exiting
2017-02-22 10:35:49,856 DEBUG [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,856 INFO  [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer0 exiting
2017-02-22 10:35:49,856 DEBUG [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,856 INFO  [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer1 exiting
2017-02-22 10:35:49,856 DEBUG [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,857 INFO  [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer2 exiting
2017-02-22 10:35:49,857 DEBUG [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,857 INFO  [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer3 exiting
2017-02-22 10:35:49,857 DEBUG [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,857 INFO  [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncSyncer4 exiting
2017-02-22 10:35:49,857 DEBUG [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:35:49,857 INFO  [RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS_OPEN_META-192.168.1.25:51911-0-WAL.AsyncWriter exiting
2017-02-22 10:35:49,857 DEBUG [RS:0;192.168.1.25:51911] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,51911,1487756065280
2017-02-22 10:35:49,858 DEBUG [RS:0;192.168.1.25:51911-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS:0;192.168.1.25:51911-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:35:49,858 INFO  [RS:0;192.168.1.25:51911-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS:0;192.168.1.25:51911-WAL.AsyncNotifier exiting
2017-02-22 10:35:49,858 DEBUG [RS:0;192.168.1.25:51911-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51911-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,858 INFO  [RS:0;192.168.1.25:51911-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51911-WAL.AsyncSyncer0 exiting
2017-02-22 10:35:49,858 DEBUG [RS:0;192.168.1.25:51911-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51911-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,859 INFO  [RS:0;192.168.1.25:51911-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51911-WAL.AsyncSyncer1 exiting
2017-02-22 10:35:49,859 DEBUG [RS:0;192.168.1.25:51911-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51911-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,859 INFO  [RS:0;192.168.1.25:51911-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51911-WAL.AsyncSyncer2 exiting
2017-02-22 10:35:49,859 DEBUG [RS:0;192.168.1.25:51911-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51911-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,859 INFO  [RS:0;192.168.1.25:51911-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51911-WAL.AsyncSyncer3 exiting
2017-02-22 10:35:49,859 DEBUG [RS:0;192.168.1.25:51911-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51911-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:49,859 INFO  [RS:0;192.168.1.25:51911-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51911-WAL.AsyncSyncer4 exiting
2017-02-22 10:35:49,859 DEBUG [RS:0;192.168.1.25:51911-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS:0;192.168.1.25:51911-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:35:49,859 INFO  [RS:0;192.168.1.25:51911-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS:0;192.168.1.25:51911-WAL.AsyncWriter exiting
2017-02-22 10:35:49,859 DEBUG [RS:0;192.168.1.25:51911] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,51911,1487756065280
2017-02-22 10:35:49,861 DEBUG [RS:0;192.168.1.25:51911] wal.FSHLog(892): Moved 2 WAL file(s) to /var/tmp/test-data/cluster2/root/oldWALs
2017-02-22 10:35:49,861 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:49,862 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: closed
2017-02-22 10:35:49,862 DEBUG [RpcServer.reader=1,port=51909] ipc.RpcServer$Listener(910): RpcServer.listener,port=51909: DISCONNECTING client 192.168.1.25:51915 because read count=-1. Number of active connections: 1
2017-02-22 10:35:49,862 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51909 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51909 from roger: stopped, connections 0
2017-02-22 10:35:49,962 INFO  [RS:0;192.168.1.25:51911] regionserver.Leases(147): RS:0;192.168.1.25:51911 closing leases
2017-02-22 10:35:49,962 INFO  [RS:0;192.168.1.25:51911] regionserver.Leases(150): RS:0;192.168.1.25:51911 closed leases
2017-02-22 10:35:50,034 INFO  [192.168.1.25,51909,1487756065220.splitLogManagerTimeoutMonitor] hbase.Chore(93): 192.168.1.25,51909,1487756065220.splitLogManagerTimeoutMonitor exiting
2017-02-22 10:35:50,413 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 27 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:50,414 DEBUG [FifoRpcScheduler.handler7-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 8 bytes.
2017-02-22 10:35:50,414 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 27, totalSize: 4 bytes
2017-02-22 10:35:50,563 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:51,597 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:52,642 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:53,420 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 28 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:53,420 DEBUG [FifoRpcScheduler.handler7-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 8 bytes.
2017-02-22 10:35:53,420 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 28, totalSize: 4 bytes
2017-02-22 10:35:53,675 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:54,020 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: closed
2017-02-22 10:35:54,020 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: stopped, connections 1
2017-02-22 10:35:54,194 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: closed
2017-02-22 10:35:54,195 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51897 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: stopped, connections 0
2017-02-22 10:35:54,708 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:55,533 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: closed
2017-02-22 10:35:55,533 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: stopped, connections 1
2017-02-22 10:35:55,548 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: closed
2017-02-22 10:35:55,548 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51911 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: stopped, connections 0
2017-02-22 10:35:55,749 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:56,424 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: wrote request header call_id: 29 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:35:56,424 DEBUG [FifoRpcScheduler.handler7-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 8 bytes.
2017-02-22 10:35:56,424 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: got response header call_id: 29, totalSize: 4 bytes
2017-02-22 10:35:56,780 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:56,803 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: closed
2017-02-22 10:35:56,803 DEBUG [RpcServer.reader=3,port=51925] ipc.RpcServer$Listener(910): RpcServer.listener,port=51925: DISCONNECTING client 192.168.1.25:51953 because read count=-1. Number of active connections: 2
2017-02-22 10:35:56,803 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: stopped, connections 1
2017-02-22 10:35:56,819 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: closed
2017-02-22 10:35:56,819 DEBUG [RpcServer.reader=5,port=51925] ipc.RpcServer$Listener(910): RpcServer.listener,port=51925: DISCONNECTING client 192.168.1.25:51955 because read count=-1. Number of active connections: 1
2017-02-22 10:35:56,819 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51925 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: stopped, connections 0
2017-02-22 10:35:57,808 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:58,853 INFO  [M:0;192.168.1.25:51909] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51911,1487756065280
2017-02-22 10:35:58,909 INFO  [RS:0;192.168.1.25:51911.leaseChecker] regionserver.Leases(147): RS:0;192.168.1.25:51911.leaseChecker closing leases
2017-02-22 10:35:58,909 INFO  [RS:0;192.168.1.25:51911.periodicFlusher] hbase.Chore(93): RS:0;192.168.1.25:51911.periodicFlusher exiting
2017-02-22 10:35:58,909 INFO  [RS:0;192.168.1.25:51911.leaseChecker] regionserver.Leases(150): RS:0;192.168.1.25:51911.leaseChecker closed leases
2017-02-22 10:35:58,914 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/replication/rs/192.168.1.25,51911,1487756065280
2017-02-22 10:35:58,914 INFO  [RS:0;192.168.1.25:51911] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bf9a60005
2017-02-22 10:35:58,916 DEBUG [RS:0;192.168.1.25:51911] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:58,918 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,51911,1487756065280
2017-02-22 10:35:58,918 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,51911,1487756065280
2017-02-22 10:35:58,918 INFO  [main-EventThread] zookeeper.RegionServerTracker(118): RegionServer ephemeral node deleted, processing expiration [192.168.1.25,51911,1487756065280]
2017-02-22 10:35:58,918 DEBUG [RS:0;192.168.1.25:51911-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51911-0x15a652bf9a60003, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:35:58,919 INFO  [main-EventThread] master.ServerManager(550): Cluster shutdown set; 192.168.1.25,51911,1487756065280 expired; onlineServers=0
2017-02-22 10:35:58,919 DEBUG [M:0;192.168.1.25:51909] master.HMaster(1359): Stopping service threads
2017-02-22 10:35:58,919 INFO  [M:0;192.168.1.25:51909] ipc.RpcServer(2286): Stopping server on 51909
2017-02-22 10:35:58,919 INFO  [main-EventThread] master.HMaster(2748): Cluster shutdown set; onlineServer=0
2017-02-22 10:35:58,919 INFO  [RpcServer.listener,port=51909] ipc.RpcServer$Listener(823): RpcServer.listener,port=51909: stopping
2017-02-22 10:35:58,920 DEBUG [main-EventThread] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3320b427
2017-02-22 10:35:58,920 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:35:58,921 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:35:58,921 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:35:58,922 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:35:58,922 INFO  [M:0;192.168.1.25:51909.oldLogCleaner] hbase.Chore(93): M:0;192.168.1.25:51909.oldLogCleaner exiting
2017-02-22 10:35:58,922 INFO  [M:0;192.168.1.25:51909.archivedHFileCleaner] hbase.Chore(93): M:0;192.168.1.25:51909.archivedHFileCleaner exiting
2017-02-22 10:35:58,922 INFO  [M:0;192.168.1.25:51909.oldLogCleaner] master.ReplicationLogCleaner(164): Stopping replicationLogCleaner-0x15a652bf9a60004, quorum=localhost:26262, baseZNode=/hbase
2017-02-22 10:35:58,924 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1075): stopping server 192.168.1.25,51911,1487756065280; zookeeper connection closed.
2017-02-22 10:35:58,925 INFO  [RS:0;192.168.1.25:51911] regionserver.HRegionServer(1078): RS:0;192.168.1.25:51911 exiting
2017-02-22 10:35:58,926 INFO  [Shutdown of org.apache.hadoop.hbase.fs.HFileSystem@6e7bf8f4] hbase.MiniHBaseCluster$SingleFileSystemShutdownThread(190): Hook closing fs=org.apache.hadoop.hbase.fs.HFileSystem@6e7bf8f4
2017-02-22 10:35:58,928 INFO  [main] util.JVMClusterUtil(325): Shutdown of 1 master(s) and 1 regionserver(s) complete
2017-02-22 10:35:58,928 DEBUG [main] util.JVMClusterUtil(241): Shutting down HBase Cluster
2017-02-22 10:35:58,928 INFO  [main] master.HMaster(2748): Cluster shutdown requested
2017-02-22 10:35:58,929 INFO  [M:0;192.168.1.25:51923] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51925,1487756071702
2017-02-22 10:35:58,930 INFO  [CatalogJanitor-192.168.1.25:51923] hbase.Chore(93): CatalogJanitor-192.168.1.25:51923 exiting
2017-02-22 10:35:58,930 INFO  [192.168.1.25,51923,1487756071661-ClusterStatusChore] hbase.Chore(93): 192.168.1.25,51923,1487756071661-ClusterStatusChore exiting
2017-02-22 10:35:58,930 INFO  [192.168.1.25,51923,1487756071661-BalancerChore] hbase.Chore(93): 192.168.1.25,51923,1487756071661-BalancerChore exiting
2017-02-22 10:35:58,931 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master
2017-02-22 10:35:58,932 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:35:58,932 INFO  [main] regionserver.HRegionServer(1865): STOPPED: Shutdown requested
2017-02-22 10:35:58,933 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:35:58,934 INFO  [RS:0;192.168.1.25:51925] ipc.RpcServer(2286): Stopping server on 51925
2017-02-22 10:35:58,935 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:51909-0x15a652bf9a60001, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:35:58,935 INFO  [RpcServer.listener,port=51925] ipc.RpcServer$Listener(823): RpcServer.listener,port=51925: stopping
2017-02-22 10:35:58,938 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZKUtil(368): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:35:58,939 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:35:58,939 INFO  [M:0;192.168.1.25:51909] master.HMaster(733): HMaster main thread exiting
2017-02-22 10:35:58,939 INFO  [RS:0;192.168.1.25:51925] regionserver.SplitLogWorker(604): Sending interrupt to stop the worker thread
2017-02-22 10:35:58,940 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:35:58,940 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:35:58,940 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:35:58,941 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(971): Stopping infoServer
2017-02-22 10:35:58,943 INFO  [SplitLogWorker-192.168.1.25,51925,1487756071702] regionserver.SplitLogWorker(295): SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2017-02-22 10:35:58,943 INFO  [SplitLogWorker-192.168.1.25,51925,1487756071702] regionserver.SplitLogWorker(212): SplitLogWorker 192.168.1.25,51925,1487756071702 exiting
2017-02-22 10:35:58,955 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.0 exiting
2017-02-22 10:35:58,955 INFO  [RS:0;192.168.1.25:51925] snapshot.RegionServerSnapshotManager(136): Stopping RegionServerSnapshotManager gracefully.
2017-02-22 10:35:58,956 INFO  [RS_OPEN_META-192.168.1.25:51925-0-MetaLogRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:35:58,956 INFO  [RS:0;192.168.1.25:51925.nonceCleaner] hbase.Chore(93): RS:0;192.168.1.25:51925.nonceCleaner exiting
2017-02-22 10:35:58,955 INFO  [RS:0;192.168.1.25:51925.logRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:35:58,955 INFO  [192.168.1.25,51925,1487756071702-HeapMemoryChore] hbase.Chore(93): 192.168.1.25,51925,1487756071702-HeapMemoryChore exiting
2017-02-22 10:35:58,956 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.1 exiting
2017-02-22 10:35:58,956 INFO  [RS:0;192.168.1.25:51925.compactionChecker] hbase.Chore(93): RS:0;192.168.1.25:51925.compactionChecker exiting
2017-02-22 10:35:58,956 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1018): stopping server 192.168.1.25,51925,1487756071702
2017-02-22 10:35:58,956 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-1] handler.CloseRegionHandler(128): Processing close of hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:35:58,956 DEBUG [RS:0;192.168.1.25:51925] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@107901f7
2017-02-22 10:35:58,957 INFO  [RS:0;192.168.1.25:51925] regionserver.CompactSplitThread(381): Waiting for Split Thread to finish...
2017-02-22 10:35:58,957 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.: disabling compactions & flushes
2017-02-22 10:35:58,957 INFO  [RS:0;192.168.1.25:51925] regionserver.CompactSplitThread(381): Waiting for Merge Thread to finish...
2017-02-22 10:35:58,957 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:35:58,957 INFO  [RS:0;192.168.1.25:51925] regionserver.CompactSplitThread(381): Waiting for Large Compaction Thread to finish...
2017-02-22 10:35:58,957 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.HRegion(1819): Started memstore flush for hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42., current region memstore size 344
2017-02-22 10:35:58,957 INFO  [RS:0;192.168.1.25:51925] regionserver.CompactSplitThread(381): Waiting for Small Compaction Thread to finish...
2017-02-22 10:35:58,958 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1231): Waiting on 2 regions to close
2017-02-22 10:35:58,958 DEBUG [RS_CLOSE_META-192.168.1.25:51925-0] handler.CloseRegionHandler(128): Processing close of hbase:meta,,1.1588230740
2017-02-22 10:35:58,958 DEBUG [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1235): {1588230740=hbase:meta,,1.1588230740, 7bfc107b17904a0cce41388d3ef6cf42=hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.}
2017-02-22 10:35:58,959 DEBUG [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:35:58,959 DEBUG [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:35:58,959 INFO  [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.HRegion(1819): Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.9 K
2017-02-22 10:35:58,995 INFO  [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=6, memsize=1.9 K, hasBloomFilter=false, into tmp file file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/.tmp/1eaaf9f524e24d39a44fd0d38939ce9a
2017-02-22 10:35:58,997 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/7bfc107b17904a0cce41388d3ef6cf42/.tmp/9bbdfe50f3bb492682519a23fa484d68
2017-02-22 10:35:58,999 DEBUG [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/.tmp/1eaaf9f524e24d39a44fd0d38939ce9a as file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/info/1eaaf9f524e24d39a44fd0d38939ce9a
2017-02-22 10:35:59,000 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/7bfc107b17904a0cce41388d3ef6cf42/.tmp/9bbdfe50f3bb492682519a23fa484d68 as file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/7bfc107b17904a0cce41388d3ef6cf42/info/9bbdfe50f3bb492682519a23fa484d68
2017-02-22 10:35:59,005 INFO  [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/info/1eaaf9f524e24d39a44fd0d38939ce9a, entries=8, sequenceid=6, filesize=1.8 K
2017-02-22 10:35:59,007 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/7bfc107b17904a0cce41388d3ef6cf42/info/9bbdfe50f3bb492682519a23fa484d68, entries=2, sequenceid=4, filesize=1.0 K
2017-02-22 10:35:59,007 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.HRegion(1986): Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42. in 50ms, sequenceid=4, compaction requested=false
2017-02-22 10:35:59,007 INFO  [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.HRegion(1986): Finished memstore flush of ~1.9 K/1976, currentsize=0/0 for region hbase:meta,,1.1588230740 in 48ms, sequenceid=6, compaction requested=false
2017-02-22 10:35:59,013 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:35:59,015 INFO  [StoreCloserThread-hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.-1] regionserver.HStore(780): Closed info
2017-02-22 10:35:59,015 DEBUG [RS_CLOSE_META-192.168.1.25:51925-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:59,015 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-1] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:35:59,015 INFO  [RS_CLOSE_REGION-192.168.1.25:51925-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:35:59,015 DEBUG [RS_CLOSE_REGION-192.168.1.25:51925-1] handler.CloseRegionHandler(182): Closed hbase:namespace,,1487756077664.7bfc107b17904a0cce41388d3ef6cf42.
2017-02-22 10:35:59,019 DEBUG [RS_CLOSE_META-192.168.1.25:51925-0] coprocessor.CoprocessorHost(316): Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2017-02-22 10:35:59,019 INFO  [RS_CLOSE_META-192.168.1.25:51925-0] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:35:59,019 DEBUG [RS_CLOSE_META-192.168.1.25:51925-0] handler.CloseRegionHandler(182): Closed hbase:meta,,1.1588230740
2017-02-22 10:35:59,163 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1037): stopping server 192.168.1.25,51925,1487756071702; all regions closed.
2017-02-22 10:35:59,163 DEBUG [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:35:59,163 INFO  [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncNotifier exiting
2017-02-22 10:35:59,164 DEBUG [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,164 INFO  [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer0 exiting
2017-02-22 10:35:59,164 DEBUG [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,164 INFO  [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer1 exiting
2017-02-22 10:35:59,165 DEBUG [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,165 INFO  [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer2 exiting
2017-02-22 10:35:59,165 DEBUG [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,165 INFO  [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer3 exiting
2017-02-22 10:35:59,165 DEBUG [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,165 INFO  [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncSyncer4 exiting
2017-02-22 10:35:59,166 DEBUG [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:35:59,166 INFO  [RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS_OPEN_META-192.168.1.25:51925-0-WAL.AsyncWriter exiting
2017-02-22 10:35:59,166 DEBUG [RS:0;192.168.1.25:51925] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,51925,1487756071702
2017-02-22 10:35:59,167 DEBUG [RS:0;192.168.1.25:51925-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS:0;192.168.1.25:51925-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:35:59,167 INFO  [RS:0;192.168.1.25:51925-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS:0;192.168.1.25:51925-WAL.AsyncNotifier exiting
2017-02-22 10:35:59,167 DEBUG [RS:0;192.168.1.25:51925-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51925-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,167 INFO  [RS:0;192.168.1.25:51925-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51925-WAL.AsyncSyncer0 exiting
2017-02-22 10:35:59,167 DEBUG [RS:0;192.168.1.25:51925-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51925-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,167 INFO  [RS:0;192.168.1.25:51925-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51925-WAL.AsyncSyncer1 exiting
2017-02-22 10:35:59,167 DEBUG [RS:0;192.168.1.25:51925-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51925-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,167 INFO  [RS:0;192.168.1.25:51925-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51925-WAL.AsyncSyncer2 exiting
2017-02-22 10:35:59,168 DEBUG [RS:0;192.168.1.25:51925-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51925-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,168 INFO  [RS:0;192.168.1.25:51925-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51925-WAL.AsyncSyncer3 exiting
2017-02-22 10:35:59,168 DEBUG [RS:0;192.168.1.25:51925-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:51925-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:35:59,168 INFO  [RS:0;192.168.1.25:51925-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:51925-WAL.AsyncSyncer4 exiting
2017-02-22 10:35:59,168 DEBUG [RS:0;192.168.1.25:51925-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS:0;192.168.1.25:51925-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:35:59,168 INFO  [RS:0;192.168.1.25:51925-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS:0;192.168.1.25:51925-WAL.AsyncWriter exiting
2017-02-22 10:35:59,168 DEBUG [RS:0;192.168.1.25:51925] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,51925,1487756071702
2017-02-22 10:35:59,172 DEBUG [RS:0;192.168.1.25:51925] wal.FSHLog(892): Moved 2 WAL file(s) to /var/tmp/test-data/cluster3/root/oldWALs
2017-02-22 10:35:59,172 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:35:59,175 DEBUG [RpcServer.reader=1,port=51923] ipc.RpcServer$Listener(910): RpcServer.listener,port=51923: DISCONNECTING client 192.168.1.25:51929 because read count=-1. Number of active connections: 1
2017-02-22 10:35:59,175 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: closed
2017-02-22 10:35:59,175 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:51923 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:51923 from roger: stopped, connections 0
2017-02-22 10:35:59,276 INFO  [RS:0;192.168.1.25:51925] regionserver.Leases(147): RS:0;192.168.1.25:51925 closing leases
2017-02-22 10:35:59,276 INFO  [RS:0;192.168.1.25:51925] regionserver.Leases(150): RS:0;192.168.1.25:51925 closed leases
2017-02-22 10:35:59,352 INFO  [192.168.1.25,51923,1487756071661.splitLogManagerTimeoutMonitor] hbase.Chore(93): 192.168.1.25,51923,1487756071661.splitLogManagerTimeoutMonitor exiting
2017-02-22 10:35:59,968 INFO  [M:0;192.168.1.25:51923] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51925,1487756071702
2017-02-22 10:36:01,013 INFO  [M:0;192.168.1.25:51923] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51925,1487756071702
2017-02-22 10:36:02,057 INFO  [M:0;192.168.1.25:51923] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51925,1487756071702
2017-02-22 10:36:03,081 INFO  [M:0;192.168.1.25:51923] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51925,1487756071702
2017-02-22 10:36:04,124 INFO  [M:0;192.168.1.25:51923] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51925,1487756071702
2017-02-22 10:36:05,169 INFO  [M:0;192.168.1.25:51923] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,51925,1487756071702
2017-02-22 10:36:05,220 INFO  [RS:0;192.168.1.25:51925.leaseChecker] regionserver.Leases(147): RS:0;192.168.1.25:51925.leaseChecker closing leases
2017-02-22 10:36:05,220 INFO  [RS:0;192.168.1.25:51925.leaseChecker] regionserver.Leases(150): RS:0;192.168.1.25:51925.leaseChecker closed leases
2017-02-22 10:36:05,220 INFO  [RS:0;192.168.1.25:51925.periodicFlusher] hbase.Chore(93): RS:0;192.168.1.25:51925.periodicFlusher exiting
2017-02-22 10:36:05,225 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/replication/rs/192.168.1.25,51925,1487756071702
2017-02-22 10:36:05,225 INFO  [RS:0;192.168.1.25:51925] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652c12db0005
2017-02-22 10:36:05,228 DEBUG [RS:0;192.168.1.25:51925] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:36:05,230 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,51925,1487756071702
2017-02-22 10:36:05,230 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,51925,1487756071702
2017-02-22 10:36:05,230 INFO  [main-EventThread] zookeeper.RegionServerTracker(118): RegionServer ephemeral node deleted, processing expiration [192.168.1.25,51925,1487756071702]
2017-02-22 10:36:05,230 DEBUG [RS:0;192.168.1.25:51925-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:51925-0x15a652c12db0003, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:36:05,231 INFO  [main-EventThread] master.ServerManager(550): Cluster shutdown set; 192.168.1.25,51925,1487756071702 expired; onlineServers=0
2017-02-22 10:36:05,231 INFO  [main-EventThread] master.HMaster(2748): Cluster shutdown set; onlineServer=0
2017-02-22 10:36:05,231 DEBUG [main-EventThread] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3b1b0696
2017-02-22 10:36:05,231 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:36:05,232 DEBUG [M:0;192.168.1.25:51923] master.HMaster(1359): Stopping service threads
2017-02-22 10:36:05,232 INFO  [M:0;192.168.1.25:51923] ipc.RpcServer(2286): Stopping server on 51923
2017-02-22 10:36:05,232 INFO  [RpcServer.listener,port=51923] ipc.RpcServer$Listener(823): RpcServer.listener,port=51923: stopping
2017-02-22 10:36:05,234 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:36:05,234 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:36:05,234 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:36:05,234 INFO  [M:0;192.168.1.25:51923.archivedHFileCleaner] hbase.Chore(93): M:0;192.168.1.25:51923.archivedHFileCleaner exiting
2017-02-22 10:36:05,235 INFO  [M:0;192.168.1.25:51923.oldLogCleaner] hbase.Chore(93): M:0;192.168.1.25:51923.oldLogCleaner exiting
2017-02-22 10:36:05,235 INFO  [M:0;192.168.1.25:51923.oldLogCleaner] master.ReplicationLogCleaner(164): Stopping replicationLogCleaner-0x15a652c12db0004, quorum=localhost:36262, baseZNode=/hbase
2017-02-22 10:36:05,238 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1075): stopping server 192.168.1.25,51925,1487756071702; zookeeper connection closed.
2017-02-22 10:36:05,238 INFO  [RS:0;192.168.1.25:51925] regionserver.HRegionServer(1078): RS:0;192.168.1.25:51925 exiting
2017-02-22 10:36:05,239 INFO  [Shutdown of org.apache.hadoop.hbase.fs.HFileSystem@339ff2e3] hbase.MiniHBaseCluster$SingleFileSystemShutdownThread(190): Hook closing fs=org.apache.hadoop.hbase.fs.HFileSystem@339ff2e3
2017-02-22 10:36:05,239 INFO  [main] util.JVMClusterUtil(325): Shutdown of 1 master(s) and 1 regionserver(s) complete
2017-02-22 10:36:05,242 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master
2017-02-22 10:36:05,244 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:51923-0x15a652c12db0001, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:36:05,245 INFO  [M:0;192.168.1.25:51923] master.HMaster(733): HMaster main thread exiting
2017-02-22 10:36:16,977 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x70e8f8e] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x70e8f8e exiting
2017-02-22 10:36:19,212 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x3c28b592] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x3c28b592 exiting
2017-02-22 10:36:19,264 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x34904cda] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x34904cda exiting
2017-02-22 10:36:25,211 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x774698ab] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x774698ab exiting
2017-02-22 10:36:28,913 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x69112497] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x69112497 exiting
2017-02-22 10:36:28,954 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x56d7edd4] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x56d7edd4 exiting
2017-02-22 10:36:31,657 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x47db5fa5] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x47db5fa5 exiting
2017-02-22 10:36:35,229 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0xca4cdae] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0xca4cdae exiting
2017-02-22 10:36:35,259 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x7d1da7b1] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x7d1da7b1 exiting
2017-02-22 10:38:03,286 DEBUG [main] zookeeper.MiniZooKeeperCluster(172): Failed binding ZK Server to client port: 16262
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:95)
	at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:167)
	at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:131)
	at pt.uminho.haslab.testingutils.ShareCluster.<init>(ShareCluster.java:49)
	at pt.uminho.haslab.smcoprocessors.TestCoprocessorBoot.<init>(TestCoprocessorBoot.java:22)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:195)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:244)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:241)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2017-02-22 10:38:03,288 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x27e0f2f5 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:38:03,293 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x27e0f2f50x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:03,293 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x27e0f2f5-0x15a652bd782000e connected
2017-02-22 10:38:03,294 DEBUG [main] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@db44aa2, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:03,295 DEBUG [main] client.HConnectionManager(2976): master//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:38:03,297 INFO  [main] ipc.RpcServer$Listener(649): master//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:38:03,306 INFO  [main] master.HMaster(547): hbase.rootdir=file:/var/tmp/test-data/cluster1/root, hbase.cluster.distributed=false
2017-02-22 10:38:03,307 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=master:52163 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:38:03,312 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:521630x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:03,313 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): master:52163-0x15a652bd782000f connected
2017-02-22 10:38:03,314 INFO  [main] zookeeper.RecoverableZooKeeper(594): Node /hbase already exists and this is not a retry
2017-02-22 10:38:03,323 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:38:03,323 INFO  [RpcServer.listener,port=52163] ipc.RpcServer$Listener(783): RpcServer.listener,port=52163: starting
2017-02-22 10:38:03,334 DEBUG [main] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:38:03,335 DEBUG [main] client.HConnectionManager(2976): regionserver//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:38:03,335 INFO  [main] ipc.SimpleRpcScheduler(86): Using default user call queue, count=3
2017-02-22 10:38:03,338 INFO  [main] ipc.RpcServer$Listener(649): regionserver//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:38:03,340 INFO  [main] hfile.CacheConfig(215): Created cacheConfig: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:03,347 INFO  [main] http.HttpServer(525): Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-02-22 10:38:03,348 INFO  [main] http.HttpServer(503): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2017-02-22 10:38:03,349 INFO  [main] http.HttpServer(510): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-02-22 10:38:03,361 INFO  [main] http.HttpServer(687): Jetty bound to port 52166
2017-02-22 10:38:03,825 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKUtil(368): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:38:03,826 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKUtil(368): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:03,828 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2017-02-22 10:38:03,830 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKUtil(366): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:03,830 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:03,830 DEBUG [main-EventThread] master.ActiveMasterManager(119): A master is now available
2017-02-22 10:38:03,830 WARN  [M:0;192.168.1.25:52163] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:38:03,831 INFO  [M:0;192.168.1.25:52163] master.ActiveMasterManager(170): Registered Active Master=192.168.1.25,52163,1487756283297
2017-02-22 10:38:03,832 INFO  [M:0;192.168.1.25:52163] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:03,840 INFO  [M:0;192.168.1.25:52163] util.FSUtils(696): Created version file at file:/var/tmp/test-data/cluster1/root with version=8
2017-02-22 10:38:03,848 DEBUG [M:0;192.168.1.25:52163] util.FSUtils(848): Created cluster ID file at file:/var/tmp/test-data/cluster1/root/hbase.id with ID: de8726b4-dd6a-446f-88e9-06ed345ec6bb
2017-02-22 10:38:03,848 INFO  [M:0;192.168.1.25:52163] master.MasterFileSystem(550): BOOTSTRAP: creating hbase:meta region
2017-02-22 10:38:03,849 INFO  [M:0;192.168.1.25:52163] regionserver.HRegion(4729): creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster1/root Table name == hbase:meta
2017-02-22 10:38:03,855 INFO  [M:0;192.168.1.25:52163] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:03,861 INFO  [M:0;192.168.1.25:52163] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/WALs/hlog.1487756283856
2017-02-22 10:38:03,862 INFO  [M:0;192.168.1.25:52163] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2017-02-22 10:38:03,862 INFO  [M:0;192.168.1.25:52163] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2017-02-22 10:38:03,862 DEBUG [M:0;192.168.1.25:52163] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:38:03,864 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:03,864 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:03,864 DEBUG [M:0;192.168.1.25:52163] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740
2017-02-22 10:38:03,865 INFO  [M:0;192.168.1.25:52163] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:38:03,865 DEBUG [M:0;192.168.1.25:52163] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:38:03,865 DEBUG [M:0;192.168.1.25:52163] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:38:03,865 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:38:03,865 INFO  [M:0;192.168.1.25:52163] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:38:03,865 DEBUG [M:0;192.168.1.25:52163-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): M:0;192.168.1.25:52163-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:38:03,865 INFO  [M:0;192.168.1.25:52163-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): M:0;192.168.1.25:52163-WAL.AsyncNotifier exiting
2017-02-22 10:38:03,865 DEBUG [M:0;192.168.1.25:52163-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52163-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:03,865 INFO  [M:0;192.168.1.25:52163-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52163-WAL.AsyncSyncer0 exiting
2017-02-22 10:38:03,865 DEBUG [M:0;192.168.1.25:52163-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52163-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:03,865 INFO  [M:0;192.168.1.25:52163-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52163-WAL.AsyncSyncer1 exiting
2017-02-22 10:38:03,866 DEBUG [M:0;192.168.1.25:52163-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52163-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:03,866 INFO  [M:0;192.168.1.25:52163-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52163-WAL.AsyncSyncer2 exiting
2017-02-22 10:38:03,866 DEBUG [M:0;192.168.1.25:52163-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52163-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:03,866 INFO  [M:0;192.168.1.25:52163-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52163-WAL.AsyncSyncer3 exiting
2017-02-22 10:38:03,866 DEBUG [M:0;192.168.1.25:52163-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52163-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:03,866 INFO  [M:0;192.168.1.25:52163-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52163-WAL.AsyncSyncer4 exiting
2017-02-22 10:38:03,866 DEBUG [M:0;192.168.1.25:52163-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): M:0;192.168.1.25:52163-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:38:03,866 INFO  [M:0;192.168.1.25:52163-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): M:0;192.168.1.25:52163-WAL.AsyncWriter exiting
2017-02-22 10:38:03,866 DEBUG [M:0;192.168.1.25:52163] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/WALs
2017-02-22 10:38:03,867 DEBUG [M:0;192.168.1.25:52163] wal.FSHLog(892): Moved 1 WAL file(s) to /var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/oldWALs
2017-02-22 10:38:03,874 DEBUG [M:0;192.168.1.25:52163] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster1/root/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-02-22 10:38:03,875 DEBUG [M:0;192.168.1.25:52163] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:38:03,875 DEBUG [M:0;192.168.1.25:52163] master.SplitLogManager(1360): Distributed log replay=false, hfile.format.version=2
2017-02-22 10:38:03,876 INFO  [M:0;192.168.1.25:52163] master.SplitLogManager(224): Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-02-22 10:38:03,877 INFO  [M:0;192.168.1.25:52163] master.SplitLogManager(1100): Found 0 orphan tasks and 0 rescan nodes
2017-02-22 10:38:03,877 DEBUG [M:0;192.168.1.25:52163] util.FSTableDescriptors(208): Fetching table descriptors from the filesystem.
2017-02-22 10:38:03,881 INFO  [M:0;192.168.1.25:52163] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x493ecf12 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:38:03,885 DEBUG [M:0;192.168.1.25:52163-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x493ecf120x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:03,885 DEBUG [M:0;192.168.1.25:52163-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x493ecf12-0x15a652bd7820010 connected
2017-02-22 10:38:03,887 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3121cb1f, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:03,889 DEBUG [M:0;192.168.1.25:52163] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@5fa5c346
2017-02-22 10:38:03,890 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKUtil(366): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:38:03,891 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKUtil(368): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/balancer
2017-02-22 10:38:03,897 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:03,899 INFO  [M:0;192.168.1.25:52163] master.HMaster(801): Server active/primary master=192.168.1.25,52163,1487756283297, sessionid=0x15a652bd782000f, setting cluster-up flag (Was=false)
2017-02-22 10:38:03,900 INFO  [M:0;192.168.1.25:52163] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:38:03,901 INFO  [M:0;192.168.1.25:52163] procedure.ZKProcedureUtil(270): Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-02-22 10:38:03,903 DEBUG [M:0;192.168.1.25:52163] procedure.ZKProcedureCoordinatorRpcs(195): Starting the controller for procedure member:192.168.1.25,52163,1487756283297
2017-02-22 10:38:03,903 INFO  [M:0;192.168.1.25:52163] master.MasterCoprocessorHost(85): System coprocessor loading is enabled
2017-02-22 10:38:03,903 DEBUG [M:0;192.168.1.25:52163] executor.ExecutorService(100): Starting executor service name=MASTER_OPEN_REGION-192.168.1.25:52163, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:03,904 DEBUG [M:0;192.168.1.25:52163] executor.ExecutorService(100): Starting executor service name=MASTER_CLOSE_REGION-192.168.1.25:52163, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:03,904 DEBUG [M:0;192.168.1.25:52163] executor.ExecutorService(100): Starting executor service name=MASTER_SERVER_OPERATIONS-192.168.1.25:52163, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:03,904 DEBUG [M:0;192.168.1.25:52163] executor.ExecutorService(100): Starting executor service name=MASTER_META_SERVER_OPERATIONS-192.168.1.25:52163, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:03,904 DEBUG [M:0;192.168.1.25:52163] executor.ExecutorService(100): Starting executor service name=M_LOG_REPLAY_OPS-192.168.1.25:52163, corePoolSize=10, maxPoolSize=10
2017-02-22 10:38:03,904 DEBUG [M:0;192.168.1.25:52163] executor.ExecutorService(100): Starting executor service name=MASTER_TABLE_OPERATIONS-192.168.1.25:52163, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:03,904 DEBUG [M:0;192.168.1.25:52163] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-02-22 10:38:03,905 INFO  [M:0;192.168.1.25:52163] zookeeper.RecoverableZooKeeper(120): Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:38:03,908 DEBUG [M:0;192.168.1.25:52163-EventThread] zookeeper.ZooKeeperWatcher(528): replicationLogCleaner0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:03,909 DEBUG [M:0;192.168.1.25:52163-EventThread] zookeeper.ZooKeeperWatcher(591): replicationLogCleaner-0x15a652bd7820011 connected
2017-02-22 10:38:03,909 DEBUG [M:0;192.168.1.25:52163] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-02-22 10:38:03,910 DEBUG [M:0;192.168.1.25:52163] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-02-22 10:38:03,910 DEBUG [M:0;192.168.1.25:52163] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-02-22 10:38:03,910 DEBUG [M:0;192.168.1.25:52163] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-02-22 10:38:03,910 DEBUG [M:0;192.168.1.25:52163] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-02-22 10:38:03,910 INFO  [M:0;192.168.1.25:52163] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:03,927 INFO  [main] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RS:0;192.168.1.25:52165
2017-02-22 10:38:03,928 DEBUG [RS:0;192.168.1.25:52165] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:339)
2017-02-22 10:38:03,929 INFO  [RS:0;192.168.1.25:52165] zookeeper.RecoverableZooKeeper(120): Process identifier=regionserver:52165 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:38:03,932 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:521650x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:03,933 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(591): regionserver:52165-0x15a652bd7820012 connected
2017-02-22 10:38:03,933 DEBUG [RS:0;192.168.1.25:52165] zookeeper.ZKUtil(366): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:03,935 DEBUG [RS:0;192.168.1.25:52165] zookeeper.ZKUtil(366): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/running
2017-02-22 10:38:03,936 DEBUG [RS:0;192.168.1.25:52165] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@34b36444
2017-02-22 10:38:03,936 DEBUG [RS:0;192.168.1.25:52165] zookeeper.ZKUtil(366): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:38:03,939 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(805): ClusterId : de8726b4-dd6a-446f-88e9-06ed345ec6bb
2017-02-22 10:38:03,939 INFO  [RS:0;192.168.1.25:52165] procedure.RegionServerProcedureManagerHost(43): Procedure online-snapshot is initializing
2017-02-22 10:38:03,940 INFO  [RS:0;192.168.1.25:52165] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:38:03,941 INFO  [RS:0;192.168.1.25:52165] procedure.RegionServerProcedureManagerHost(45): Procedure online-snapshot is initialized
2017-02-22 10:38:03,942 INFO  [RS:0;192.168.1.25:52165] regionserver.MemStoreFlusher(119): globalMemStoreLimit=1.4 G, globalMemStoreLimitLowMark=1.4 G, maxHeap=3.6 G
2017-02-22 10:38:03,942 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer$CompactionChecker(1508): CompactionChecker runs every 10sec
2017-02-22 10:38:03,942 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@308cf60a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=192.168.1.25/192.168.1.25:0
2017-02-22 10:38:03,943 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,52163,1487756283297 with port=52165, startcode=1487756283339
2017-02-22 10:38:03,943 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service RegionServerStatusService, sasl=false
2017-02-22 10:38:03,944 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52163
2017-02-22 10:38:03,945 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 0 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:38:03,946 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: starting, connections 1
2017-02-22 10:38:03,946 DEBUG [RpcServer.listener,port=52163] ipc.RpcServer$Listener(885): RpcServer.listener,port=52163: connection from 192.168.1.25:52170; # active connections: 1
2017-02-22 10:38:03,947 DEBUG [RpcServer.reader=1,port=52163] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "RegionServerStatusService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:03,949 INFO  [FifoRpcScheduler.handler10-thread-1] master.ServerManager(423): Registering server=192.168.1.25,52165,1487756283339
2017-02-22 10:38:03,949 DEBUG [FifoRpcScheduler.handler10-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 184 bytes.
2017-02-22 10:38:03,949 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 0, totalSize: 180 bytes
2017-02-22 10:38:03,949 DEBUG [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1323): Config from master: hbase.rootdir=file:///var/tmp/test-data/cluster1/root
2017-02-22 10:38:03,950 DEBUG [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1323): Config from master: fs.default.name=file:/
2017-02-22 10:38:03,950 DEBUG [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1323): Config from master: hbase.master.info.port=-1
2017-02-22 10:38:03,954 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:38:03,955 DEBUG [RS:0;192.168.1.25:52165] zookeeper.ZKUtil(366): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:03,955 INFO  [RS:0;192.168.1.25:52165] regionserver.RegionServerCoprocessorHost(66): System coprocessor loading is enabled
2017-02-22 10:38:03,955 INFO  [RS:0;192.168.1.25:52165] regionserver.RegionServerCoprocessorHost(67): Table coprocessor loading is enabled
2017-02-22 10:38:03,955 WARN  [RS:0;192.168.1.25:52165] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:38:03,955 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:03,956 DEBUG [RS:0;192.168.1.25:52165] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:38:03,956 DEBUG [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1605): logdir=file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:03,957 DEBUG [main-EventThread] zookeeper.RegionServerTracker(95): Added tracking of RS /hbase/rs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:03,961 INFO  [M:0;192.168.1.25:52163] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 51 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:03,965 DEBUG [RS:0;192.168.1.25:52165] regionserver.Replication(141): ReplicationStatisticsThread 300
2017-02-22 10:38:03,965 INFO  [RS:0;192.168.1.25:52165] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:03,981 INFO  [RS:0;192.168.1.25:52165] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster1/root/WALs/192.168.1.25,52165,1487756283339/192.168.1.25%2C52165%2C1487756283339.1487756283966
2017-02-22 10:38:03,981 INFO  [RS:0;192.168.1.25:52165] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:03,982 INFO  [RS:0;192.168.1.25:52165] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:03,982 INFO  [RS:0;192.168.1.25:52165] regionserver.MetricsRegionServerWrapperImpl(101): Computing regionserver metrics every 5000 milliseconds
2017-02-22 10:38:03,983 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsSystemImpl(220): RegionServer,sub=Server-3, Metrics about HBase RegionServer
2017-02-22 10:38:03,983 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:38:03,983 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:38:03,983 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:38:03,983 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:38:03,983 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:38:03,983 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:38:03,984 DEBUG [RS:0;192.168.1.25:52165] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:38:03,984 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:38:03,984 DEBUG [RS:0;192.168.1.25:52165] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Server-3
2017-02-22 10:38:03,984 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Server-3 registered.
2017-02-22 10:38:03,984 DEBUG [RS:0;192.168.1.25:52165] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Server-3
2017-02-22 10:38:03,985 DEBUG [RS:0;192.168.1.25:52165] executor.ExecutorService(100): Starting executor service name=RS_OPEN_REGION-192.168.1.25:52165, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:03,985 DEBUG [RS:0;192.168.1.25:52165] executor.ExecutorService(100): Starting executor service name=RS_OPEN_META-192.168.1.25:52165, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:03,985 DEBUG [RS:0;192.168.1.25:52165] executor.ExecutorService(100): Starting executor service name=RS_OPEN_PRIORITY_REGION-192.168.1.25:52165, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:03,985 DEBUG [RS:0;192.168.1.25:52165] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_REGION-192.168.1.25:52165, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:03,985 DEBUG [RS:0;192.168.1.25:52165] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_META-192.168.1.25:52165, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:03,985 DEBUG [RS:0;192.168.1.25:52165] executor.ExecutorService(100): Starting executor service name=RS_LOG_REPLAY_OPS-192.168.1.25:52165, corePoolSize=2, maxPoolSize=2
2017-02-22 10:38:03,988 DEBUG [RS:0;192.168.1.25:52165] zookeeper.ZKUtil(366): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:03,988 INFO  [RS:0;192.168.1.25:52165] regionserver.ReplicationSourceManager(226): Current list of replicators: [192.168.1.25,52165,1487756283339] other RSs: [192.168.1.25,52165,1487756283339]
2017-02-22 10:38:04,002 INFO  [RS:0;192.168.1.25:52165] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:38:04,002 INFO  [RS:0;192.168.1.25:52165] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:38:04,002 INFO  [RS:0;192.168.1.25:52165] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:04,003 INFO  [RS:0;192.168.1.25:52165] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x1842d38d connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:38:04,007 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x1842d38d0x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:04,007 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x1842d38d-0x15a652bd7820013 connected
2017-02-22 10:38:04,008 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6ba15eea, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:04,010 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:38:04,010 INFO  [RpcServer.listener,port=52165] ipc.RpcServer$Listener(783): RpcServer.listener,port=52165: starting
2017-02-22 10:38:04,010 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=0 queue=0
2017-02-22 10:38:04,011 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=1 queue=1
2017-02-22 10:38:04,011 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=2 queue=2
2017-02-22 10:38:04,011 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=3 queue=0
2017-02-22 10:38:04,011 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=4 queue=1
2017-02-22 10:38:04,011 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=5 queue=2
2017-02-22 10:38:04,011 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=6 queue=0
2017-02-22 10:38:04,012 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=7 queue=1
2017-02-22 10:38:04,012 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=8 queue=2
2017-02-22 10:38:04,012 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=9 queue=0
2017-02-22 10:38:04,012 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=10 queue=1
2017-02-22 10:38:04,012 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=11 queue=2
2017-02-22 10:38:04,012 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=12 queue=0
2017-02-22 10:38:04,012 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=13 queue=1
2017-02-22 10:38:04,013 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=14 queue=2
2017-02-22 10:38:04,013 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=15 queue=0
2017-02-22 10:38:04,013 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=16 queue=1
2017-02-22 10:38:04,013 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=17 queue=2
2017-02-22 10:38:04,013 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=18 queue=0
2017-02-22 10:38:04,013 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=19 queue=1
2017-02-22 10:38:04,013 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=20 queue=2
2017-02-22 10:38:04,014 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=21 queue=0
2017-02-22 10:38:04,014 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=22 queue=1
2017-02-22 10:38:04,014 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=23 queue=2
2017-02-22 10:38:04,014 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=24 queue=0
2017-02-22 10:38:04,014 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=25 queue=1
2017-02-22 10:38:04,014 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=26 queue=2
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=27 queue=0
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=28 queue=1
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): B.Default Start Handler index=29 queue=2
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=0 queue=0
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=1 queue=0
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=2 queue=0
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=3 queue=0
2017-02-22 10:38:04,015 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=4 queue=0
2017-02-22 10:38:04,016 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=5 queue=0
2017-02-22 10:38:04,016 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=6 queue=0
2017-02-22 10:38:04,016 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=7 queue=0
2017-02-22 10:38:04,016 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=8 queue=0
2017-02-22 10:38:04,016 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Priority Start Handler index=9 queue=0
2017-02-22 10:38:04,016 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Replication Start Handler index=0 queue=0
2017-02-22 10:38:04,017 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Replication Start Handler index=1 queue=0
2017-02-22 10:38:04,017 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcExecutor(115): Replication Start Handler index=2 queue=0
2017-02-22 10:38:04,028 INFO  [RS:0;192.168.1.25:52165] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:38:04,029 INFO  [RS:0;192.168.1.25:52165] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:38:04,029 INFO  [RS:0;192.168.1.25:52165] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:04,029 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1367): Serving as 192.168.1.25,52165,1487756283339, RpcServer on 192.168.1.25/192.168.1.25:52165, sessionid=0x15a652bd7820012
2017-02-22 10:38:04,029 INFO  [SplitLogWorker-192.168.1.25,52165,1487756283339] regionserver.SplitLogWorker(176): SplitLogWorker 192.168.1.25,52165,1487756283339 starting
2017-02-22 10:38:04,029 INFO  [RS:0;192.168.1.25:52165] procedure.RegionServerProcedureManagerHost(51): Procedure online-snapshot is starting
2017-02-22 10:38:04,030 DEBUG [RS:0;192.168.1.25:52165] snapshot.RegionServerSnapshotManager(124): Start Snapshot Manager 192.168.1.25,52165,1487756283339
2017-02-22 10:38:04,030 DEBUG [RS:0;192.168.1.25:52165] procedure.ZKProcedureMemberRpcs(340): Starting procedure member '192.168.1.25,52165,1487756283339'
2017-02-22 10:38:04,030 DEBUG [RS:0;192.168.1.25:52165] procedure.ZKProcedureMemberRpcs(136): Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2017-02-22 10:38:04,031 DEBUG [RS:0;192.168.1.25:52165] procedure.ZKProcedureMemberRpcs(152): Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2017-02-22 10:38:04,032 INFO  [SplitLogWorker-192.168.1.25,52165,1487756283339] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x97d8c32 connecting to ZooKeeper ensemble=localhost:16262
2017-02-22 10:38:04,032 INFO  [RS:0;192.168.1.25:52165] procedure.RegionServerProcedureManagerHost(53): Procedure online-snapshot is started
2017-02-22 10:38:04,033 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 1 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:04,035 DEBUG [FifoRpcScheduler.handler10-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:38:04,035 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:38:04,037 DEBUG [SplitLogWorker-192.168.1.25,52165,1487756283339-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x97d8c320x0, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:04,037 DEBUG [SplitLogWorker-192.168.1.25,52165,1487756283339-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x97d8c32-0x15a652bd7820014 connected
2017-02-22 10:38:04,039 DEBUG [SplitLogWorker-192.168.1.25,52165,1487756283339] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7942e9c7, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:05,500 INFO  [M:0;192.168.1.25:52163] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 1590 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:07,033 INFO  [M:0;192.168.1.25:52163] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 3123 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:07,037 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 2 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:07,038 DEBUG [FifoRpcScheduler.handler10-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 8 bytes.
2017-02-22 10:38:07,039 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 2, totalSize: 4 bytes
2017-02-22 10:38:08,441 INFO  [M:0;192.168.1.25:52163] master.ServerManager(918): Finished waiting for region servers count to settle; checked in 1, slept for 4531 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-02-22 10:38:08,443 INFO  [M:0;192.168.1.25:52163] master.MasterFileSystem(260): Log folder file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,52165,1487756283339 belongs to an existing region server
2017-02-22 10:38:08,452 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:38:08,452 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51897
2017-02-22 10:38:08,452 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1014): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: closing ipc connection to /192.168.1.25:51897: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:583)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:873)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1578)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1477)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1694)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1764)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.getRegionInfo(AdminProtos.java:21172)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRegionInfo(ProtobufUtil.java:1699)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyRegionLocation(CatalogTracker.java:422)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyMetaRegionLocation(CatalogTracker.java:468)
	at org.apache.hadoop.hbase.master.HMaster.assignMeta(HMaster.java:1113)
	at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:995)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:698)
	at java.lang.Thread.run(Thread.java:745)
2017-02-22 10:38:08,453 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51897 from roger: closed
2017-02-22 10:38:08,453 INFO  [M:0;192.168.1.25:52163] catalog.CatalogTracker(441): Failed verification of hbase:meta,,1 at address=192.168.1.25,51897,1487756057911, exception=java.net.ConnectException: Connection refused
2017-02-22 10:38:08,453 INFO  [M:0;192.168.1.25:52163] master.MasterFileSystem(332): Log dir for server 192.168.1.25,51897,1487756057911 does not exist
2017-02-22 10:38:08,453 INFO  [M:0;192.168.1.25:52163] master.SplitLogManager(1458): dead splitlog workers [192.168.1.25,51897,1487756057911]
2017-02-22 10:38:08,453 DEBUG [M:0;192.168.1.25:52163] master.SplitLogManager(323): Scheduling batch of logs to split
2017-02-22 10:38:08,453 INFO  [M:0;192.168.1.25:52163] master.SplitLogManager(325): started splitting 0 logs in []
2017-02-22 10:38:08,454 INFO  [M:0;192.168.1.25:52163] master.SplitLogManager(382): finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 1ms
2017-02-22 10:38:08,454 INFO  [M:0;192.168.1.25:52163] zookeeper.MetaRegionTracker(184): Unsetting hbase:meta region location in ZooKeeper
2017-02-22 10:38:08,456 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:08,456 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:08,458 DEBUG [M:0;192.168.1.25:52163] master.AssignmentManager(2461): No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=192.168.1.25,52165,1487756283339; 1 (online=1, available=1) available servers, forceNewPlan=false
2017-02-22 10:38:08,458 INFO  [M:0;192.168.1.25:52163] master.AssignmentManager(2089): Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:08,458 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKAssign(206): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-02-22 10:38:08,458 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZKUtil(368): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:38:08,458 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:38:08,465 INFO  [M:0;192.168.1.25:52163] master.AssignmentManager(2120): Assigning hbase:meta,,1.1588230740 to 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,465 INFO  [M:0;192.168.1.25:52163] master.RegionStates(894): Transition {1588230740 state=OFFLINE, ts=1487756288458, server=null} to {1588230740 state=PENDING_OPEN, ts=1487756288465, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,465 DEBUG [M:0;192.168.1.25:52163] master.ServerManager(836): New admin connection to 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,465 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:38:08,465 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52165
2017-02-22 10:38:08,467 DEBUG [RpcServer.listener,port=52165] ipc.RpcServer$Listener(885): RpcServer.listener,port=52165: connection from 192.168.1.25:52174; # active connections: 1
2017-02-22 10:38:08,467 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: starting, connections 1
2017-02-22 10:38:08,467 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 1 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:38:08,467 DEBUG [RpcServer.reader=1,port=52165] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:08,467 INFO  [PriorityRpcServer.handler=0,queue=0,port=52165] regionserver.HRegionServer(4011): Open hbase:meta,,1.1588230740
2017-02-22 10:38:08,468 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 10 bytes.
2017-02-22 10:38:08,469 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 1, totalSize: 6 bytes
2017-02-22 10:38:08,468 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] zookeeper.ZKAssign(832): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:08,469 INFO  [M:0;192.168.1.25:52163] master.ServerManager(618): AssignmentManager hasn't finished failover cleanup; waiting
2017-02-22 10:38:08,473 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:08,473 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] zookeeper.ZKAssign(907): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:08,474 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] regionserver.HRegionServer(1622): logdir=file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,475 INFO  [RS_OPEN_META-192.168.1.25:52165-0] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:08,477 DEBUG [AM.ZK.Worker-pool71-t1] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,52165,1487756283339, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1487756288465, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,478 INFO  [AM.ZK.Worker-pool71-t1] master.RegionStates(894): Transition {1588230740 state=PENDING_OPEN, ts=1487756288465, server=192.168.1.25,52165,1487756283339} to {1588230740 state=OPENING, ts=1487756288478, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,500 INFO  [RS_OPEN_META-192.168.1.25:52165-0] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster1/root/WALs/192.168.1.25,52165,1487756283339/192.168.1.25%2C52165%2C1487756283339.1487756288476.meta
2017-02-22 10:38:08,500 INFO  [RS_OPEN_META-192.168.1.25:52165-0] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:08,501 INFO  [RS_OPEN_META-192.168.1.25:52165-0] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:08,502 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] regionserver.HRegion(4915): Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:08,502 INFO  [RS_OPEN_META-192.168.1.25:52165-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:38:08,502 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] coprocessor.CoprocessorHost(226): Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2017-02-22 10:38:08,502 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] regionserver.HRegion(6103): Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2017-02-22 10:38:08,503 INFO  [RS_OPEN_META-192.168.1.25:52165-0] regionserver.RegionCoprocessorHost(373): Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2017-02-22 10:38:08,503 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table meta 1588230740
2017-02-22 10:38:08,503 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:38:08,505 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:08,505 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:08,506 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740
2017-02-22 10:38:08,507 INFO  [RS_OPEN_META-192.168.1.25:52165-0] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:38:08,507 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] zookeeper.ZKAssign(644): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2017-02-22 10:38:08,509 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:meta,,1.1588230740
2017-02-22 10:38:08,509 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1911): Updating zk with meta location
2017-02-22 10:38:08,509 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaRegionTracker(142): Setting hbase:meta region location in ZooKeeper as 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,511 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:08,511 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:08,513 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:meta,,1.1588230740
2017-02-22 10:38:08,514 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] zookeeper.ZKAssign(832): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:08,517 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:08,518 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] zookeeper.ZKAssign(907): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:08,518 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] handler.OpenRegionHandler(403): Transitioned 1588230740 to OPENED in zk on 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,518 DEBUG [RS_OPEN_META-192.168.1.25:52165-0] handler.OpenRegionHandler(189): Opened hbase:meta,,1.1588230740 on 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,519 DEBUG [AM.ZK.Worker-pool71-t2] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,52165,1487756283339, region=1588230740, current_state={1588230740 state=OPENING, ts=1487756288478, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,519 INFO  [AM.ZK.Worker-pool71-t2] master.RegionStates(894): Transition {1588230740 state=OPENING, ts=1487756288478, server=192.168.1.25,52165,1487756283339} to {1588230740 state=OPEN, ts=1487756288519, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,519 INFO  [AM.ZK.Worker-pool71-t2] handler.OpenedRegionHandler(147): Handling OPENED of 1588230740 from 192.168.1.25,52165,1487756283339; deleting unassigned node
2017-02-22 10:38:08,521 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:08,522 DEBUG [AM.ZK.Worker-pool71-t2] zookeeper.ZKAssign(480): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:38:08,523 DEBUG [AM.ZK.Worker-pool71-t3] master.AssignmentManager$4(1316): Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1487756288519, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,524 INFO  [AM.ZK.Worker-pool71-t3] master.RegionStates(397): Onlined 1588230740 on 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,528 INFO  [M:0;192.168.1.25:52163] master.HMaster(1162): hbase:meta assigned=1, rit=false, location=192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,531 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:38:08,531 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52165
2017-02-22 10:38:08,533 DEBUG [RpcServer.listener,port=52165] ipc.RpcServer$Listener(885): RpcServer.listener,port=52165: connection from 192.168.1.25:52175; # active connections: 2
2017-02-22 10:38:08,533 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: starting, connections 2
2017-02-22 10:38:08,533 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true
2017-02-22 10:38:08,534 DEBUG [RpcServer.reader=2,port=52165] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:08,535 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 16 bytes.
2017-02-22 10:38:08,536 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 2, totalSize: 12 bytes
2017-02-22 10:38:08,537 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,538 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 18 bytes.
2017-02-22 10:38:08,538 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 3, totalSize: 14 bytes
2017-02-22 10:38:08,540 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,541 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 12 bytes.
2017-02-22 10:38:08,542 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 4, totalSize: 8 bytes
2017-02-22 10:38:08,543 INFO  [M:0;192.168.1.25:52163] catalog.MetaMigrationConvertingToPB(166): hbase:meta doesn't have any entries to update.
2017-02-22 10:38:08,543 INFO  [M:0;192.168.1.25:52163] catalog.MetaMigrationConvertingToPB(132): META already up-to date with PB serialization
2017-02-22 10:38:08,552 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true
2017-02-22 10:38:08,555 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 16 bytes.
2017-02-22 10:38:08,555 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 5, totalSize: 12 bytes
2017-02-22 10:38:08,556 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,556 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 18 bytes.
2017-02-22 10:38:08,556 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 6, totalSize: 14 bytes
2017-02-22 10:38:08,556 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,557 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 12 bytes.
2017-02-22 10:38:08,557 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 7, totalSize: 8 bytes
2017-02-22 10:38:08,566 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKAssign(498): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Deleting any existing unassigned nodes
2017-02-22 10:38:08,567 INFO  [M:0;192.168.1.25:52163] master.AssignmentManager(646): Clean cluster startup. Assigning user regions
2017-02-22 10:38:08,567 INFO  [M:0;192.168.1.25:52163] master.SnapshotOfRegionAssignmentFromMeta(95): Start to scan the hbase:meta for the current region assignment snappshot
2017-02-22 10:38:08,568 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true
2017-02-22 10:38:08,569 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 16 bytes.
2017-02-22 10:38:08,569 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 8, totalSize: 12 bytes
2017-02-22 10:38:08,569 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,569 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 18 bytes.
2017-02-22 10:38:08,569 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 9, totalSize: 14 bytes
2017-02-22 10:38:08,570 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,570 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 12 bytes.
2017-02-22 10:38:08,570 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 10, totalSize: 8 bytes
2017-02-22 10:38:08,570 INFO  [M:0;192.168.1.25:52163] master.SnapshotOfRegionAssignmentFromMeta(138): Finished to scan the hbase:meta for the current region assignmentsnapshot
2017-02-22 10:38:08,576 INFO  [M:0;192.168.1.25:52163] master.AssignmentManager(511): Joined the cluster in 33ms, failover=false
2017-02-22 10:38:08,578 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 11 method_name: "Scan" request_param: true
2017-02-22 10:38:08,581 DEBUG [CatalogJanitor-192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true
2017-02-22 10:38:08,581 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 16 bytes.
2017-02-22 10:38:08,582 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 16 bytes.
2017-02-22 10:38:08,582 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 11, totalSize: 12 bytes
2017-02-22 10:38:08,582 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 12, totalSize: 12 bytes
2017-02-22 10:38:08,583 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 13 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,583 DEBUG [CatalogJanitor-192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 14 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,583 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:38:08,583 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:38:08,583 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 18 bytes.
2017-02-22 10:38:08,584 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 14, totalSize: 14 bytes
2017-02-22 10:38:08,584 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 15 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,584 DEBUG [CatalogJanitor-192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 16 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,585 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 12 bytes.
2017-02-22 10:38:08,585 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 12 bytes.
2017-02-22 10:38:08,585 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 15, totalSize: 8 bytes
2017-02-22 10:38:08,585 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 16, totalSize: 8 bytes
2017-02-22 10:38:08,585 INFO  [M:0;192.168.1.25:52163] master.TableNamespaceManager(85): Namespace table not found. Creating...
2017-02-22 10:38:08,591 DEBUG [M:0;192.168.1.25:52163] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:521630000000001
2017-02-22 10:38:08,591 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 17 method_name: "Scan" request_param: true
2017-02-22 10:38:08,593 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 16 bytes.
2017-02-22 10:38:08,593 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 17, totalSize: 12 bytes
2017-02-22 10:38:08,594 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 18 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,595 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 18 bytes.
2017-02-22 10:38:08,595 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 18, totalSize: 14 bytes
2017-02-22 10:38:08,596 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 19 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,596 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 12 bytes.
2017-02-22 10:38:08,597 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 19, totalSize: 8 bytes
2017-02-22 10:38:08,597 WARN  [M:0;192.168.1.25:52163] zookeeper.ZKTable(133): Moving table hbase:namespace state to enabling but was not first in disabled state: ENABLED
2017-02-22 10:38:08,599 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] handler.CreateTableHandler(165): Create table hbase:namespace
2017-02-22 10:38:08,616 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster1/root/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2017-02-22 10:38:08,617 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(4729): creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster1/root/.tmp Table name == hbase:namespace
2017-02-22 10:38:08,630 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:08,630 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.: disabling compactions & flushes
2017-02-22 10:38:08,630 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:08,630 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:08,632 DEBUG [htable-pool78-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 20 method_name: "Multi" request_param: true cell_block_meta { length: 141 } priority: 100
2017-02-22 10:38:08,634 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 18 bytes.
2017-02-22 10:38:08,634 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 20, totalSize: 14 bytes
2017-02-22 10:38:08,635 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:38:08,635 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,636 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] zookeeper.ZKAssign(175): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Async create of unassigned node af97da49046429fb0f19334415bce319 with OFFLINE state
2017-02-22 10:38:08,637 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:38:08,638 DEBUG [main-EventThread] master.OfflineCallback(69): rs={af97da49046429fb0f19334415bce319 state=OFFLINE, ts=1487756288635, server=null}, server=192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,639 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={af97da49046429fb0f19334415bce319 state=OFFLINE, ts=1487756288635, server=null}, server=192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,641 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] master.AssignmentManager(1673): 192.168.1.25,52165,1487756283339 unassigned znodes=1 of total=1
2017-02-22 10:38:08,641 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] master.RegionStates(894): Transition {af97da49046429fb0f19334415bce319 state=OFFLINE, ts=1487756288636, server=null} to {af97da49046429fb0f19334415bce319 state=PENDING_OPEN, ts=1487756288641, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,643 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 21 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:38:08,644 INFO  [PriorityRpcServer.handler=0,queue=0,port=52165] regionserver.HRegionServer(4011): Open hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:08,645 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 10 bytes.
2017-02-22 10:38:08,645 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 21, totalSize: 6 bytes
2017-02-22 10:38:08,645 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] zookeeper.ZKAssign(832): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioning af97da49046429fb0f19334415bce319 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:08,646 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,647 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] zookeeper.ZKAssign(907): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioned node af97da49046429fb0f19334415bce319 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:08,648 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/af97da49046429fb0f19334415bce319
2017-02-22 10:38:08,648 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] regionserver.HRegion(4915): Opening region: {ENCODED => af97da49046429fb0f19334415bce319, NAME => 'hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:08,648 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:38:08,649 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table namespace af97da49046429fb0f19334415bce319
2017-02-22 10:38:08,649 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:08,650 DEBUG [AM.ZK.Worker-pool71-t5] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,52165,1487756283339, region=af97da49046429fb0f19334415bce319, current_state={af97da49046429fb0f19334415bce319 state=PENDING_OPEN, ts=1487756288641, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,650 INFO  [AM.ZK.Worker-pool71-t5] master.RegionStates(894): Transition {af97da49046429fb0f19334415bce319 state=PENDING_OPEN, ts=1487756288641, server=192.168.1.25,52165,1487756283339} to {af97da49046429fb0f19334415bce319 state=OPENING, ts=1487756288650, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,651 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/hbase:namespace/write-master:521630000000001
2017-02-22 10:38:08,651 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:38:08,651 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52163-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:38:08,657 INFO  [StoreOpener-af97da49046429fb0f19334415bce319-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:08,658 INFO  [StoreOpener-af97da49046429fb0f19334415bce319-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:08,660 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/af97da49046429fb0f19334415bce319
2017-02-22 10:38:08,660 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] regionserver.HRegion(826): Onlined af97da49046429fb0f19334415bce319; next sequenceid=1
2017-02-22 10:38:08,661 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] zookeeper.ZKAssign(644): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Attempting to retransition opening state of node af97da49046429fb0f19334415bce319
2017-02-22 10:38:08,664 INFO  [PostOpenDeployTasks:af97da49046429fb0f19334415bce319] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:08,677 DEBUG [htable-pool79-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 22 method_name: "Multi" request_param: true cell_block_meta { length: 347 } priority: 100
2017-02-22 10:38:08,679 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 18 bytes.
2017-02-22 10:38:08,679 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 22, totalSize: 14 bytes
2017-02-22 10:38:08,679 INFO  [PostOpenDeployTasks:af97da49046429fb0f19334415bce319] catalog.MetaEditor(523): Updated row hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319. with server=192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,679 INFO  [PostOpenDeployTasks:af97da49046429fb0f19334415bce319] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:08,679 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] zookeeper.ZKAssign(832): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioning af97da49046429fb0f19334415bce319 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:08,681 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/af97da49046429fb0f19334415bce319
2017-02-22 10:38:08,681 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] zookeeper.ZKAssign(907): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Transitioned node af97da49046429fb0f19334415bce319 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:08,681 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] handler.OpenRegionHandler(403): Transitioned af97da49046429fb0f19334415bce319 to OPENED in zk on 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,681 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52165-0] handler.OpenRegionHandler(189): Opened hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319. on 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,682 DEBUG [AM.ZK.Worker-pool71-t6] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,52165,1487756283339, region=af97da49046429fb0f19334415bce319, current_state={af97da49046429fb0f19334415bce319 state=OPENING, ts=1487756288650, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,682 INFO  [AM.ZK.Worker-pool71-t6] master.RegionStates(894): Transition {af97da49046429fb0f19334415bce319 state=OPENING, ts=1487756288650, server=192.168.1.25,52165,1487756283339} to {af97da49046429fb0f19334415bce319 state=OPEN, ts=1487756288682, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,682 DEBUG [AM.ZK.Worker-pool71-t6] handler.OpenedRegionHandler(149): Handling OPENED of af97da49046429fb0f19334415bce319 from 192.168.1.25,52165,1487756283339; deleting unassigned node
2017-02-22 10:38:08,684 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/af97da49046429fb0f19334415bce319
2017-02-22 10:38:08,684 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:38:08,684 DEBUG [AM.ZK.Worker-pool71-t6] zookeeper.ZKAssign(480): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Deleted unassigned node af97da49046429fb0f19334415bce319 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:38:08,684 DEBUG [AM.ZK.Worker-pool71-t8] master.AssignmentManager$4(1316): Znode hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319. deleted, state: {af97da49046429fb0f19334415bce319 state=OPEN, ts=1487756288682, server=192.168.1.25,52165,1487756283339}
2017-02-22 10:38:08,684 INFO  [AM.ZK.Worker-pool71-t8] master.RegionStates(397): Onlined af97da49046429fb0f19334415bce319 on 192.168.1.25,52165,1487756283339
2017-02-22 10:38:08,707 DEBUG [M:0;192.168.1.25:52163] zookeeper.ZKUtil(366): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on existing znode=/hbase/namespace
2017-02-22 10:38:08,711 DEBUG [M:0;192.168.1.25:52163] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:38:08,711 DEBUG [M:0;192.168.1.25:52163] hbase.ZKNamespaceManager(196): Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-02-22 10:38:08,711 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 23 method_name: "Get" request_param: true
2017-02-22 10:38:08,712 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 481 bytes.
2017-02-22 10:38:08,712 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 23, totalSize: 477 bytes
2017-02-22 10:38:08,713 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 24 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,713 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 509 bytes.
2017-02-22 10:38:08,714 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 24 cell_block_meta { length: 488 }, totalSize: 505 bytes
2017-02-22 10:38:08,714 DEBUG [M:0;192.168.1.25:52163] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:08,714 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:08,715 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 12 bytes.
2017-02-22 10:38:08,715 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 25, totalSize: 8 bytes
2017-02-22 10:38:08,715 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 26 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:08,717 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 12 bytes.
2017-02-22 10:38:08,717 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 26, totalSize: 8 bytes
2017-02-22 10:38:08,718 DEBUG [htable-pool80-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 27 method_name: "Multi" request_param: true cell_block_meta { length: 45 } priority: 100
2017-02-22 10:38:08,720 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 18 bytes.
2017-02-22 10:38:08,720 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 27, totalSize: 14 bytes
2017-02-22 10:38:08,721 INFO  [M:0;192.168.1.25:52163] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:38:08,722 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:38:08,722 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:08,723 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 12 bytes.
2017-02-22 10:38:08,723 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 28, totalSize: 8 bytes
2017-02-22 10:38:08,723 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 29 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:08,724 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 12 bytes.
2017-02-22 10:38:08,724 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 29, totalSize: 8 bytes
2017-02-22 10:38:08,725 DEBUG [htable-pool80-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 30 method_name: "Multi" request_param: true cell_block_meta { length: 41 } priority: 100
2017-02-22 10:38:08,727 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 18 bytes.
2017-02-22 10:38:08,727 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 30, totalSize: 14 bytes
2017-02-22 10:38:08,728 INFO  [M:0;192.168.1.25:52163] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:38:08,730 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:38:08,731 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 31 method_name: "Scan" request_param: true
2017-02-22 10:38:08,732 DEBUG [B.DefaultRpcServer.handler=0,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 16 bytes.
2017-02-22 10:38:08,732 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 31, totalSize: 12 bytes
2017-02-22 10:38:08,733 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 32 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,734 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 112 bytes.
2017-02-22 10:38:08,734 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 32 cell_block_meta { length: 86 }, totalSize: 108 bytes
2017-02-22 10:38:08,734 DEBUG [M:0;192.168.1.25:52163] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: wrote request header call_id: 33 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:08,735 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52165] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 12 bytes.
2017-02-22 10:38:08,735 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: got response header call_id: 33, totalSize: 8 bytes
2017-02-22 10:38:08,736 INFO  [M:0;192.168.1.25:52163] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:38:08,737 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:38:08,739 INFO  [M:0;192.168.1.25:52163] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:38:08,740 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:38:08,740 INFO  [M:0;192.168.1.25:52163] master.HMaster(1043): Master has completed initialization
2017-02-22 10:38:08,741 INFO  [M:0;192.168.1.25:52163] zookeeper.ZooKeeperWatcher(236): not a secure deployment, proceeding
2017-02-22 10:38:08,828 DEBUG [main] zookeeper.MiniZooKeeperCluster(172): Failed binding ZK Server to client port: 26262
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:95)
	at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:167)
	at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:131)
	at pt.uminho.haslab.testingutils.ShareCluster.<init>(ShareCluster.java:49)
	at pt.uminho.haslab.smcoprocessors.TestCoprocessorBoot.<init>(TestCoprocessorBoot.java:22)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:195)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:244)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:241)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2017-02-22 10:38:08,829 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x7a0e1b5e connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:38:08,833 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x7a0e1b5e0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:08,834 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x7a0e1b5e-0x15a652bf9a6000e connected
2017-02-22 10:38:08,835 DEBUG [main] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@173b9122, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:08,836 DEBUG [main] client.HConnectionManager(2976): master//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:38:08,838 INFO  [main] ipc.RpcServer$Listener(649): master//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:38:08,839 INFO  [main] master.HMaster(547): hbase.rootdir=file:/var/tmp/test-data/cluster2/root, hbase.cluster.distributed=false
2017-02-22 10:38:08,839 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=master:52177 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:38:08,842 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:521770x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:08,843 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): master:52177-0x15a652bf9a6000f connected
2017-02-22 10:38:08,843 INFO  [main] zookeeper.RecoverableZooKeeper(594): Node /hbase already exists and this is not a retry
2017-02-22 10:38:08,848 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:38:08,848 INFO  [RpcServer.listener,port=52177] ipc.RpcServer$Listener(783): RpcServer.listener,port=52177: starting
2017-02-22 10:38:08,864 DEBUG [main] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:38:08,865 DEBUG [main] client.HConnectionManager(2976): regionserver//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:38:08,865 INFO  [main] ipc.SimpleRpcScheduler(86): Using default user call queue, count=3
2017-02-22 10:38:08,868 INFO  [main] ipc.RpcServer$Listener(649): regionserver//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:38:08,869 INFO  [main] hfile.CacheConfig(215): Created cacheConfig: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:08,875 INFO  [main] http.HttpServer(525): Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-02-22 10:38:08,877 INFO  [main] http.HttpServer(503): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2017-02-22 10:38:08,877 INFO  [main] http.HttpServer(510): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-02-22 10:38:08,888 INFO  [main] http.HttpServer(687): Jetty bound to port 52180
2017-02-22 10:38:09,215 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKUtil(368): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:38:09,217 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKUtil(368): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:09,220 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2017-02-22 10:38:09,224 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKUtil(366): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:09,225 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:09,225 DEBUG [main-EventThread] master.ActiveMasterManager(119): A master is now available
2017-02-22 10:38:09,226 WARN  [M:0;192.168.1.25:52177] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:38:09,227 INFO  [M:0;192.168.1.25:52177] master.ActiveMasterManager(170): Registered Active Master=192.168.1.25,52177,1487756288838
2017-02-22 10:38:09,227 INFO  [M:0;192.168.1.25:52177] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:09,245 INFO  [M:0;192.168.1.25:52177] util.FSUtils(696): Created version file at file:/var/tmp/test-data/cluster2/root with version=8
2017-02-22 10:38:09,258 DEBUG [M:0;192.168.1.25:52177] util.FSUtils(848): Created cluster ID file at file:/var/tmp/test-data/cluster2/root/hbase.id with ID: 7443f11f-4eac-4006-9671-3eb0d6d5a5ba
2017-02-22 10:38:09,259 INFO  [M:0;192.168.1.25:52177] master.MasterFileSystem(550): BOOTSTRAP: creating hbase:meta region
2017-02-22 10:38:09,260 INFO  [M:0;192.168.1.25:52177] regionserver.HRegion(4729): creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster2/root Table name == hbase:meta
2017-02-22 10:38:09,274 INFO  [M:0;192.168.1.25:52177] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:09,288 INFO  [M:0;192.168.1.25:52177] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/WALs/hlog.1487756289274
2017-02-22 10:38:09,288 INFO  [M:0;192.168.1.25:52177] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:09,288 INFO  [M:0;192.168.1.25:52177] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:09,289 DEBUG [M:0;192.168.1.25:52177] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:38:09,290 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:09,291 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:09,293 DEBUG [M:0;192.168.1.25:52177] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740
2017-02-22 10:38:09,295 INFO  [M:0;192.168.1.25:52177] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:38:09,295 DEBUG [M:0;192.168.1.25:52177] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:38:09,296 DEBUG [M:0;192.168.1.25:52177] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:38:09,296 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:38:09,297 INFO  [M:0;192.168.1.25:52177] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:38:09,297 DEBUG [M:0;192.168.1.25:52177-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): M:0;192.168.1.25:52177-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:38:09,297 INFO  [M:0;192.168.1.25:52177-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): M:0;192.168.1.25:52177-WAL.AsyncNotifier exiting
2017-02-22 10:38:09,297 DEBUG [M:0;192.168.1.25:52177-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52177-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:09,297 INFO  [M:0;192.168.1.25:52177-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52177-WAL.AsyncSyncer0 exiting
2017-02-22 10:38:09,297 DEBUG [M:0;192.168.1.25:52177-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52177-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:09,297 INFO  [M:0;192.168.1.25:52177-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52177-WAL.AsyncSyncer1 exiting
2017-02-22 10:38:09,297 DEBUG [M:0;192.168.1.25:52177-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52177-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:09,298 INFO  [M:0;192.168.1.25:52177-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52177-WAL.AsyncSyncer2 exiting
2017-02-22 10:38:09,298 DEBUG [M:0;192.168.1.25:52177-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52177-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:09,298 INFO  [M:0;192.168.1.25:52177-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52177-WAL.AsyncSyncer3 exiting
2017-02-22 10:38:09,298 DEBUG [M:0;192.168.1.25:52177-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52177-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:09,298 INFO  [M:0;192.168.1.25:52177-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52177-WAL.AsyncSyncer4 exiting
2017-02-22 10:38:09,298 DEBUG [M:0;192.168.1.25:52177-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): M:0;192.168.1.25:52177-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:38:09,298 INFO  [M:0;192.168.1.25:52177-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): M:0;192.168.1.25:52177-WAL.AsyncWriter exiting
2017-02-22 10:38:09,298 DEBUG [M:0;192.168.1.25:52177] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/WALs
2017-02-22 10:38:09,299 DEBUG [M:0;192.168.1.25:52177] wal.FSHLog(892): Moved 1 WAL file(s) to /var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/oldWALs
2017-02-22 10:38:09,313 DEBUG [M:0;192.168.1.25:52177] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster2/root/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-02-22 10:38:09,314 DEBUG [M:0;192.168.1.25:52177] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:38:09,315 DEBUG [M:0;192.168.1.25:52177] master.SplitLogManager(1360): Distributed log replay=false, hfile.format.version=2
2017-02-22 10:38:09,316 INFO  [M:0;192.168.1.25:52177] master.SplitLogManager(224): Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-02-22 10:38:09,317 INFO  [M:0;192.168.1.25:52177] master.SplitLogManager(1100): Found 0 orphan tasks and 0 rescan nodes
2017-02-22 10:38:09,317 DEBUG [M:0;192.168.1.25:52177] util.FSTableDescriptors(208): Fetching table descriptors from the filesystem.
2017-02-22 10:38:09,320 INFO  [main] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RS:0;192.168.1.25:52179
2017-02-22 10:38:09,320 DEBUG [RS:0;192.168.1.25:52179] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:339)
2017-02-22 10:38:09,321 INFO  [RS:0;192.168.1.25:52179] zookeeper.RecoverableZooKeeper(120): Process identifier=regionserver:52179 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:38:09,322 INFO  [M:0;192.168.1.25:52177] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x5a26bdc0 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:38:09,327 DEBUG [M:0;192.168.1.25:52177-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x5a26bdc00x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:09,327 DEBUG [M:0;192.168.1.25:52177-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x5a26bdc0-0x15a652bf9a60010 connected
2017-02-22 10:38:09,328 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:521790x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:09,328 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(591): regionserver:52179-0x15a652bf9a60011 connected
2017-02-22 10:38:09,329 DEBUG [RS:0;192.168.1.25:52179] zookeeper.ZKUtil(366): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:09,329 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@22a2e07e, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:09,330 DEBUG [RS:0;192.168.1.25:52179] zookeeper.ZKUtil(368): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:09,331 DEBUG [M:0;192.168.1.25:52177] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4477b22a
2017-02-22 10:38:09,331 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKUtil(366): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:38:09,333 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKUtil(368): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/balancer
2017-02-22 10:38:09,337 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:09,337 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:09,339 INFO  [M:0;192.168.1.25:52177] master.HMaster(801): Server active/primary master=192.168.1.25,52177,1487756288838, sessionid=0x15a652bf9a6000f, setting cluster-up flag (Was=false)
2017-02-22 10:38:09,341 DEBUG [RS:0;192.168.1.25:52179] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2e75c6ef
2017-02-22 10:38:09,342 DEBUG [RS:0;192.168.1.25:52179] zookeeper.ZKUtil(366): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:38:09,342 INFO  [M:0;192.168.1.25:52177] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:38:09,344 INFO  [M:0;192.168.1.25:52177] procedure.ZKProcedureUtil(270): Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-02-22 10:38:09,345 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(805): ClusterId : 7443f11f-4eac-4006-9671-3eb0d6d5a5ba
2017-02-22 10:38:09,345 INFO  [RS:0;192.168.1.25:52179] procedure.RegionServerProcedureManagerHost(43): Procedure online-snapshot is initializing
2017-02-22 10:38:09,346 INFO  [RS:0;192.168.1.25:52179] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:38:09,347 DEBUG [M:0;192.168.1.25:52177] procedure.ZKProcedureCoordinatorRpcs(195): Starting the controller for procedure member:192.168.1.25,52177,1487756288838
2017-02-22 10:38:09,347 INFO  [M:0;192.168.1.25:52177] master.MasterCoprocessorHost(85): System coprocessor loading is enabled
2017-02-22 10:38:09,347 DEBUG [M:0;192.168.1.25:52177] executor.ExecutorService(100): Starting executor service name=MASTER_OPEN_REGION-192.168.1.25:52177, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:09,348 DEBUG [M:0;192.168.1.25:52177] executor.ExecutorService(100): Starting executor service name=MASTER_CLOSE_REGION-192.168.1.25:52177, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:09,348 DEBUG [M:0;192.168.1.25:52177] executor.ExecutorService(100): Starting executor service name=MASTER_SERVER_OPERATIONS-192.168.1.25:52177, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:09,348 DEBUG [M:0;192.168.1.25:52177] executor.ExecutorService(100): Starting executor service name=MASTER_META_SERVER_OPERATIONS-192.168.1.25:52177, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:09,348 INFO  [RS:0;192.168.1.25:52179] procedure.RegionServerProcedureManagerHost(45): Procedure online-snapshot is initialized
2017-02-22 10:38:09,348 DEBUG [M:0;192.168.1.25:52177] executor.ExecutorService(100): Starting executor service name=M_LOG_REPLAY_OPS-192.168.1.25:52177, corePoolSize=10, maxPoolSize=10
2017-02-22 10:38:09,348 DEBUG [M:0;192.168.1.25:52177] executor.ExecutorService(100): Starting executor service name=MASTER_TABLE_OPERATIONS-192.168.1.25:52177, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:09,348 INFO  [RS:0;192.168.1.25:52179] regionserver.MemStoreFlusher(119): globalMemStoreLimit=1.4 G, globalMemStoreLimitLowMark=1.4 G, maxHeap=3.6 G
2017-02-22 10:38:09,348 DEBUG [M:0;192.168.1.25:52177] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-02-22 10:38:09,348 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer$CompactionChecker(1508): CompactionChecker runs every 10sec
2017-02-22 10:38:09,349 INFO  [M:0;192.168.1.25:52177] zookeeper.RecoverableZooKeeper(120): Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:38:09,349 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2a4a47f9, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=192.168.1.25/192.168.1.25:0
2017-02-22 10:38:09,350 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,52177,1487756288838 with port=52179, startcode=1487756288868
2017-02-22 10:38:09,350 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service RegionServerStatusService, sasl=false
2017-02-22 10:38:09,351 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52177
2017-02-22 10:38:09,354 DEBUG [RpcServer.listener,port=52177] ipc.RpcServer$Listener(885): RpcServer.listener,port=52177: connection from 192.168.1.25:52183; # active connections: 1
2017-02-22 10:38:09,354 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 0 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:38:09,354 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: starting, connections 1
2017-02-22 10:38:09,355 DEBUG [RpcServer.reader=1,port=52177] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "RegionServerStatusService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:09,356 DEBUG [M:0;192.168.1.25:52177-EventThread] zookeeper.ZooKeeperWatcher(528): replicationLogCleaner0x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:09,357 DEBUG [FifoRpcScheduler.handler13-thread-1] ipc.CallRunner(107): FifoRpcScheduler.handler13-thread-1: callId: 0 service: RegionServerStatusService methodName: RegionServerStartup size: 47 connection: 192.168.1.25:52183
org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.25/192.168.1.25:52177 is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:97)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-02-22 10:38:09,358 DEBUG [M:0;192.168.1.25:52177-EventThread] zookeeper.ZooKeeperWatcher(591): replicationLogCleaner-0x15a652bf9a60012 connected
2017-02-22 10:38:09,358 DEBUG [FifoRpcScheduler.handler13-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 685 bytes.
2017-02-22 10:38:09,359 DEBUG [M:0;192.168.1.25:52177] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-02-22 10:38:09,359 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 0 exception { exception_class_name: "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException" stack_trace: "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server 192.168.1.25/192.168.1.25:52177 is not running yet\n\tat org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:97)\n\tat org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n" do_not_retry: false }, totalSize: 681 bytes
2017-02-22 10:38:09,360 DEBUG [M:0;192.168.1.25:52177] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-02-22 10:38:09,360 DEBUG [RS:0;192.168.1.25:52179] regionserver.HRegionServer(2214): Master is not running yet
2017-02-22 10:38:09,360 WARN  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(900): reportForDuty failed; sleeping and then retrying.
2017-02-22 10:38:09,361 DEBUG [M:0;192.168.1.25:52177] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-02-22 10:38:09,361 DEBUG [M:0;192.168.1.25:52177] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-02-22 10:38:09,362 DEBUG [M:0;192.168.1.25:52177] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-02-22 10:38:09,362 INFO  [M:0;192.168.1.25:52177] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:10,042 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 3 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:10,042 DEBUG [FifoRpcScheduler.handler10-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 8 bytes.
2017-02-22 10:38:10,043 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 3, totalSize: 4 bytes
2017-02-22 10:38:10,896 INFO  [M:0;192.168.1.25:52177] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 1534 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:12,365 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,52177,1487756288838 with port=52179, startcode=1487756288868
2017-02-22 10:38:12,365 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 1 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:38:12,367 INFO  [FifoRpcScheduler.handler13-thread-2] master.ServerManager(423): Registering server=192.168.1.25,52179,1487756288868
2017-02-22 10:38:12,368 DEBUG [FifoRpcScheduler.handler13-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 184 bytes.
2017-02-22 10:38:12,368 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 1, totalSize: 180 bytes
2017-02-22 10:38:12,368 DEBUG [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1323): Config from master: hbase.rootdir=file:///var/tmp/test-data/cluster2/root
2017-02-22 10:38:12,369 DEBUG [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1323): Config from master: fs.default.name=file:/
2017-02-22 10:38:12,369 DEBUG [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1323): Config from master: hbase.master.info.port=-1
2017-02-22 10:38:12,371 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:38:12,372 DEBUG [RS:0;192.168.1.25:52179] zookeeper.ZKUtil(366): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:12,372 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:12,372 INFO  [RS:0;192.168.1.25:52179] regionserver.RegionServerCoprocessorHost(66): System coprocessor loading is enabled
2017-02-22 10:38:12,373 INFO  [RS:0;192.168.1.25:52179] regionserver.RegionServerCoprocessorHost(67): Table coprocessor loading is enabled
2017-02-22 10:38:12,373 WARN  [RS:0;192.168.1.25:52179] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:38:12,373 DEBUG [RS:0;192.168.1.25:52179] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:38:12,373 DEBUG [main-EventThread] zookeeper.RegionServerTracker(95): Added tracking of RS /hbase/rs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:12,373 DEBUG [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1605): logdir=file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:12,374 INFO  [M:0;192.168.1.25:52177] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 3012 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:12,378 DEBUG [RS:0;192.168.1.25:52179] regionserver.Replication(141): ReplicationStatisticsThread 300
2017-02-22 10:38:12,378 INFO  [RS:0;192.168.1.25:52179] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:12,390 INFO  [RS:0;192.168.1.25:52179] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster2/root/WALs/192.168.1.25,52179,1487756288868/192.168.1.25%2C52179%2C1487756288868.1487756292378
2017-02-22 10:38:12,390 INFO  [RS:0;192.168.1.25:52179] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:12,390 INFO  [RS:0;192.168.1.25:52179] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:12,391 INFO  [RS:0;192.168.1.25:52179] regionserver.MetricsRegionServerWrapperImpl(101): Computing regionserver metrics every 5000 milliseconds
2017-02-22 10:38:12,391 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsSystemImpl(220): RegionServer,sub=Server-4, Metrics about HBase RegionServer
2017-02-22 10:38:12,391 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:38:12,391 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:38:12,391 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:38:12,391 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:38:12,392 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:38:12,392 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:38:12,392 DEBUG [RS:0;192.168.1.25:52179] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:38:12,392 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:38:12,392 DEBUG [RS:0;192.168.1.25:52179] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Server-4
2017-02-22 10:38:12,392 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Server-4 registered.
2017-02-22 10:38:12,392 DEBUG [RS:0;192.168.1.25:52179] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Server-4
2017-02-22 10:38:12,393 DEBUG [RS:0;192.168.1.25:52179] executor.ExecutorService(100): Starting executor service name=RS_OPEN_REGION-192.168.1.25:52179, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:12,393 DEBUG [RS:0;192.168.1.25:52179] executor.ExecutorService(100): Starting executor service name=RS_OPEN_META-192.168.1.25:52179, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:12,393 DEBUG [RS:0;192.168.1.25:52179] executor.ExecutorService(100): Starting executor service name=RS_OPEN_PRIORITY_REGION-192.168.1.25:52179, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:12,393 DEBUG [RS:0;192.168.1.25:52179] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_REGION-192.168.1.25:52179, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:12,393 DEBUG [RS:0;192.168.1.25:52179] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_META-192.168.1.25:52179, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:12,393 DEBUG [RS:0;192.168.1.25:52179] executor.ExecutorService(100): Starting executor service name=RS_LOG_REPLAY_OPS-192.168.1.25:52179, corePoolSize=2, maxPoolSize=2
2017-02-22 10:38:12,395 DEBUG [RS:0;192.168.1.25:52179] zookeeper.ZKUtil(366): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:12,395 INFO  [RS:0;192.168.1.25:52179] regionserver.ReplicationSourceManager(226): Current list of replicators: [192.168.1.25,52179,1487756288868] other RSs: [192.168.1.25,52179,1487756288868]
2017-02-22 10:38:12,404 INFO  [RS:0;192.168.1.25:52179] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:38:12,404 INFO  [RS:0;192.168.1.25:52179] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:38:12,404 INFO  [RS:0;192.168.1.25:52179] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:12,405 INFO  [RS:0;192.168.1.25:52179] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0xcd1cb06 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:38:12,408 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0xcd1cb060x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:12,409 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0xcd1cb06-0x15a652bf9a60013 connected
2017-02-22 10:38:12,410 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6d828fac, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:12,411 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:38:12,411 INFO  [RpcServer.listener,port=52179] ipc.RpcServer$Listener(783): RpcServer.listener,port=52179: starting
2017-02-22 10:38:12,411 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=0 queue=0
2017-02-22 10:38:12,412 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=1 queue=1
2017-02-22 10:38:12,412 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=2 queue=2
2017-02-22 10:38:12,412 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=3 queue=0
2017-02-22 10:38:12,413 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=4 queue=1
2017-02-22 10:38:12,413 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=5 queue=2
2017-02-22 10:38:12,413 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=6 queue=0
2017-02-22 10:38:12,413 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=7 queue=1
2017-02-22 10:38:12,413 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=8 queue=2
2017-02-22 10:38:12,413 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=9 queue=0
2017-02-22 10:38:12,413 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=10 queue=1
2017-02-22 10:38:12,414 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=11 queue=2
2017-02-22 10:38:12,414 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=12 queue=0
2017-02-22 10:38:12,414 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=13 queue=1
2017-02-22 10:38:12,414 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=14 queue=2
2017-02-22 10:38:12,414 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=15 queue=0
2017-02-22 10:38:12,414 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=16 queue=1
2017-02-22 10:38:12,414 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=17 queue=2
2017-02-22 10:38:12,415 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=18 queue=0
2017-02-22 10:38:12,415 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=19 queue=1
2017-02-22 10:38:12,415 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=20 queue=2
2017-02-22 10:38:12,415 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=21 queue=0
2017-02-22 10:38:12,415 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=22 queue=1
2017-02-22 10:38:12,415 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=23 queue=2
2017-02-22 10:38:12,415 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=24 queue=0
2017-02-22 10:38:12,416 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=25 queue=1
2017-02-22 10:38:12,416 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=26 queue=2
2017-02-22 10:38:12,416 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=27 queue=0
2017-02-22 10:38:12,416 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=28 queue=1
2017-02-22 10:38:12,416 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): B.Default Start Handler index=29 queue=2
2017-02-22 10:38:12,416 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=0 queue=0
2017-02-22 10:38:12,416 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=1 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=2 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=3 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=4 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=5 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=6 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=7 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=8 queue=0
2017-02-22 10:38:12,417 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Priority Start Handler index=9 queue=0
2017-02-22 10:38:12,418 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Replication Start Handler index=0 queue=0
2017-02-22 10:38:12,418 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Replication Start Handler index=1 queue=0
2017-02-22 10:38:12,418 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcExecutor(115): Replication Start Handler index=2 queue=0
2017-02-22 10:38:12,426 INFO  [RS:0;192.168.1.25:52179] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:38:12,426 INFO  [RS:0;192.168.1.25:52179] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:38:12,426 INFO  [RS:0;192.168.1.25:52179] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:12,427 INFO  [SplitLogWorker-192.168.1.25,52179,1487756288868] regionserver.SplitLogWorker(176): SplitLogWorker 192.168.1.25,52179,1487756288868 starting
2017-02-22 10:38:12,427 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1367): Serving as 192.168.1.25,52179,1487756288868, RpcServer on 192.168.1.25/192.168.1.25:52179, sessionid=0x15a652bf9a60011
2017-02-22 10:38:12,428 INFO  [RS:0;192.168.1.25:52179] procedure.RegionServerProcedureManagerHost(51): Procedure online-snapshot is starting
2017-02-22 10:38:12,428 DEBUG [RS:0;192.168.1.25:52179] snapshot.RegionServerSnapshotManager(124): Start Snapshot Manager 192.168.1.25,52179,1487756288868
2017-02-22 10:38:12,428 DEBUG [RS:0;192.168.1.25:52179] procedure.ZKProcedureMemberRpcs(340): Starting procedure member '192.168.1.25,52179,1487756288868'
2017-02-22 10:38:12,428 DEBUG [RS:0;192.168.1.25:52179] procedure.ZKProcedureMemberRpcs(136): Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2017-02-22 10:38:12,428 INFO  [SplitLogWorker-192.168.1.25,52179,1487756288868] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x211e0306 connecting to ZooKeeper ensemble=localhost:26262
2017-02-22 10:38:12,429 DEBUG [RS:0;192.168.1.25:52179] procedure.ZKProcedureMemberRpcs(152): Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2017-02-22 10:38:12,429 INFO  [RS:0;192.168.1.25:52179] procedure.RegionServerProcedureManagerHost(53): Procedure online-snapshot is started
2017-02-22 10:38:12,431 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 2 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:12,432 DEBUG [FifoRpcScheduler.handler13-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 8 bytes.
2017-02-22 10:38:12,432 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 2, totalSize: 4 bytes
2017-02-22 10:38:12,433 DEBUG [SplitLogWorker-192.168.1.25,52179,1487756288868-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x211e03060x0, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:12,434 DEBUG [SplitLogWorker-192.168.1.25,52179,1487756288868-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x211e0306-0x15a652bf9a60014 connected
2017-02-22 10:38:12,435 DEBUG [SplitLogWorker-192.168.1.25,52179,1487756288868] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2be66876, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:13,046 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 4 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:13,047 DEBUG [FifoRpcScheduler.handler10-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 8 bytes.
2017-02-22 10:38:13,047 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 4, totalSize: 4 bytes
2017-02-22 10:38:13,899 INFO  [M:0;192.168.1.25:52177] master.ServerManager(918): Finished waiting for region servers count to settle; checked in 1, slept for 4537 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-02-22 10:38:13,901 INFO  [M:0;192.168.1.25:52177] master.MasterFileSystem(260): Log folder file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,52179,1487756288868 belongs to an existing region server
2017-02-22 10:38:13,907 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:38:13,908 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51911
2017-02-22 10:38:13,908 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1014): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: closing ipc connection to /192.168.1.25:51911: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:583)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:873)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1578)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1477)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1694)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1764)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.getRegionInfo(AdminProtos.java:21172)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRegionInfo(ProtobufUtil.java:1699)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyRegionLocation(CatalogTracker.java:422)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyMetaRegionLocation(CatalogTracker.java:468)
	at org.apache.hadoop.hbase.master.HMaster.assignMeta(HMaster.java:1113)
	at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:995)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:698)
	at java.lang.Thread.run(Thread.java:745)
2017-02-22 10:38:13,908 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51911 from roger: closed
2017-02-22 10:38:13,908 INFO  [M:0;192.168.1.25:52177] catalog.CatalogTracker(441): Failed verification of hbase:meta,,1 at address=192.168.1.25,51911,1487756065280, exception=java.net.ConnectException: Connection refused
2017-02-22 10:38:13,908 INFO  [M:0;192.168.1.25:52177] master.MasterFileSystem(332): Log dir for server 192.168.1.25,51911,1487756065280 does not exist
2017-02-22 10:38:13,908 INFO  [M:0;192.168.1.25:52177] master.SplitLogManager(1458): dead splitlog workers [192.168.1.25,51911,1487756065280]
2017-02-22 10:38:13,909 DEBUG [M:0;192.168.1.25:52177] master.SplitLogManager(323): Scheduling batch of logs to split
2017-02-22 10:38:13,909 INFO  [M:0;192.168.1.25:52177] master.SplitLogManager(325): started splitting 0 logs in []
2017-02-22 10:38:13,909 INFO  [M:0;192.168.1.25:52177] master.SplitLogManager(382): finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 0ms
2017-02-22 10:38:13,909 INFO  [M:0;192.168.1.25:52177] zookeeper.MetaRegionTracker(184): Unsetting hbase:meta region location in ZooKeeper
2017-02-22 10:38:13,910 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:13,911 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:13,911 DEBUG [M:0;192.168.1.25:52177] master.AssignmentManager(2461): No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=192.168.1.25,52179,1487756288868; 1 (online=1, available=1) available servers, forceNewPlan=false
2017-02-22 10:38:13,911 INFO  [M:0;192.168.1.25:52177] master.AssignmentManager(2089): Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:13,911 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKAssign(206): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-02-22 10:38:13,912 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:38:13,912 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZKUtil(368): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:38:13,914 INFO  [M:0;192.168.1.25:52177] master.AssignmentManager(2120): Assigning hbase:meta,,1.1588230740 to 192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,914 INFO  [M:0;192.168.1.25:52177] master.RegionStates(894): Transition {1588230740 state=OFFLINE, ts=1487756293911, server=null} to {1588230740 state=PENDING_OPEN, ts=1487756293914, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:13,914 DEBUG [M:0;192.168.1.25:52177] master.ServerManager(836): New admin connection to 192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,914 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:38:13,914 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52179
2017-02-22 10:38:13,915 DEBUG [RpcServer.listener,port=52179] ipc.RpcServer$Listener(885): RpcServer.listener,port=52179: connection from 192.168.1.25:52188; # active connections: 1
2017-02-22 10:38:13,916 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 1 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:38:13,916 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: starting, connections 1
2017-02-22 10:38:13,916 DEBUG [RpcServer.reader=1,port=52179] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:13,916 INFO  [PriorityRpcServer.handler=0,queue=0,port=52179] regionserver.HRegionServer(4011): Open hbase:meta,,1.1588230740
2017-02-22 10:38:13,917 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 10 bytes.
2017-02-22 10:38:13,917 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 1, totalSize: 6 bytes
2017-02-22 10:38:13,917 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] zookeeper.ZKAssign(832): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:13,917 INFO  [M:0;192.168.1.25:52177] master.ServerManager(618): AssignmentManager hasn't finished failover cleanup; waiting
2017-02-22 10:38:13,919 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:13,919 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] zookeeper.ZKAssign(907): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:13,919 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] regionserver.HRegionServer(1622): logdir=file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,920 INFO  [RS_OPEN_META-192.168.1.25:52179-0] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:13,920 DEBUG [AM.ZK.Worker-pool82-t1] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,52179,1487756288868, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1487756293914, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:13,921 INFO  [AM.ZK.Worker-pool82-t1] master.RegionStates(894): Transition {1588230740 state=PENDING_OPEN, ts=1487756293914, server=192.168.1.25,52179,1487756288868} to {1588230740 state=OPENING, ts=1487756293921, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:13,936 INFO  [RS_OPEN_META-192.168.1.25:52179-0] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster2/root/WALs/192.168.1.25,52179,1487756288868/192.168.1.25%2C52179%2C1487756288868.1487756293920.meta
2017-02-22 10:38:13,936 INFO  [RS_OPEN_META-192.168.1.25:52179-0] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:13,936 INFO  [RS_OPEN_META-192.168.1.25:52179-0] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:13,937 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] regionserver.HRegion(4915): Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:13,937 INFO  [RS_OPEN_META-192.168.1.25:52179-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:38:13,938 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] coprocessor.CoprocessorHost(226): Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2017-02-22 10:38:13,938 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] regionserver.HRegion(6103): Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2017-02-22 10:38:13,938 INFO  [RS_OPEN_META-192.168.1.25:52179-0] regionserver.RegionCoprocessorHost(373): Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2017-02-22 10:38:13,938 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table meta 1588230740
2017-02-22 10:38:13,938 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:38:13,939 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:13,939 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:13,940 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740
2017-02-22 10:38:13,940 INFO  [RS_OPEN_META-192.168.1.25:52179-0] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:38:13,941 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] zookeeper.ZKAssign(644): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2017-02-22 10:38:13,942 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:meta,,1.1588230740
2017-02-22 10:38:13,942 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1911): Updating zk with meta location
2017-02-22 10:38:13,942 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaRegionTracker(142): Setting hbase:meta region location in ZooKeeper as 192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,943 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:13,943 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:13,944 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:meta,,1.1588230740
2017-02-22 10:38:13,946 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] zookeeper.ZKAssign(832): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:13,948 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:13,948 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] zookeeper.ZKAssign(907): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:13,948 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] handler.OpenRegionHandler(403): Transitioned 1588230740 to OPENED in zk on 192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,948 DEBUG [RS_OPEN_META-192.168.1.25:52179-0] handler.OpenRegionHandler(189): Opened hbase:meta,,1.1588230740 on 192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,949 DEBUG [AM.ZK.Worker-pool82-t2] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,52179,1487756288868, region=1588230740, current_state={1588230740 state=OPENING, ts=1487756293921, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:13,949 INFO  [AM.ZK.Worker-pool82-t2] master.RegionStates(894): Transition {1588230740 state=OPENING, ts=1487756293921, server=192.168.1.25,52179,1487756288868} to {1588230740 state=OPEN, ts=1487756293949, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:13,949 INFO  [AM.ZK.Worker-pool82-t2] handler.OpenedRegionHandler(147): Handling OPENED of 1588230740 from 192.168.1.25,52179,1487756288868; deleting unassigned node
2017-02-22 10:38:13,950 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:13,951 DEBUG [AM.ZK.Worker-pool82-t2] zookeeper.ZKAssign(480): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:38:13,951 DEBUG [AM.ZK.Worker-pool82-t3] master.AssignmentManager$4(1316): Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1487756293949, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:13,952 INFO  [AM.ZK.Worker-pool82-t3] master.RegionStates(397): Onlined 1588230740 on 192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,953 INFO  [M:0;192.168.1.25:52177] master.HMaster(1162): hbase:meta assigned=1, rit=false, location=192.168.1.25,52179,1487756288868
2017-02-22 10:38:13,954 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:38:13,955 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52179
2017-02-22 10:38:13,956 DEBUG [RpcServer.listener,port=52179] ipc.RpcServer$Listener(885): RpcServer.listener,port=52179: connection from 192.168.1.25:52189; # active connections: 2
2017-02-22 10:38:13,956 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: starting, connections 2
2017-02-22 10:38:13,956 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true
2017-02-22 10:38:13,957 DEBUG [RpcServer.reader=2,port=52179] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:13,957 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 16 bytes.
2017-02-22 10:38:13,957 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 2, totalSize: 12 bytes
2017-02-22 10:38:13,958 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,958 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 18 bytes.
2017-02-22 10:38:13,958 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 3, totalSize: 14 bytes
2017-02-22 10:38:13,958 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,959 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 12 bytes.
2017-02-22 10:38:13,959 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 4, totalSize: 8 bytes
2017-02-22 10:38:13,959 INFO  [M:0;192.168.1.25:52177] catalog.MetaMigrationConvertingToPB(166): hbase:meta doesn't have any entries to update.
2017-02-22 10:38:13,959 INFO  [M:0;192.168.1.25:52177] catalog.MetaMigrationConvertingToPB(132): META already up-to date with PB serialization
2017-02-22 10:38:13,965 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true
2017-02-22 10:38:13,968 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 16 bytes.
2017-02-22 10:38:13,968 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 5, totalSize: 12 bytes
2017-02-22 10:38:13,968 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,968 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 18 bytes.
2017-02-22 10:38:13,969 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 6, totalSize: 14 bytes
2017-02-22 10:38:13,969 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,969 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 12 bytes.
2017-02-22 10:38:13,969 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 7, totalSize: 8 bytes
2017-02-22 10:38:13,973 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKAssign(498): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Deleting any existing unassigned nodes
2017-02-22 10:38:13,974 INFO  [M:0;192.168.1.25:52177] master.AssignmentManager(646): Clean cluster startup. Assigning user regions
2017-02-22 10:38:13,974 INFO  [M:0;192.168.1.25:52177] master.SnapshotOfRegionAssignmentFromMeta(95): Start to scan the hbase:meta for the current region assignment snappshot
2017-02-22 10:38:13,974 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true
2017-02-22 10:38:13,975 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 16 bytes.
2017-02-22 10:38:13,975 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 8, totalSize: 12 bytes
2017-02-22 10:38:13,975 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,976 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 18 bytes.
2017-02-22 10:38:13,976 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 9, totalSize: 14 bytes
2017-02-22 10:38:13,976 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,977 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 12 bytes.
2017-02-22 10:38:13,977 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 10, totalSize: 8 bytes
2017-02-22 10:38:13,977 INFO  [M:0;192.168.1.25:52177] master.SnapshotOfRegionAssignmentFromMeta(138): Finished to scan the hbase:meta for the current region assignmentsnapshot
2017-02-22 10:38:13,981 INFO  [M:0;192.168.1.25:52177] master.AssignmentManager(511): Joined the cluster in 22ms, failover=false
2017-02-22 10:38:13,985 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 11 method_name: "Scan" request_param: true
2017-02-22 10:38:13,987 DEBUG [CatalogJanitor-192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true
2017-02-22 10:38:13,988 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 16 bytes.
2017-02-22 10:38:13,988 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 12, totalSize: 12 bytes
2017-02-22 10:38:13,988 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 16 bytes.
2017-02-22 10:38:13,988 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 11, totalSize: 12 bytes
2017-02-22 10:38:13,988 DEBUG [CatalogJanitor-192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 13 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,989 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 14 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,989 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:38:13,989 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:38:13,990 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 18 bytes.
2017-02-22 10:38:13,990 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 14, totalSize: 14 bytes
2017-02-22 10:38:13,990 DEBUG [CatalogJanitor-192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 15 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,990 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 16 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,990 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 12 bytes.
2017-02-22 10:38:13,990 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 15, totalSize: 8 bytes
2017-02-22 10:38:13,990 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 12 bytes.
2017-02-22 10:38:13,990 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 16, totalSize: 8 bytes
2017-02-22 10:38:13,991 INFO  [M:0;192.168.1.25:52177] master.TableNamespaceManager(85): Namespace table not found. Creating...
2017-02-22 10:38:13,995 DEBUG [M:0;192.168.1.25:52177] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:521770000000001
2017-02-22 10:38:13,995 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 17 method_name: "Scan" request_param: true
2017-02-22 10:38:13,996 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 16 bytes.
2017-02-22 10:38:13,996 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 17, totalSize: 12 bytes
2017-02-22 10:38:13,996 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 18 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,997 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 18 bytes.
2017-02-22 10:38:13,997 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 18, totalSize: 14 bytes
2017-02-22 10:38:13,997 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 19 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:13,997 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 12 bytes.
2017-02-22 10:38:13,997 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 19, totalSize: 8 bytes
2017-02-22 10:38:13,997 WARN  [M:0;192.168.1.25:52177] zookeeper.ZKTable(133): Moving table hbase:namespace state to enabling but was not first in disabled state: ENABLED
2017-02-22 10:38:13,999 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] handler.CreateTableHandler(165): Create table hbase:namespace
2017-02-22 10:38:14,011 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster2/root/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2017-02-22 10:38:14,012 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(4729): creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster2/root/.tmp Table name == hbase:namespace
2017-02-22 10:38:14,026 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:14,026 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.: disabling compactions & flushes
2017-02-22 10:38:14,026 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:14,026 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:14,027 DEBUG [htable-pool89-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 20 method_name: "Multi" request_param: true cell_block_meta { length: 141 } priority: 100
2017-02-22 10:38:14,029 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 18 bytes.
2017-02-22 10:38:14,029 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 20, totalSize: 14 bytes
2017-02-22 10:38:14,030 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:38:14,030 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,031 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] zookeeper.ZKAssign(175): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Async create of unassigned node bfe890dd6be7d22d590410994269660f with OFFLINE state
2017-02-22 10:38:14,032 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:38:14,032 DEBUG [main-EventThread] master.OfflineCallback(69): rs={bfe890dd6be7d22d590410994269660f state=OFFLINE, ts=1487756294030, server=null}, server=192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,033 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={bfe890dd6be7d22d590410994269660f state=OFFLINE, ts=1487756294030, server=null}, server=192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,037 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] master.AssignmentManager(1673): 192.168.1.25,52179,1487756288868 unassigned znodes=1 of total=1
2017-02-22 10:38:14,037 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] master.RegionStates(894): Transition {bfe890dd6be7d22d590410994269660f state=OFFLINE, ts=1487756294031, server=null} to {bfe890dd6be7d22d590410994269660f state=PENDING_OPEN, ts=1487756294037, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:14,038 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 21 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:38:14,038 INFO  [PriorityRpcServer.handler=1,queue=0,port=52179] regionserver.HRegionServer(4011): Open hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:14,041 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 10 bytes.
2017-02-22 10:38:14,041 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 21, totalSize: 6 bytes
2017-02-22 10:38:14,041 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] zookeeper.ZKAssign(832): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioning bfe890dd6be7d22d590410994269660f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:14,041 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,043 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/bfe890dd6be7d22d590410994269660f
2017-02-22 10:38:14,043 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] zookeeper.ZKAssign(907): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioned node bfe890dd6be7d22d590410994269660f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:14,043 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] regionserver.HRegion(4915): Opening region: {ENCODED => bfe890dd6be7d22d590410994269660f, NAME => 'hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:14,044 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:38:14,044 DEBUG [AM.ZK.Worker-pool82-t5] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,52179,1487756288868, region=bfe890dd6be7d22d590410994269660f, current_state={bfe890dd6be7d22d590410994269660f state=PENDING_OPEN, ts=1487756294037, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:14,044 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table namespace bfe890dd6be7d22d590410994269660f
2017-02-22 10:38:14,044 INFO  [AM.ZK.Worker-pool82-t5] master.RegionStates(894): Transition {bfe890dd6be7d22d590410994269660f state=PENDING_OPEN, ts=1487756294037, server=192.168.1.25,52179,1487756288868} to {bfe890dd6be7d22d590410994269660f state=OPENING, ts=1487756294044, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:14,045 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:14,047 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/hbase:namespace/write-master:521770000000001
2017-02-22 10:38:14,047 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:38:14,047 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52177-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:38:14,053 INFO  [StoreOpener-bfe890dd6be7d22d590410994269660f-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:14,053 INFO  [StoreOpener-bfe890dd6be7d22d590410994269660f-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:14,054 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/bfe890dd6be7d22d590410994269660f
2017-02-22 10:38:14,054 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] regionserver.HRegion(826): Onlined bfe890dd6be7d22d590410994269660f; next sequenceid=1
2017-02-22 10:38:14,054 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] zookeeper.ZKAssign(644): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Attempting to retransition opening state of node bfe890dd6be7d22d590410994269660f
2017-02-22 10:38:14,055 INFO  [PostOpenDeployTasks:bfe890dd6be7d22d590410994269660f] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:14,056 DEBUG [htable-pool90-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 22 method_name: "Multi" request_param: true cell_block_meta { length: 347 } priority: 100
2017-02-22 10:38:14,058 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 18 bytes.
2017-02-22 10:38:14,058 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 22, totalSize: 14 bytes
2017-02-22 10:38:14,058 INFO  [PostOpenDeployTasks:bfe890dd6be7d22d590410994269660f] catalog.MetaEditor(523): Updated row hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f. with server=192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,058 INFO  [PostOpenDeployTasks:bfe890dd6be7d22d590410994269660f] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:14,059 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] zookeeper.ZKAssign(832): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioning bfe890dd6be7d22d590410994269660f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:14,060 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/bfe890dd6be7d22d590410994269660f
2017-02-22 10:38:14,060 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] zookeeper.ZKAssign(907): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Transitioned node bfe890dd6be7d22d590410994269660f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:14,061 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] handler.OpenRegionHandler(403): Transitioned bfe890dd6be7d22d590410994269660f to OPENED in zk on 192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,061 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52179-0] handler.OpenRegionHandler(189): Opened hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f. on 192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,061 DEBUG [AM.ZK.Worker-pool82-t6] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,52179,1487756288868, region=bfe890dd6be7d22d590410994269660f, current_state={bfe890dd6be7d22d590410994269660f state=OPENING, ts=1487756294044, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:14,062 INFO  [AM.ZK.Worker-pool82-t6] master.RegionStates(894): Transition {bfe890dd6be7d22d590410994269660f state=OPENING, ts=1487756294044, server=192.168.1.25,52179,1487756288868} to {bfe890dd6be7d22d590410994269660f state=OPEN, ts=1487756294061, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:14,062 DEBUG [AM.ZK.Worker-pool82-t6] handler.OpenedRegionHandler(149): Handling OPENED of bfe890dd6be7d22d590410994269660f from 192.168.1.25,52179,1487756288868; deleting unassigned node
2017-02-22 10:38:14,063 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/bfe890dd6be7d22d590410994269660f
2017-02-22 10:38:14,063 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:38:14,063 DEBUG [AM.ZK.Worker-pool82-t6] zookeeper.ZKAssign(480): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Deleted unassigned node bfe890dd6be7d22d590410994269660f in expected state RS_ZK_REGION_OPENED
2017-02-22 10:38:14,064 DEBUG [AM.ZK.Worker-pool82-t8] master.AssignmentManager$4(1316): Znode hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f. deleted, state: {bfe890dd6be7d22d590410994269660f state=OPEN, ts=1487756294061, server=192.168.1.25,52179,1487756288868}
2017-02-22 10:38:14,064 INFO  [AM.ZK.Worker-pool82-t8] master.RegionStates(397): Onlined bfe890dd6be7d22d590410994269660f on 192.168.1.25,52179,1487756288868
2017-02-22 10:38:14,105 DEBUG [M:0;192.168.1.25:52177] zookeeper.ZKUtil(366): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on existing znode=/hbase/namespace
2017-02-22 10:38:14,107 DEBUG [M:0;192.168.1.25:52177] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:38:14,107 DEBUG [M:0;192.168.1.25:52177] hbase.ZKNamespaceManager(196): Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-02-22 10:38:14,108 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 23 method_name: "Get" request_param: true
2017-02-22 10:38:14,109 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 481 bytes.
2017-02-22 10:38:14,109 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 23, totalSize: 477 bytes
2017-02-22 10:38:14,109 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 24 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:14,110 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 509 bytes.
2017-02-22 10:38:14,110 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 24 cell_block_meta { length: 488 }, totalSize: 505 bytes
2017-02-22 10:38:14,110 DEBUG [M:0;192.168.1.25:52177] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:14,111 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:14,111 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 12 bytes.
2017-02-22 10:38:14,111 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 25, totalSize: 8 bytes
2017-02-22 10:38:14,112 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 26 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:14,114 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 12 bytes.
2017-02-22 10:38:14,114 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 26, totalSize: 8 bytes
2017-02-22 10:38:14,115 DEBUG [htable-pool91-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 27 method_name: "Multi" request_param: true cell_block_meta { length: 45 } priority: 100
2017-02-22 10:38:14,117 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 18 bytes.
2017-02-22 10:38:14,117 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 27, totalSize: 14 bytes
2017-02-22 10:38:14,119 INFO  [M:0;192.168.1.25:52177] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:38:14,120 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:38:14,120 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:14,121 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 12 bytes.
2017-02-22 10:38:14,121 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 28, totalSize: 8 bytes
2017-02-22 10:38:14,121 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 29 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:14,122 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 12 bytes.
2017-02-22 10:38:14,122 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 29, totalSize: 8 bytes
2017-02-22 10:38:14,122 DEBUG [htable-pool91-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 30 method_name: "Multi" request_param: true cell_block_meta { length: 41 } priority: 100
2017-02-22 10:38:14,125 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 18 bytes.
2017-02-22 10:38:14,125 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 30, totalSize: 14 bytes
2017-02-22 10:38:14,126 INFO  [M:0;192.168.1.25:52177] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:38:14,126 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:38:14,127 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 31 method_name: "Scan" request_param: true
2017-02-22 10:38:14,128 DEBUG [B.DefaultRpcServer.handler=1,queue=1,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 16 bytes.
2017-02-22 10:38:14,128 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 31, totalSize: 12 bytes
2017-02-22 10:38:14,128 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 32 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:14,129 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 112 bytes.
2017-02-22 10:38:14,129 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 32 cell_block_meta { length: 86 }, totalSize: 108 bytes
2017-02-22 10:38:14,129 DEBUG [M:0;192.168.1.25:52177] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: wrote request header call_id: 33 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:14,129 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52179] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 12 bytes.
2017-02-22 10:38:14,129 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: got response header call_id: 33, totalSize: 8 bytes
2017-02-22 10:38:14,130 INFO  [M:0;192.168.1.25:52177] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:38:14,131 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:38:14,132 INFO  [M:0;192.168.1.25:52177] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:38:14,133 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:38:14,133 INFO  [M:0;192.168.1.25:52177] master.HMaster(1043): Master has completed initialization
2017-02-22 10:38:14,133 INFO  [M:0;192.168.1.25:52177] zookeeper.ZooKeeperWatcher(236): not a secure deployment, proceeding
2017-02-22 10:38:14,207 DEBUG [main] zookeeper.MiniZooKeeperCluster(172): Failed binding ZK Server to client port: 36262
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:95)
	at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:167)
	at org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:131)
	at pt.uminho.haslab.testingutils.ShareCluster.<init>(ShareCluster.java:49)
	at pt.uminho.haslab.smcoprocessors.TestCoprocessorBoot.<init>(TestCoprocessorBoot.java:22)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:195)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:244)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:241)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2017-02-22 10:38:14,208 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x2fa7ae9 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:38:14,213 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x2fa7ae90x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:14,214 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x2fa7ae9-0x15a652c12db000e connected
2017-02-22 10:38:14,215 DEBUG [main] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3704122f, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:14,216 DEBUG [main] client.HConnectionManager(2976): master//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:38:14,217 INFO  [main] ipc.RpcServer$Listener(649): master//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:38:14,221 INFO  [main] master.HMaster(547): hbase.rootdir=file:/var/tmp/test-data/cluster3/root, hbase.cluster.distributed=false
2017-02-22 10:38:14,221 INFO  [main] zookeeper.RecoverableZooKeeper(120): Process identifier=master:52191 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:38:14,225 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:521910x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:14,226 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(591): master:52191-0x15a652c12db000f connected
2017-02-22 10:38:14,227 INFO  [main] zookeeper.RecoverableZooKeeper(594): Node /hbase already exists and this is not a retry
2017-02-22 10:38:14,230 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:38:14,230 INFO  [RpcServer.listener,port=52191] ipc.RpcServer$Listener(783): RpcServer.listener,port=52191: starting
2017-02-22 10:38:14,241 DEBUG [main] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:38:14,242 DEBUG [main] client.HConnectionManager(2976): regionserver//192.168.1.25:0 HConnection server-to-server retries=350
2017-02-22 10:38:14,242 INFO  [main] ipc.SimpleRpcScheduler(86): Using default user call queue, count=3
2017-02-22 10:38:14,244 INFO  [main] ipc.RpcServer$Listener(649): regionserver//192.168.1.25:0: started 10 reader(s).
2017-02-22 10:38:14,245 INFO  [main] hfile.CacheConfig(215): Created cacheConfig: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:14,250 INFO  [main] http.HttpServer(525): Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2017-02-22 10:38:14,251 INFO  [main] http.HttpServer(503): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2017-02-22 10:38:14,251 INFO  [main] http.HttpServer(510): Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-02-22 10:38:14,260 INFO  [main] http.HttpServer(687): Jetty bound to port 52194
2017-02-22 10:38:14,532 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKUtil(368): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:38:14,533 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKUtil(368): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:14,536 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/master
2017-02-22 10:38:14,537 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKUtil(366): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:14,538 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:14,538 DEBUG [main-EventThread] master.ActiveMasterManager(119): A master is now available
2017-02-22 10:38:14,539 WARN  [M:0;192.168.1.25:52191] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:38:14,539 INFO  [M:0;192.168.1.25:52191] master.ActiveMasterManager(170): Registered Active Master=192.168.1.25,52191,1487756294218
2017-02-22 10:38:14,540 INFO  [M:0;192.168.1.25:52191] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:14,551 INFO  [M:0;192.168.1.25:52191] util.FSUtils(696): Created version file at file:/var/tmp/test-data/cluster3/root with version=8
2017-02-22 10:38:14,561 DEBUG [M:0;192.168.1.25:52191] util.FSUtils(848): Created cluster ID file at file:/var/tmp/test-data/cluster3/root/hbase.id with ID: 1a614ed8-6ec9-431a-afc1-018952441afc
2017-02-22 10:38:14,562 INFO  [M:0;192.168.1.25:52191] master.MasterFileSystem(550): BOOTSTRAP: creating hbase:meta region
2017-02-22 10:38:14,562 INFO  [M:0;192.168.1.25:52191] regionserver.HRegion(4729): creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster3/root Table name == hbase:meta
2017-02-22 10:38:14,573 INFO  [M:0;192.168.1.25:52191] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:14,584 INFO  [M:0;192.168.1.25:52191] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/WALs/hlog.1487756294573
2017-02-22 10:38:14,585 INFO  [M:0;192.168.1.25:52191] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:14,585 INFO  [M:0;192.168.1.25:52191] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:14,585 DEBUG [M:0;192.168.1.25:52191] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:38:14,587 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=false] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:14,588 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:14,588 DEBUG [M:0;192.168.1.25:52191] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740
2017-02-22 10:38:14,588 INFO  [M:0;192.168.1.25:52191] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:38:14,588 DEBUG [M:0;192.168.1.25:52191] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:38:14,588 DEBUG [M:0;192.168.1.25:52191] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:38:14,589 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:38:14,589 INFO  [M:0;192.168.1.25:52191] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:38:14,589 DEBUG [M:0;192.168.1.25:52191-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): M:0;192.168.1.25:52191-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:38:14,589 INFO  [M:0;192.168.1.25:52191-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): M:0;192.168.1.25:52191-WAL.AsyncNotifier exiting
2017-02-22 10:38:14,589 DEBUG [M:0;192.168.1.25:52191-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52191-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:14,589 INFO  [M:0;192.168.1.25:52191-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52191-WAL.AsyncSyncer0 exiting
2017-02-22 10:38:14,589 DEBUG [M:0;192.168.1.25:52191-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52191-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:14,589 INFO  [M:0;192.168.1.25:52191-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52191-WAL.AsyncSyncer1 exiting
2017-02-22 10:38:14,589 DEBUG [M:0;192.168.1.25:52191-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52191-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:14,589 INFO  [M:0;192.168.1.25:52191-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52191-WAL.AsyncSyncer2 exiting
2017-02-22 10:38:14,589 DEBUG [M:0;192.168.1.25:52191-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52191-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:14,589 INFO  [M:0;192.168.1.25:52191-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52191-WAL.AsyncSyncer3 exiting
2017-02-22 10:38:14,590 DEBUG [M:0;192.168.1.25:52191-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): M:0;192.168.1.25:52191-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:14,590 INFO  [M:0;192.168.1.25:52191-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): M:0;192.168.1.25:52191-WAL.AsyncSyncer4 exiting
2017-02-22 10:38:14,590 DEBUG [M:0;192.168.1.25:52191-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): M:0;192.168.1.25:52191-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:38:14,590 INFO  [M:0;192.168.1.25:52191-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): M:0;192.168.1.25:52191-WAL.AsyncWriter exiting
2017-02-22 10:38:14,590 DEBUG [M:0;192.168.1.25:52191] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/WALs
2017-02-22 10:38:14,590 DEBUG [M:0;192.168.1.25:52191] wal.FSHLog(892): Moved 1 WAL file(s) to /var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/oldWALs
2017-02-22 10:38:14,602 DEBUG [M:0;192.168.1.25:52191] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster3/root/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2017-02-22 10:38:14,604 DEBUG [M:0;192.168.1.25:52191] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:38:14,604 DEBUG [M:0;192.168.1.25:52191] master.SplitLogManager(1360): Distributed log replay=false, hfile.format.version=2
2017-02-22 10:38:14,605 INFO  [M:0;192.168.1.25:52191] master.SplitLogManager(224): Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2017-02-22 10:38:14,605 INFO  [M:0;192.168.1.25:52191] master.SplitLogManager(1100): Found 0 orphan tasks and 0 rescan nodes
2017-02-22 10:38:14,605 DEBUG [M:0;192.168.1.25:52191] util.FSTableDescriptors(208): Fetching table descriptors from the filesystem.
2017-02-22 10:38:14,608 INFO  [M:0;192.168.1.25:52191] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x520ff85a connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:38:14,611 DEBUG [M:0;192.168.1.25:52191-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x520ff85a0x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:14,612 DEBUG [M:0;192.168.1.25:52191-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x520ff85a-0x15a652c12db0010 connected
2017-02-22 10:38:14,613 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@30925e4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:14,615 DEBUG [M:0;192.168.1.25:52191] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4cb84158
2017-02-22 10:38:14,615 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKUtil(366): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:38:14,616 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKUtil(368): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/balancer
2017-02-22 10:38:14,619 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:14,621 INFO  [M:0;192.168.1.25:52191] master.HMaster(801): Server active/primary master=192.168.1.25,52191,1487756294218, sessionid=0x15a652c12db000f, setting cluster-up flag (Was=false)
2017-02-22 10:38:14,622 INFO  [M:0;192.168.1.25:52191] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:38:14,623 INFO  [M:0;192.168.1.25:52191] procedure.ZKProcedureUtil(270): Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
2017-02-22 10:38:14,623 DEBUG [M:0;192.168.1.25:52191] procedure.ZKProcedureCoordinatorRpcs(195): Starting the controller for procedure member:192.168.1.25,52191,1487756294218
2017-02-22 10:38:14,623 INFO  [M:0;192.168.1.25:52191] master.MasterCoprocessorHost(85): System coprocessor loading is enabled
2017-02-22 10:38:14,624 DEBUG [M:0;192.168.1.25:52191] executor.ExecutorService(100): Starting executor service name=MASTER_OPEN_REGION-192.168.1.25:52191, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:14,624 DEBUG [M:0;192.168.1.25:52191] executor.ExecutorService(100): Starting executor service name=MASTER_CLOSE_REGION-192.168.1.25:52191, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:14,624 DEBUG [M:0;192.168.1.25:52191] executor.ExecutorService(100): Starting executor service name=MASTER_SERVER_OPERATIONS-192.168.1.25:52191, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:14,624 DEBUG [M:0;192.168.1.25:52191] executor.ExecutorService(100): Starting executor service name=MASTER_META_SERVER_OPERATIONS-192.168.1.25:52191, corePoolSize=5, maxPoolSize=5
2017-02-22 10:38:14,624 DEBUG [M:0;192.168.1.25:52191] executor.ExecutorService(100): Starting executor service name=M_LOG_REPLAY_OPS-192.168.1.25:52191, corePoolSize=10, maxPoolSize=10
2017-02-22 10:38:14,624 DEBUG [M:0;192.168.1.25:52191] executor.ExecutorService(100): Starting executor service name=MASTER_TABLE_OPERATIONS-192.168.1.25:52191, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:14,624 DEBUG [M:0;192.168.1.25:52191] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2017-02-22 10:38:14,624 INFO  [M:0;192.168.1.25:52191] zookeeper.RecoverableZooKeeper(120): Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:38:14,628 DEBUG [M:0;192.168.1.25:52191-EventThread] zookeeper.ZooKeeperWatcher(528): replicationLogCleaner0x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:14,628 DEBUG [M:0;192.168.1.25:52191-EventThread] zookeeper.ZooKeeperWatcher(591): replicationLogCleaner-0x15a652c12db0011 connected
2017-02-22 10:38:14,629 DEBUG [M:0;192.168.1.25:52191] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2017-02-22 10:38:14,629 DEBUG [M:0;192.168.1.25:52191] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2017-02-22 10:38:14,629 DEBUG [M:0;192.168.1.25:52191] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2017-02-22 10:38:14,629 DEBUG [M:0;192.168.1.25:52191] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2017-02-22 10:38:14,630 DEBUG [M:0;192.168.1.25:52191] cleaner.CleanerChore(91): initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2017-02-22 10:38:14,630 INFO  [M:0;192.168.1.25:52191] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:14,636 INFO  [main] regionserver.ShutdownHook(87): Installed shutdown hook thread: Shutdownhook:RS:0;192.168.1.25:52193
2017-02-22 10:38:14,636 DEBUG [RS:0;192.168.1.25:52193] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:339)
2017-02-22 10:38:14,638 INFO  [RS:0;192.168.1.25:52193] zookeeper.RecoverableZooKeeper(120): Process identifier=regionserver:52193 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:38:14,643 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:521930x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:14,644 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(591): regionserver:52193-0x15a652c12db0012 connected
2017-02-22 10:38:14,644 DEBUG [RS:0;192.168.1.25:52193] zookeeper.ZKUtil(366): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/master
2017-02-22 10:38:14,645 DEBUG [RS:0;192.168.1.25:52193] zookeeper.ZKUtil(366): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/running
2017-02-22 10:38:14,646 DEBUG [RS:0;192.168.1.25:52193] catalog.CatalogTracker(199): Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@60a10040
2017-02-22 10:38:14,646 DEBUG [RS:0;192.168.1.25:52193] zookeeper.ZKUtil(366): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/meta-region-server
2017-02-22 10:38:14,648 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(805): ClusterId : 1a614ed8-6ec9-431a-afc1-018952441afc
2017-02-22 10:38:14,648 INFO  [RS:0;192.168.1.25:52193] procedure.RegionServerProcedureManagerHost(43): Procedure online-snapshot is initializing
2017-02-22 10:38:14,649 INFO  [RS:0;192.168.1.25:52193] zookeeper.RecoverableZooKeeper(594): Node /hbase/online-snapshot/acquired already exists and this is not a retry
2017-02-22 10:38:14,650 INFO  [RS:0;192.168.1.25:52193] procedure.RegionServerProcedureManagerHost(45): Procedure online-snapshot is initialized
2017-02-22 10:38:14,650 INFO  [RS:0;192.168.1.25:52193] regionserver.MemStoreFlusher(119): globalMemStoreLimit=1.4 G, globalMemStoreLimitLowMark=1.4 G, maxHeap=3.6 G
2017-02-22 10:38:14,650 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer$CompactionChecker(1508): CompactionChecker runs every 10sec
2017-02-22 10:38:14,650 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@649e988c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=192.168.1.25/192.168.1.25:0
2017-02-22 10:38:14,651 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(2198): reportForDuty to master=192.168.1.25,52191,1487756294218 with port=52193, startcode=1487756294244
2017-02-22 10:38:14,651 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service RegionServerStatusService, sasl=false
2017-02-22 10:38:14,651 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52191
2017-02-22 10:38:14,653 DEBUG [RpcServer.listener,port=52191] ipc.RpcServer$Listener(885): RpcServer.listener,port=52191: connection from 192.168.1.25:52198; # active connections: 1
2017-02-22 10:38:14,653 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 0 method_name: "RegionServerStartup" request_param: true priority: 0
2017-02-22 10:38:14,653 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: starting, connections 1
2017-02-22 10:38:14,654 DEBUG [RpcServer.reader=1,port=52191] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "RegionServerStatusService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:14,655 INFO  [FifoRpcScheduler.handler16-thread-1] master.ServerManager(423): Registering server=192.168.1.25,52193,1487756294244
2017-02-22 10:38:14,655 DEBUG [FifoRpcScheduler.handler16-thread-1] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 184 bytes.
2017-02-22 10:38:14,655 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 0, totalSize: 180 bytes
2017-02-22 10:38:14,655 DEBUG [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1323): Config from master: hbase.rootdir=file:///var/tmp/test-data/cluster3/root
2017-02-22 10:38:14,656 DEBUG [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1323): Config from master: fs.default.name=file:/
2017-02-22 10:38:14,656 DEBUG [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1323): Config from master: hbase.master.info.port=-1
2017-02-22 10:38:14,657 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:38:14,658 DEBUG [RS:0;192.168.1.25:52193] zookeeper.ZKUtil(366): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52193,1487756294244
2017-02-22 10:38:14,658 INFO  [RS:0;192.168.1.25:52193] regionserver.RegionServerCoprocessorHost(66): System coprocessor loading is enabled
2017-02-22 10:38:14,658 INFO  [RS:0;192.168.1.25:52193] regionserver.RegionServerCoprocessorHost(67): Table coprocessor loading is enabled
2017-02-22 10:38:14,658 WARN  [RS:0;192.168.1.25:52193] hbase.ZNodeClearer(58): Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2017-02-22 10:38:14,658 DEBUG [main-EventThread] zookeeper.ZKUtil(366): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52193,1487756294244
2017-02-22 10:38:14,659 DEBUG [RS:0;192.168.1.25:52193] fs.HFileSystem(236): The file system is not a DistributedFileSystem. Skipping on block location reordering
2017-02-22 10:38:14,659 DEBUG [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1605): logdir=file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,52193,1487756294244
2017-02-22 10:38:14,659 DEBUG [main-EventThread] zookeeper.RegionServerTracker(95): Added tracking of RS /hbase/rs/192.168.1.25,52193,1487756294244
2017-02-22 10:38:14,663 DEBUG [RS:0;192.168.1.25:52193] regionserver.Replication(141): ReplicationStatisticsThread 300
2017-02-22 10:38:14,664 INFO  [RS:0;192.168.1.25:52193] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:14,674 INFO  [RS:0;192.168.1.25:52193] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster3/root/WALs/192.168.1.25,52193,1487756294244/192.168.1.25%2C52193%2C1487756294244.1487756294664
2017-02-22 10:38:14,675 INFO  [RS:0;192.168.1.25:52193] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:14,675 INFO  [RS:0;192.168.1.25:52193] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:14,675 INFO  [RS:0;192.168.1.25:52193] regionserver.MetricsRegionServerWrapperImpl(101): Computing regionserver metrics every 5000 milliseconds
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsSystemImpl(220): RegionServer,sub=Server-5, Metrics about HBase RegionServer
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: source.source.start_mbeans
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsConfig(179): poking parent 'MetricsConfig' for key: source.start_mbeans
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsConfig(179): poking parent 'PropertiesConfiguration' for key: *.source.start_mbeans
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsSourceAdapter(238): Updating attr cache...
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsSourceAdapter(252): Done. # tags & metrics=2
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsSourceAdapter(232): Updating info cache...
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MBeanInfoBuilder(109): [javax.management.MBeanAttributeInfo[description=Metrics context, name=tag.Context, type=java.lang.String, read-only, descriptor={}], javax.management.MBeanAttributeInfo[description=Local hostname, name=tag.Hostname, type=java.lang.String, read-only, descriptor={}]]
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsSourceAdapter(234): Done
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] util.MBeans(58): Registered Hadoop:service=HBase,name=RegionServer,sub=Server-5
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsSourceAdapter(221): MBean for source RegionServer,sub=Server-5 registered.
2017-02-22 10:38:14,676 DEBUG [RS:0;192.168.1.25:52193] impl.MetricsSystemImpl(245): Registered source RegionServer,sub=Server-5
2017-02-22 10:38:14,677 DEBUG [RS:0;192.168.1.25:52193] executor.ExecutorService(100): Starting executor service name=RS_OPEN_REGION-192.168.1.25:52193, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:14,677 DEBUG [RS:0;192.168.1.25:52193] executor.ExecutorService(100): Starting executor service name=RS_OPEN_META-192.168.1.25:52193, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:14,677 DEBUG [RS:0;192.168.1.25:52193] executor.ExecutorService(100): Starting executor service name=RS_OPEN_PRIORITY_REGION-192.168.1.25:52193, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:14,678 DEBUG [RS:0;192.168.1.25:52193] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_REGION-192.168.1.25:52193, corePoolSize=3, maxPoolSize=3
2017-02-22 10:38:14,678 DEBUG [RS:0;192.168.1.25:52193] executor.ExecutorService(100): Starting executor service name=RS_CLOSE_META-192.168.1.25:52193, corePoolSize=1, maxPoolSize=1
2017-02-22 10:38:14,678 DEBUG [RS:0;192.168.1.25:52193] executor.ExecutorService(100): Starting executor service name=RS_LOG_REPLAY_OPS-192.168.1.25:52193, corePoolSize=2, maxPoolSize=2
2017-02-22 10:38:14,679 DEBUG [RS:0;192.168.1.25:52193] zookeeper.ZKUtil(366): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/rs/192.168.1.25,52193,1487756294244
2017-02-22 10:38:14,680 INFO  [RS:0;192.168.1.25:52193] regionserver.ReplicationSourceManager(226): Current list of replicators: [192.168.1.25,52193,1487756294244] other RSs: [192.168.1.25,52193,1487756294244]
2017-02-22 10:38:14,684 INFO  [M:0;192.168.1.25:52191] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 54 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:14,688 INFO  [RS:0;192.168.1.25:52193] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:38:14,689 INFO  [RS:0;192.168.1.25:52193] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:38:14,689 INFO  [RS:0;192.168.1.25:52193] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:14,689 INFO  [RS:0;192.168.1.25:52193] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x346110f5 connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:38:14,695 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x346110f50x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:14,698 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x346110f5-0x15a652c12db0013 connected
2017-02-22 10:38:14,700 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@1b5cbb2c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:14,702 INFO  [RpcServer.listener,port=52193] ipc.RpcServer$Listener(783): RpcServer.listener,port=52193: starting
2017-02-22 10:38:14,702 INFO  [RpcServer.responder] ipc.RpcServer$Responder(958): RpcServer.responder: starting
2017-02-22 10:38:14,702 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=0 queue=0
2017-02-22 10:38:14,703 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=1 queue=1
2017-02-22 10:38:14,704 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=2 queue=2
2017-02-22 10:38:14,704 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=3 queue=0
2017-02-22 10:38:14,704 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=4 queue=1
2017-02-22 10:38:14,704 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=5 queue=2
2017-02-22 10:38:14,704 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=6 queue=0
2017-02-22 10:38:14,704 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=7 queue=1
2017-02-22 10:38:14,705 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=8 queue=2
2017-02-22 10:38:14,705 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=9 queue=0
2017-02-22 10:38:14,705 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=10 queue=1
2017-02-22 10:38:14,705 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=11 queue=2
2017-02-22 10:38:14,705 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=12 queue=0
2017-02-22 10:38:14,705 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=13 queue=1
2017-02-22 10:38:14,705 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=14 queue=2
2017-02-22 10:38:14,706 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=15 queue=0
2017-02-22 10:38:14,706 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=16 queue=1
2017-02-22 10:38:14,706 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=17 queue=2
2017-02-22 10:38:14,706 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=18 queue=0
2017-02-22 10:38:14,706 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=19 queue=1
2017-02-22 10:38:14,706 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=20 queue=2
2017-02-22 10:38:14,706 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=21 queue=0
2017-02-22 10:38:14,707 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=22 queue=1
2017-02-22 10:38:14,707 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=23 queue=2
2017-02-22 10:38:14,707 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=24 queue=0
2017-02-22 10:38:14,707 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=25 queue=1
2017-02-22 10:38:14,707 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=26 queue=2
2017-02-22 10:38:14,707 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=27 queue=0
2017-02-22 10:38:14,707 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=28 queue=1
2017-02-22 10:38:14,708 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): B.Default Start Handler index=29 queue=2
2017-02-22 10:38:14,708 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=0 queue=0
2017-02-22 10:38:14,708 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=1 queue=0
2017-02-22 10:38:14,708 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=2 queue=0
2017-02-22 10:38:14,708 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=3 queue=0
2017-02-22 10:38:14,708 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=4 queue=0
2017-02-22 10:38:14,708 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=5 queue=0
2017-02-22 10:38:14,709 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=6 queue=0
2017-02-22 10:38:14,709 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=7 queue=0
2017-02-22 10:38:14,709 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=8 queue=0
2017-02-22 10:38:14,709 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Priority Start Handler index=9 queue=0
2017-02-22 10:38:14,709 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Replication Start Handler index=0 queue=0
2017-02-22 10:38:14,709 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Replication Start Handler index=1 queue=0
2017-02-22 10:38:14,709 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcExecutor(115): Replication Start Handler index=2 queue=0
2017-02-22 10:38:14,719 INFO  [RS:0;192.168.1.25:52193] conf.Configuration(840): mapreduce.job.counters.limit is deprecated. Instead, use mapreduce.job.counters.max
2017-02-22 10:38:14,720 INFO  [RS:0;192.168.1.25:52193] conf.Configuration(840): io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
2017-02-22 10:38:14,720 INFO  [RS:0;192.168.1.25:52193] conf.Configuration(840): fs.default.name is deprecated. Instead, use fs.defaultFS
2017-02-22 10:38:14,720 INFO  [SplitLogWorker-192.168.1.25,52193,1487756294244] regionserver.SplitLogWorker(176): SplitLogWorker 192.168.1.25,52193,1487756294244 starting
2017-02-22 10:38:14,720 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1367): Serving as 192.168.1.25,52193,1487756294244, RpcServer on 192.168.1.25/192.168.1.25:52193, sessionid=0x15a652c12db0012
2017-02-22 10:38:14,721 INFO  [RS:0;192.168.1.25:52193] procedure.RegionServerProcedureManagerHost(51): Procedure online-snapshot is starting
2017-02-22 10:38:14,722 DEBUG [RS:0;192.168.1.25:52193] snapshot.RegionServerSnapshotManager(124): Start Snapshot Manager 192.168.1.25,52193,1487756294244
2017-02-22 10:38:14,722 DEBUG [RS:0;192.168.1.25:52193] procedure.ZKProcedureMemberRpcs(340): Starting procedure member '192.168.1.25,52193,1487756294244'
2017-02-22 10:38:14,722 DEBUG [RS:0;192.168.1.25:52193] procedure.ZKProcedureMemberRpcs(136): Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2017-02-22 10:38:14,722 INFO  [SplitLogWorker-192.168.1.25,52193,1487756294244] zookeeper.RecoverableZooKeeper(120): Process identifier=hconnection-0x722815ef connecting to ZooKeeper ensemble=localhost:36262
2017-02-22 10:38:14,722 DEBUG [RS:0;192.168.1.25:52193] procedure.ZKProcedureMemberRpcs(152): Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2017-02-22 10:38:14,723 INFO  [RS:0;192.168.1.25:52193] procedure.RegionServerProcedureManagerHost(53): Procedure online-snapshot is started
2017-02-22 10:38:14,723 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 1 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:14,726 DEBUG [FifoRpcScheduler.handler16-thread-2] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:38:14,726 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:38:14,727 DEBUG [SplitLogWorker-192.168.1.25,52193,1487756294244-EventThread] zookeeper.ZooKeeperWatcher(528): hconnection-0x722815ef0x0, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
2017-02-22 10:38:14,728 DEBUG [SplitLogWorker-192.168.1.25,52193,1487756294244-EventThread] zookeeper.ZooKeeperWatcher(591): hconnection-0x722815ef-0x15a652c12db0014 connected
2017-02-22 10:38:14,729 DEBUG [SplitLogWorker-192.168.1.25,52193,1487756294244] ipc.RpcClient(1307): Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@78d07e9f, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, maxIdleTime=10000, maxRetries=0, fallbackAllowed=false, ping interval=60000ms, bind address=null
2017-02-22 10:38:15,439 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 3 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:15,440 DEBUG [FifoRpcScheduler.handler13-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 8 bytes.
2017-02-22 10:38:15,440 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 3, totalSize: 4 bytes
2017-02-22 10:38:16,050 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 5 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:16,051 DEBUG [FifoRpcScheduler.handler10-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 8 bytes.
2017-02-22 10:38:16,051 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 5, totalSize: 4 bytes
2017-02-22 10:38:16,220 INFO  [M:0;192.168.1.25:52191] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 1590 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:17,723 INFO  [M:0;192.168.1.25:52191] master.ServerManager(901): Waiting for region servers count to settle; currently checked in 1, slept for 3093 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2017-02-22 10:38:17,732 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 2 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:17,732 DEBUG [FifoRpcScheduler.handler16-thread-3] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 8 bytes.
2017-02-22 10:38:17,733 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 2, totalSize: 4 bytes
2017-02-22 10:38:18,442 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 4 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:18,443 DEBUG [FifoRpcScheduler.handler13-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 8 bytes.
2017-02-22 10:38:18,443 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 4, totalSize: 4 bytes
2017-02-22 10:38:18,643 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: closed
2017-02-22 10:38:18,643 DEBUG [RpcServer.reader=1,port=52165] ipc.RpcServer$Listener(910): RpcServer.listener,port=52165: DISCONNECTING client 192.168.1.25:52174 because read count=-1. Number of active connections: 2
2017-02-22 10:38:18,643 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: stopped, connections 1
2017-02-22 10:38:18,736 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: closed
2017-02-22 10:38:18,736 DEBUG [RpcServer.reader=2,port=52165] ipc.RpcServer$Listener(910): RpcServer.listener,port=52165: DISCONNECTING client 192.168.1.25:52175 because read count=-1. Number of active connections: 1
2017-02-22 10:38:18,736 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52165 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52165 from roger: stopped, connections 0
2017-02-22 10:38:19,055 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 6 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:19,056 DEBUG [FifoRpcScheduler.handler10-thread-7] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 8 bytes.
2017-02-22 10:38:19,056 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 6, totalSize: 4 bytes
2017-02-22 10:38:19,163 INFO  [M:0;192.168.1.25:52191] master.ServerManager(918): Finished waiting for region servers count to settle; checked in 1, slept for 4533 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2017-02-22 10:38:19,164 INFO  [M:0;192.168.1.25:52191] master.MasterFileSystem(260): Log folder file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,52193,1487756294244 belongs to an existing region server
2017-02-22 10:38:19,171 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:38:19,171 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:51925
2017-02-22 10:38:19,171 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1014): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: closing ipc connection to /192.168.1.25:51925: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:583)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:873)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1578)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1477)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1694)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1764)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$BlockingStub.getRegionInfo(AdminProtos.java:21172)
	at org.apache.hadoop.hbase.protobuf.ProtobufUtil.getRegionInfo(ProtobufUtil.java:1699)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyRegionLocation(CatalogTracker.java:422)
	at org.apache.hadoop.hbase.catalog.CatalogTracker.verifyMetaRegionLocation(CatalogTracker.java:468)
	at org.apache.hadoop.hbase.master.HMaster.assignMeta(HMaster.java:1113)
	at org.apache.hadoop.hbase.master.HMaster.finishInitialization(HMaster.java:995)
	at org.apache.hadoop.hbase.master.HMaster.run(HMaster.java:698)
	at java.lang.Thread.run(Thread.java:745)
2017-02-22 10:38:19,171 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:51925 from roger: closed
2017-02-22 10:38:19,171 INFO  [M:0;192.168.1.25:52191] catalog.CatalogTracker(441): Failed verification of hbase:meta,,1 at address=192.168.1.25,51925,1487756071702, exception=java.net.ConnectException: Connection refused
2017-02-22 10:38:19,172 INFO  [M:0;192.168.1.25:52191] master.MasterFileSystem(332): Log dir for server 192.168.1.25,51925,1487756071702 does not exist
2017-02-22 10:38:19,172 INFO  [M:0;192.168.1.25:52191] master.SplitLogManager(1458): dead splitlog workers [192.168.1.25,51925,1487756071702]
2017-02-22 10:38:19,172 DEBUG [M:0;192.168.1.25:52191] master.SplitLogManager(323): Scheduling batch of logs to split
2017-02-22 10:38:19,172 INFO  [M:0;192.168.1.25:52191] master.SplitLogManager(325): started splitting 0 logs in []
2017-02-22 10:38:19,172 INFO  [M:0;192.168.1.25:52191] master.SplitLogManager(382): finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 0ms
2017-02-22 10:38:19,172 INFO  [M:0;192.168.1.25:52191] zookeeper.MetaRegionTracker(184): Unsetting hbase:meta region location in ZooKeeper
2017-02-22 10:38:19,174 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:19,174 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:19,176 DEBUG [M:0;192.168.1.25:52191] master.AssignmentManager(2461): No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=192.168.1.25,52193,1487756294244; 1 (online=1, available=1) available servers, forceNewPlan=false
2017-02-22 10:38:19,176 INFO  [M:0;192.168.1.25:52191] master.AssignmentManager(2089): Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:19,176 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKAssign(206): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Creating (or updating) unassigned node 1588230740 with OFFLINE state
2017-02-22 10:38:19,177 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:38:19,177 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZKUtil(368): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/meta-region-server
2017-02-22 10:38:19,178 INFO  [M:0;192.168.1.25:52191] master.AssignmentManager(2120): Assigning hbase:meta,,1.1588230740 to 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,178 INFO  [M:0;192.168.1.25:52191] master.RegionStates(894): Transition {1588230740 state=OFFLINE, ts=1487756299176, server=null} to {1588230740 state=PENDING_OPEN, ts=1487756299178, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,179 DEBUG [M:0;192.168.1.25:52191] master.ServerManager(836): New admin connection to 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,179 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service AdminService, sasl=false
2017-02-22 10:38:19,179 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52193
2017-02-22 10:38:19,181 DEBUG [RpcServer.listener,port=52193] ipc.RpcServer$Listener(885): RpcServer.listener,port=52193: connection from 192.168.1.25:52202; # active connections: 1
2017-02-22 10:38:19,181 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: starting, connections 1
2017-02-22 10:38:19,181 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 1 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:38:19,181 DEBUG [RpcServer.reader=1,port=52193] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "AdminService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:19,181 INFO  [PriorityRpcServer.handler=0,queue=0,port=52193] regionserver.HRegionServer(4011): Open hbase:meta,,1.1588230740
2017-02-22 10:38:19,182 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 1, totalSize: 6 bytes
2017-02-22 10:38:19,182 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] zookeeper.ZKAssign(832): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:19,182 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 10 bytes.
2017-02-22 10:38:19,182 INFO  [M:0;192.168.1.25:52191] master.ServerManager(618): AssignmentManager hasn't finished failover cleanup; waiting
2017-02-22 10:38:19,184 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:19,184 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] zookeeper.ZKAssign(907): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:19,184 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] regionserver.HRegionServer(1622): logdir=file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,184 INFO  [RS_OPEN_META-192.168.1.25:52193-0] wal.FSHLog(401): WAL/HLog configuration: blocksize=32 MB, rollsize=30.40 MB, enabled=true
2017-02-22 10:38:19,185 DEBUG [AM.ZK.Worker-pool93-t1] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,52193,1487756294244, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1487756299178, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,186 INFO  [AM.ZK.Worker-pool93-t1] master.RegionStates(894): Transition {1588230740 state=PENDING_OPEN, ts=1487756299178, server=192.168.1.25,52193,1487756294244} to {1588230740 state=OPENING, ts=1487756299186, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,201 INFO  [RS_OPEN_META-192.168.1.25:52193-0] wal.FSHLog(584): New WAL /var/tmp/test-data/cluster3/root/WALs/192.168.1.25,52193,1487756294244/192.168.1.25%2C52193%2C1487756294244.1487756299185.meta
2017-02-22 10:38:19,201 INFO  [RS_OPEN_META-192.168.1.25:52193-0] wal.FSHLog(468): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:19,201 INFO  [RS_OPEN_META-192.168.1.25:52193-0] wal.FSHLog(1734): FileSystem's output stream doesn't support getPipeline; not available; fsOut=java.io.BufferedOutputStream
2017-02-22 10:38:19,202 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] regionserver.HRegion(4915): Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:19,202 INFO  [RS_OPEN_META-192.168.1.25:52193-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:38:19,202 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] coprocessor.CoprocessorHost(226): Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2017-02-22 10:38:19,203 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] regionserver.HRegion(6103): Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2017-02-22 10:38:19,203 INFO  [RS_OPEN_META-192.168.1.25:52193-0] regionserver.RegionCoprocessorHost(373): Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2017-02-22 10:38:19,203 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table meta 1588230740
2017-02-22 10:38:19,203 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] regionserver.HRegion(718): Instantiated hbase:meta,,1.1588230740
2017-02-22 10:38:19,204 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:19,204 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:19,205 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740
2017-02-22 10:38:19,205 INFO  [RS_OPEN_META-192.168.1.25:52193-0] regionserver.HRegion(826): Onlined 1588230740; next sequenceid=1
2017-02-22 10:38:19,205 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] zookeeper.ZKAssign(644): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2017-02-22 10:38:19,207 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:meta,,1.1588230740
2017-02-22 10:38:19,207 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1911): Updating zk with meta location
2017-02-22 10:38:19,207 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaRegionTracker(142): Setting hbase:meta region location in ZooKeeper as 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,208 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:19,208 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeCreated, state=SyncConnected, path=/hbase/meta-region-server
2017-02-22 10:38:19,209 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:meta,,1.1588230740
2017-02-22 10:38:19,210 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] zookeeper.ZKAssign(832): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:19,212 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:19,212 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] zookeeper.ZKAssign(907): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:19,212 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] handler.OpenRegionHandler(403): Transitioned 1588230740 to OPENED in zk on 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,213 DEBUG [RS_OPEN_META-192.168.1.25:52193-0] handler.OpenRegionHandler(189): Opened hbase:meta,,1.1588230740 on 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,213 DEBUG [AM.ZK.Worker-pool93-t2] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,52193,1487756294244, region=1588230740, current_state={1588230740 state=OPENING, ts=1487756299186, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,213 INFO  [AM.ZK.Worker-pool93-t2] master.RegionStates(894): Transition {1588230740 state=OPENING, ts=1487756299186, server=192.168.1.25,52193,1487756294244} to {1588230740 state=OPEN, ts=1487756299213, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,214 INFO  [AM.ZK.Worker-pool93-t2] handler.OpenedRegionHandler(147): Handling OPENED of 1588230740 from 192.168.1.25,52193,1487756294244; deleting unassigned node
2017-02-22 10:38:19,215 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/1588230740
2017-02-22 10:38:19,216 DEBUG [AM.ZK.Worker-pool93-t2] zookeeper.ZKAssign(480): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:38:19,216 DEBUG [AM.ZK.Worker-pool93-t3] master.AssignmentManager$4(1316): Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1487756299213, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,217 INFO  [AM.ZK.Worker-pool93-t3] master.RegionStates(397): Onlined 1588230740 on 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,219 INFO  [M:0;192.168.1.25:52191] master.HMaster(1162): hbase:meta assigned=1, rit=false, location=192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,219 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service ClientService, sasl=false
2017-02-22 10:38:19,220 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52193
2017-02-22 10:38:19,221 DEBUG [RpcServer.listener,port=52193] ipc.RpcServer$Listener(885): RpcServer.listener,port=52193: connection from 192.168.1.25:52203; # active connections: 2
2017-02-22 10:38:19,221 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: starting, connections 2
2017-02-22 10:38:19,221 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 2 method_name: "Scan" request_param: true
2017-02-22 10:38:19,222 DEBUG [RpcServer.reader=2,port=52193] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "ClientService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:19,222 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 2 wrote 16 bytes.
2017-02-22 10:38:19,222 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 2, totalSize: 12 bytes
2017-02-22 10:38:19,223 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 3 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,223 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 18 bytes.
2017-02-22 10:38:19,223 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 3, totalSize: 14 bytes
2017-02-22 10:38:19,223 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 4 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,224 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 12 bytes.
2017-02-22 10:38:19,224 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 4, totalSize: 8 bytes
2017-02-22 10:38:19,224 INFO  [M:0;192.168.1.25:52191] catalog.MetaMigrationConvertingToPB(166): hbase:meta doesn't have any entries to update.
2017-02-22 10:38:19,224 INFO  [M:0;192.168.1.25:52191] catalog.MetaMigrationConvertingToPB(132): META already up-to date with PB serialization
2017-02-22 10:38:19,229 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 5 method_name: "Scan" request_param: true
2017-02-22 10:38:19,232 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 16 bytes.
2017-02-22 10:38:19,232 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 5, totalSize: 12 bytes
2017-02-22 10:38:19,232 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 6 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,232 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 18 bytes.
2017-02-22 10:38:19,232 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 6, totalSize: 14 bytes
2017-02-22 10:38:19,232 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 7 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,233 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 12 bytes.
2017-02-22 10:38:19,233 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 7, totalSize: 8 bytes
2017-02-22 10:38:19,237 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKAssign(498): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Deleting any existing unassigned nodes
2017-02-22 10:38:19,238 INFO  [M:0;192.168.1.25:52191] master.AssignmentManager(646): Clean cluster startup. Assigning user regions
2017-02-22 10:38:19,238 INFO  [M:0;192.168.1.25:52191] master.SnapshotOfRegionAssignmentFromMeta(95): Start to scan the hbase:meta for the current region assignment snappshot
2017-02-22 10:38:19,239 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 8 method_name: "Scan" request_param: true
2017-02-22 10:38:19,239 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 16 bytes.
2017-02-22 10:38:19,239 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 8, totalSize: 12 bytes
2017-02-22 10:38:19,240 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 9 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,240 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 18 bytes.
2017-02-22 10:38:19,240 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 9, totalSize: 14 bytes
2017-02-22 10:38:19,240 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 10 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,241 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 12 bytes.
2017-02-22 10:38:19,241 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 10, totalSize: 8 bytes
2017-02-22 10:38:19,241 INFO  [M:0;192.168.1.25:52191] master.SnapshotOfRegionAssignmentFromMeta(138): Finished to scan the hbase:meta for the current region assignmentsnapshot
2017-02-22 10:38:19,244 INFO  [M:0;192.168.1.25:52191] master.AssignmentManager(511): Joined the cluster in 20ms, failover=false
2017-02-22 10:38:19,247 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 11 method_name: "Scan" request_param: true
2017-02-22 10:38:19,250 DEBUG [CatalogJanitor-192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 12 method_name: "Scan" request_param: true
2017-02-22 10:38:19,250 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 16 bytes.
2017-02-22 10:38:19,250 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 11, totalSize: 12 bytes
2017-02-22 10:38:19,251 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 16 bytes.
2017-02-22 10:38:19,251 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 12, totalSize: 12 bytes
2017-02-22 10:38:19,251 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 13 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,251 DEBUG [CatalogJanitor-192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 14 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,251 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 13, totalSize: 14 bytes
2017-02-22 10:38:19,251 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 18 bytes.
2017-02-22 10:38:19,251 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 18 bytes.
2017-02-22 10:38:19,251 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 15 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,251 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 14, totalSize: 14 bytes
2017-02-22 10:38:19,251 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 12 bytes.
2017-02-22 10:38:19,252 DEBUG [CatalogJanitor-192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 16 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,252 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 15, totalSize: 8 bytes
2017-02-22 10:38:19,252 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 12 bytes.
2017-02-22 10:38:19,252 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 16, totalSize: 8 bytes
2017-02-22 10:38:19,252 INFO  [M:0;192.168.1.25:52191] master.TableNamespaceManager(85): Namespace table not found. Creating...
2017-02-22 10:38:19,255 DEBUG [M:0;192.168.1.25:52191] lock.ZKInterProcessLockBase(226): Acquired a lock for /hbase/table-lock/hbase:namespace/write-master:521910000000001
2017-02-22 10:38:19,255 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 17 method_name: "Scan" request_param: true
2017-02-22 10:38:19,256 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 17 wrote 16 bytes.
2017-02-22 10:38:19,256 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 17, totalSize: 12 bytes
2017-02-22 10:38:19,256 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 18 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,256 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 18 wrote 18 bytes.
2017-02-22 10:38:19,256 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 18, totalSize: 14 bytes
2017-02-22 10:38:19,256 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 19 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,257 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 19 wrote 12 bytes.
2017-02-22 10:38:19,257 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 19, totalSize: 8 bytes
2017-02-22 10:38:19,257 WARN  [M:0;192.168.1.25:52191] zookeeper.ZKTable(133): Moving table hbase:namespace state to enabling but was not first in disabled state: ENABLED
2017-02-22 10:38:19,258 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] handler.CreateTableHandler(165): Create table hbase:namespace
2017-02-22 10:38:19,270 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] util.FSTableDescriptors(661): Wrote descriptor into: file:/var/tmp/test-data/cluster3/root/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2017-02-22 10:38:19,270 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(4729): creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = file:/var/tmp/test-data/cluster3/root/.tmp Table name == hbase:namespace
2017-02-22 10:38:19,281 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:38:19,282 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1224): Closing hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.: disabling compactions & flushes
2017-02-22 10:38:19,282 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:38:19,282 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion(1340): Closed hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:38:19,283 DEBUG [htable-pool100-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 20 method_name: "Multi" request_param: true cell_block_meta { length: 141 } priority: 100
2017-02-22 10:38:19,285 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 20 wrote 18 bytes.
2017-02-22 10:38:19,285 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 20, totalSize: 14 bytes
2017-02-22 10:38:19,286 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] catalog.MetaEditor(307): Added 1
2017-02-22 10:38:19,287 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] master.AssignmentManager(1621): Assigning 1 region(s) to 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,287 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] zookeeper.ZKAssign(175): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Async create of unassigned node 17ef2f59c4d7f1148ea1b890ea053749 with OFFLINE state
2017-02-22 10:38:19,288 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:38:19,288 DEBUG [main-EventThread] master.OfflineCallback(69): rs={17ef2f59c4d7f1148ea1b890ea053749 state=OFFLINE, ts=1487756299286, server=null}, server=192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,288 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback(106): rs={17ef2f59c4d7f1148ea1b890ea053749 state=OFFLINE, ts=1487756299286, server=null}, server=192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,293 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] master.AssignmentManager(1673): 192.168.1.25,52193,1487756294244 unassigned znodes=1 of total=1
2017-02-22 10:38:19,294 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] master.RegionStates(894): Transition {17ef2f59c4d7f1148ea1b890ea053749 state=OFFLINE, ts=1487756299287, server=null} to {17ef2f59c4d7f1148ea1b890ea053749 state=PENDING_OPEN, ts=1487756299293, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,296 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 21 method_name: "OpenRegion" request_param: true priority: 0
2017-02-22 10:38:19,297 INFO  [PriorityRpcServer.handler=0,queue=0,port=52193] regionserver.HRegionServer(4011): Open hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:38:19,299 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 21 wrote 10 bytes.
2017-02-22 10:38:19,299 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 21, totalSize: 6 bytes
2017-02-22 10:38:19,299 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] zookeeper.ZKAssign(832): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioning 17ef2f59c4d7f1148ea1b890ea053749 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:19,300 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] master.AssignmentManager(1805): Bulk assigning done for 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,301 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] zookeeper.ZKAssign(907): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioned node 17ef2f59c4d7f1148ea1b890ea053749 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2017-02-22 10:38:19,301 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/17ef2f59c4d7f1148ea1b890ea053749
2017-02-22 10:38:19,301 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] regionserver.HRegion(4915): Opening region: {ENCODED => 17ef2f59c4d7f1148ea1b890ea053749, NAME => 'hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:19,302 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] coprocessor.CoprocessorHost(186): System coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor was loaded successfully with priority (536870911).
2017-02-22 10:38:19,302 DEBUG [AM.ZK.Worker-pool93-t5] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENING, server=192.168.1.25,52193,1487756294244, region=17ef2f59c4d7f1148ea1b890ea053749, current_state={17ef2f59c4d7f1148ea1b890ea053749 state=PENDING_OPEN, ts=1487756299293, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,302 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] regionserver.MetricsRegionSourceImpl(67): Creating new MetricsRegionSourceImpl for table namespace 17ef2f59c4d7f1148ea1b890ea053749
2017-02-22 10:38:19,302 INFO  [AM.ZK.Worker-pool93-t5] master.RegionStates(894): Transition {17ef2f59c4d7f1148ea1b890ea053749 state=PENDING_OPEN, ts=1487756299293, server=192.168.1.25,52193,1487756294244} to {17ef2f59c4d7f1148ea1b890ea053749 state=OPENING, ts=1487756299302, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,303 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] regionserver.HRegion(718): Instantiated hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:38:19,304 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] lock.ZKInterProcessLockBase(328): Released /hbase/table-lock/hbase:namespace/write-master:521910000000001
2017-02-22 10:38:19,304 INFO  [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] handler.CreateTableHandler(196): failed. null
2017-02-22 10:38:19,304 DEBUG [MASTER_TABLE_OPERATIONS-192.168.1.25:52191-0] security.UserGroupInformation(1513): PrivilegedAction as:roger (auth:SIMPLE) from:org.apache.hadoop.hbase.security.User$SecureHadoopUser.runAs(User.java:345)
2017-02-22 10:38:19,310 INFO  [StoreOpener-17ef2f59c4d7f1148ea1b890ea053749-1] hfile.CacheConfig(192): Created cacheConfig for info: CacheConfig:enabled [cacheDataOnRead=true] [cacheDataOnWrite=false] [cacheIndexesOnWrite=false] [cacheBloomsOnWrite=false] [cacheEvictOnClose=false] [cacheDataCompressed=false] [prefetchOnOpen=false]
2017-02-22 10:38:19,310 INFO  [StoreOpener-17ef2f59c4d7f1148ea1b890ea053749-1] compactions.CompactionConfiguration(126): size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000; tiered compaction: max_age 9223372036854775807, incoming window min 6, compaction policy for tiered window org.apache.hadoop.hbase.regionserver.compactions.ExploringCompactionPolicy, single output for minor true, compaction window factory org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory
2017-02-22 10:38:19,311 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] regionserver.HRegion(3471): Found 0 recovered edits file(s) under file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/17ef2f59c4d7f1148ea1b890ea053749
2017-02-22 10:38:19,311 INFO  [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] regionserver.HRegion(826): Onlined 17ef2f59c4d7f1148ea1b890ea053749; next sequenceid=1
2017-02-22 10:38:19,311 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] zookeeper.ZKAssign(644): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Attempting to retransition opening state of node 17ef2f59c4d7f1148ea1b890ea053749
2017-02-22 10:38:19,312 INFO  [PostOpenDeployTasks:17ef2f59c4d7f1148ea1b890ea053749] regionserver.HRegionServer(1892): Post open deploy tasks for region=hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:38:19,313 DEBUG [htable-pool101-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 22 method_name: "Multi" request_param: true cell_block_meta { length: 347 } priority: 100
2017-02-22 10:38:19,314 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 22 wrote 18 bytes.
2017-02-22 10:38:19,314 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 22, totalSize: 14 bytes
2017-02-22 10:38:19,314 INFO  [PostOpenDeployTasks:17ef2f59c4d7f1148ea1b890ea053749] catalog.MetaEditor(523): Updated row hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749. with server=192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,314 INFO  [PostOpenDeployTasks:17ef2f59c4d7f1148ea1b890ea053749] regionserver.HRegionServer(1927): Finished post open deploy task for hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:38:19,315 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] zookeeper.ZKAssign(832): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioning 17ef2f59c4d7f1148ea1b890ea053749 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:19,317 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/region-in-transition/17ef2f59c4d7f1148ea1b890ea053749
2017-02-22 10:38:19,317 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] zookeeper.ZKAssign(907): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Transitioned node 17ef2f59c4d7f1148ea1b890ea053749 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2017-02-22 10:38:19,317 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] handler.OpenRegionHandler(403): Transitioned 17ef2f59c4d7f1148ea1b890ea053749 to OPENED in zk on 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,317 DEBUG [RS_OPEN_PRIORITY_REGION-192.168.1.25:52193-0] handler.OpenRegionHandler(189): Opened hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749. on 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,318 DEBUG [AM.ZK.Worker-pool93-t6] master.AssignmentManager(930): Handling RS_ZK_REGION_OPENED, server=192.168.1.25,52193,1487756294244, region=17ef2f59c4d7f1148ea1b890ea053749, current_state={17ef2f59c4d7f1148ea1b890ea053749 state=OPENING, ts=1487756299302, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,318 INFO  [AM.ZK.Worker-pool93-t6] master.RegionStates(894): Transition {17ef2f59c4d7f1148ea1b890ea053749 state=OPENING, ts=1487756299302, server=192.168.1.25,52193,1487756294244} to {17ef2f59c4d7f1148ea1b890ea053749 state=OPEN, ts=1487756299318, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,318 DEBUG [AM.ZK.Worker-pool93-t6] handler.OpenedRegionHandler(149): Handling OPENED of 17ef2f59c4d7f1148ea1b890ea053749 from 192.168.1.25,52193,1487756294244; deleting unassigned node
2017-02-22 10:38:19,320 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/region-in-transition/17ef2f59c4d7f1148ea1b890ea053749
2017-02-22 10:38:19,320 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/region-in-transition
2017-02-22 10:38:19,320 DEBUG [AM.ZK.Worker-pool93-t6] zookeeper.ZKAssign(480): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Deleted unassigned node 17ef2f59c4d7f1148ea1b890ea053749 in expected state RS_ZK_REGION_OPENED
2017-02-22 10:38:19,320 DEBUG [AM.ZK.Worker-pool93-t8] master.AssignmentManager$4(1316): Znode hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749. deleted, state: {17ef2f59c4d7f1148ea1b890ea053749 state=OPEN, ts=1487756299318, server=192.168.1.25,52193,1487756294244}
2017-02-22 10:38:19,320 INFO  [AM.ZK.Worker-pool93-t8] master.RegionStates(397): Onlined 17ef2f59c4d7f1148ea1b890ea053749 on 192.168.1.25,52193,1487756294244
2017-02-22 10:38:19,365 DEBUG [M:0;192.168.1.25:52191] zookeeper.ZKUtil(366): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on existing znode=/hbase/namespace
2017-02-22 10:38:19,367 DEBUG [M:0;192.168.1.25:52191] hbase.ZKNamespaceManager(196): Updating namespace cache from node default with data: \x0A\x07default
2017-02-22 10:38:19,367 DEBUG [M:0;192.168.1.25:52191] hbase.ZKNamespaceManager(196): Updating namespace cache from node hbase with data: \x0A\x05hbase
2017-02-22 10:38:19,367 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 23 method_name: "Get" request_param: true
2017-02-22 10:38:19,368 DEBUG [PriorityRpcServer.handler=2,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 23 wrote 481 bytes.
2017-02-22 10:38:19,368 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 23, totalSize: 477 bytes
2017-02-22 10:38:19,369 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 24 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,369 DEBUG [PriorityRpcServer.handler=3,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 24 wrote 509 bytes.
2017-02-22 10:38:19,369 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 24 cell_block_meta { length: 488 }, totalSize: 505 bytes
2017-02-22 10:38:19,370 DEBUG [M:0;192.168.1.25:52191] client.ClientSmallScanner(169): Finished with small scan at {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2017-02-22 10:38:19,370 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 25 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:19,371 DEBUG [PriorityRpcServer.handler=4,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 25 wrote 12 bytes.
2017-02-22 10:38:19,371 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 25, totalSize: 8 bytes
2017-02-22 10:38:19,371 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 26 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:19,374 DEBUG [PriorityRpcServer.handler=5,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 26 wrote 12 bytes.
2017-02-22 10:38:19,374 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 26, totalSize: 8 bytes
2017-02-22 10:38:19,375 DEBUG [htable-pool102-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 27 method_name: "Multi" request_param: true cell_block_meta { length: 45 } priority: 100
2017-02-22 10:38:19,377 DEBUG [PriorityRpcServer.handler=6,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 27 wrote 18 bytes.
2017-02-22 10:38:19,377 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 27, totalSize: 14 bytes
2017-02-22 10:38:19,379 INFO  [M:0;192.168.1.25:52191] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:38:19,380 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:38:19,380 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 28 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:19,381 DEBUG [PriorityRpcServer.handler=7,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 28 wrote 12 bytes.
2017-02-22 10:38:19,381 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 28, totalSize: 8 bytes
2017-02-22 10:38:19,381 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 29 method_name: "Get" request_param: true priority: 100
2017-02-22 10:38:19,382 DEBUG [PriorityRpcServer.handler=8,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 29 wrote 12 bytes.
2017-02-22 10:38:19,382 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 29, totalSize: 8 bytes
2017-02-22 10:38:19,383 DEBUG [htable-pool102-t1] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 30 method_name: "Multi" request_param: true cell_block_meta { length: 41 } priority: 100
2017-02-22 10:38:19,385 DEBUG [PriorityRpcServer.handler=9,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 30 wrote 18 bytes.
2017-02-22 10:38:19,385 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 30, totalSize: 14 bytes
2017-02-22 10:38:19,386 INFO  [M:0;192.168.1.25:52191] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:38:19,387 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:38:19,387 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 31 method_name: "Scan" request_param: true
2017-02-22 10:38:19,388 DEBUG [B.DefaultRpcServer.handler=2,queue=2,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 31 wrote 16 bytes.
2017-02-22 10:38:19,388 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 31, totalSize: 12 bytes
2017-02-22 10:38:19,388 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 32 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,389 DEBUG [PriorityRpcServer.handler=0,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 32 wrote 112 bytes.
2017-02-22 10:38:19,389 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 32 cell_block_meta { length: 86 }, totalSize: 108 bytes
2017-02-22 10:38:19,390 DEBUG [M:0;192.168.1.25:52191] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: wrote request header call_id: 33 method_name: "Scan" request_param: true priority: 100
2017-02-22 10:38:19,390 DEBUG [PriorityRpcServer.handler=1,queue=0,port=52193] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 33 wrote 12 bytes.
2017-02-22 10:38:19,390 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: got response header call_id: 33, totalSize: 8 bytes
2017-02-22 10:38:19,391 INFO  [M:0;192.168.1.25:52191] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/default already exists and this is not a retry
2017-02-22 10:38:19,391 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/default
2017-02-22 10:38:19,393 INFO  [M:0;192.168.1.25:52191] zookeeper.RecoverableZooKeeper(594): Node /hbase/namespace/hbase already exists and this is not a retry
2017-02-22 10:38:19,393 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDataChanged, state=SyncConnected, path=/hbase/namespace/hbase
2017-02-22 10:38:19,393 INFO  [M:0;192.168.1.25:52191] master.HMaster(1043): Master has completed initialization
2017-02-22 10:38:19,393 INFO  [M:0;192.168.1.25:52191] zookeeper.ZooKeeperWatcher(236): not a secure deployment, proceeding
2017-02-22 10:38:20,743 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 3 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:20,744 DEBUG [FifoRpcScheduler.handler16-thread-4] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 3 wrote 8 bytes.
2017-02-22 10:38:20,744 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 3, totalSize: 4 bytes
2017-02-22 10:38:21,444 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 5 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:21,445 DEBUG [FifoRpcScheduler.handler13-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 8 bytes.
2017-02-22 10:38:21,445 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 5, totalSize: 4 bytes
2017-02-22 10:38:22,058 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 7 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:22,059 DEBUG [FifoRpcScheduler.handler10-thread-8] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 8 bytes.
2017-02-22 10:38:22,059 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 7, totalSize: 4 bytes
2017-02-22 10:38:23,750 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 4 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:23,751 DEBUG [FifoRpcScheduler.handler16-thread-5] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 4 wrote 8 bytes.
2017-02-22 10:38:23,751 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 4, totalSize: 4 bytes
2017-02-22 10:38:24,044 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: closed
2017-02-22 10:38:24,044 DEBUG [RpcServer.reader=1,port=52179] ipc.RpcServer$Listener(910): RpcServer.listener,port=52179: DISCONNECTING client 192.168.1.25:52188 because read count=-1. Number of active connections: 2
2017-02-22 10:38:24,044 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: stopped, connections 1
2017-02-22 10:38:24,129 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: closed
2017-02-22 10:38:24,129 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52179 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52179 from roger: stopped, connections 0
2017-02-22 10:38:24,129 DEBUG [RpcServer.reader=2,port=52179] ipc.RpcServer$Listener(910): RpcServer.listener,port=52179: DISCONNECTING client 192.168.1.25:52189 because read count=-1. Number of active connections: 1
2017-02-22 10:38:24,449 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 6 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:24,450 DEBUG [FifoRpcScheduler.handler13-thread-7] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 8 bytes.
2017-02-22 10:38:24,450 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 6, totalSize: 4 bytes
2017-02-22 10:38:25,064 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 8 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:25,065 DEBUG [FifoRpcScheduler.handler10-thread-9] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 8 bytes.
2017-02-22 10:38:25,065 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 8, totalSize: 4 bytes
2017-02-22 10:38:26,755 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 5 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:26,756 DEBUG [FifoRpcScheduler.handler16-thread-6] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 5 wrote 8 bytes.
2017-02-22 10:38:26,756 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 5, totalSize: 4 bytes
2017-02-22 10:38:27,456 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 7 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:27,457 DEBUG [FifoRpcScheduler.handler13-thread-8] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 8 bytes.
2017-02-22 10:38:27,457 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 7, totalSize: 4 bytes
2017-02-22 10:38:28,066 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 9 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:28,067 DEBUG [FifoRpcScheduler.handler10-thread-10] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 8 bytes.
2017-02-22 10:38:28,068 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 9, totalSize: 4 bytes
2017-02-22 10:38:29,295 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: closed
2017-02-22 10:38:29,295 DEBUG [RpcServer.reader=1,port=52193] ipc.RpcServer$Listener(910): RpcServer.listener,port=52193: DISCONNECTING client 192.168.1.25:52202 because read count=-1. Number of active connections: 2
2017-02-22 10:38:29,295 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: stopped, connections 1
2017-02-22 10:38:29,394 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: closed
2017-02-22 10:38:29,394 DEBUG [RpcServer.reader=2,port=52193] ipc.RpcServer$Listener(910): RpcServer.listener,port=52193: DISCONNECTING client 192.168.1.25:52203 because read count=-1. Number of active connections: 1
2017-02-22 10:38:29,395 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52193 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52193 from roger: stopped, connections 0
2017-02-22 10:38:29,760 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 6 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:29,760 DEBUG [FifoRpcScheduler.handler16-thread-7] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 6 wrote 8 bytes.
2017-02-22 10:38:29,761 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 6, totalSize: 4 bytes
2017-02-22 10:38:30,463 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 8 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:30,464 DEBUG [FifoRpcScheduler.handler13-thread-9] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 8 bytes.
2017-02-22 10:38:30,464 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 8, totalSize: 4 bytes
2017-02-22 10:38:31,070 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 10 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:31,071 DEBUG [FifoRpcScheduler.handler10-thread-11] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 8 bytes.
2017-02-22 10:38:31,071 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 10, totalSize: 4 bytes
2017-02-22 10:38:32,762 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 7 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:32,763 DEBUG [FifoRpcScheduler.handler16-thread-8] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 7 wrote 8 bytes.
2017-02-22 10:38:32,763 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 7, totalSize: 4 bytes
2017-02-22 10:38:33,470 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 9 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:33,471 DEBUG [FifoRpcScheduler.handler13-thread-10] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 8 bytes.
2017-02-22 10:38:33,472 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 9, totalSize: 4 bytes
2017-02-22 10:38:34,074 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 11 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:34,075 DEBUG [FifoRpcScheduler.handler10-thread-12] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 8 bytes.
2017-02-22 10:38:34,075 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 11, totalSize: 4 bytes
2017-02-22 10:38:35,769 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 8 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:35,770 DEBUG [FifoRpcScheduler.handler16-thread-9] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 8 wrote 8 bytes.
2017-02-22 10:38:35,770 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 8, totalSize: 4 bytes
2017-02-22 10:38:36,477 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 10 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:36,478 DEBUG [FifoRpcScheduler.handler13-thread-11] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 8 bytes.
2017-02-22 10:38:36,478 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 10, totalSize: 4 bytes
2017-02-22 10:38:37,081 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 12 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:37,082 DEBUG [FifoRpcScheduler.handler10-thread-13] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 8 bytes.
2017-02-22 10:38:37,082 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 12, totalSize: 4 bytes
2017-02-22 10:38:38,776 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 9 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:38,777 DEBUG [FifoRpcScheduler.handler16-thread-10] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 9 wrote 8 bytes.
2017-02-22 10:38:38,777 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 9, totalSize: 4 bytes
2017-02-22 10:38:39,484 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 11 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:39,485 DEBUG [FifoRpcScheduler.handler13-thread-12] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 8 bytes.
2017-02-22 10:38:39,485 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 11, totalSize: 4 bytes
2017-02-22 10:38:40,086 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 13 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:40,089 DEBUG [FifoRpcScheduler.handler10-thread-14] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 8 bytes.
2017-02-22 10:38:40,089 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 13, totalSize: 4 bytes
2017-02-22 10:38:41,783 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 10 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:41,784 DEBUG [FifoRpcScheduler.handler16-thread-11] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 10 wrote 8 bytes.
2017-02-22 10:38:41,784 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 10, totalSize: 4 bytes
2017-02-22 10:38:42,490 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 12 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:42,492 DEBUG [FifoRpcScheduler.handler13-thread-13] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 8 bytes.
2017-02-22 10:38:42,493 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 12, totalSize: 4 bytes
2017-02-22 10:38:43,095 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 14 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:43,098 DEBUG [FifoRpcScheduler.handler10-thread-15] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 8 bytes.
2017-02-22 10:38:43,099 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 14, totalSize: 4 bytes
2017-02-22 10:38:44,787 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 11 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:44,788 DEBUG [FifoRpcScheduler.handler16-thread-12] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 11 wrote 8 bytes.
2017-02-22 10:38:44,788 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 11, totalSize: 4 bytes
2017-02-22 10:38:45,499 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 13 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:45,499 DEBUG [FifoRpcScheduler.handler13-thread-14] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 8 bytes.
2017-02-22 10:38:45,500 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 13, totalSize: 4 bytes
2017-02-22 10:38:46,104 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 15 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:46,105 DEBUG [FifoRpcScheduler.handler10-thread-16] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 8 bytes.
2017-02-22 10:38:46,105 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 15, totalSize: 4 bytes
2017-02-22 10:38:47,793 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 12 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:47,793 DEBUG [FifoRpcScheduler.handler16-thread-13] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 12 wrote 8 bytes.
2017-02-22 10:38:47,794 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 12, totalSize: 4 bytes
2017-02-22 10:38:48,502 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 14 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:48,504 DEBUG [FifoRpcScheduler.handler13-thread-15] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 8 bytes.
2017-02-22 10:38:48,505 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 14, totalSize: 4 bytes
2017-02-22 10:38:49,110 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 16 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:49,110 DEBUG [FifoRpcScheduler.handler10-thread-17] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 8 bytes.
2017-02-22 10:38:49,110 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 16, totalSize: 4 bytes
2017-02-22 10:38:49,425 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service MasterService, sasl=false
2017-02-22 10:38:49,425 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52163
2017-02-22 10:38:49,428 DEBUG [RpcServer.listener,port=52163] ipc.RpcServer$Listener(885): RpcServer.listener,port=52163: connection from 192.168.1.25:52204; # active connections: 2
2017-02-22 10:38:49,428 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:38:49,428 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: starting, connections 1
2017-02-22 10:38:49,429 DEBUG [RpcServer.reader=2,port=52163] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "MasterService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:49,429 DEBUG [FifoRpcScheduler.handler10-thread-18] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:38:49,429 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:38:49,429 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: wrote request header call_id: 1 method_name: "GetTableDescriptors" request_param: true priority: 0
2017-02-22 10:38:49,430 DEBUG [FifoRpcScheduler.handler10-thread-19] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:38:49,430 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:38:49,430 INFO  [main] client.HConnectionManager$HConnectionImplementation(2322): Closing master protocol: MasterService
2017-02-22 10:38:49,431 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bd782000e
2017-02-22 10:38:49,435 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:49,437 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: closed
2017-02-22 10:38:49,437 DEBUG [RpcServer.reader=2,port=52163] ipc.RpcServer$Listener(910): RpcServer.listener,port=52163: DISCONNECTING client 192.168.1.25:52204 because read count=-1. Number of active connections: 2
2017-02-22 10:38:49,437 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: stopped, connections 0
2017-02-22 10:38:49,541 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service MasterService, sasl=false
2017-02-22 10:38:49,541 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52177
2017-02-22 10:38:49,546 DEBUG [RpcServer.listener,port=52177] ipc.RpcServer$Listener(885): RpcServer.listener,port=52177: connection from 192.168.1.25:52205; # active connections: 2
2017-02-22 10:38:49,546 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:38:49,546 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: starting, connections 1
2017-02-22 10:38:49,546 DEBUG [RpcServer.reader=2,port=52177] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "MasterService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:49,547 DEBUG [FifoRpcScheduler.handler13-thread-16] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:38:49,547 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:38:49,547 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 1 method_name: "GetTableDescriptors" request_param: true priority: 0
2017-02-22 10:38:49,547 DEBUG [FifoRpcScheduler.handler13-thread-17] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:38:49,547 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:38:49,548 INFO  [main] client.HConnectionManager$HConnectionImplementation(2322): Closing master protocol: MasterService
2017-02-22 10:38:49,548 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bf9a6000e
2017-02-22 10:38:49,551 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:49,553 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: closed
2017-02-22 10:38:49,553 DEBUG [RpcServer.reader=2,port=52177] ipc.RpcServer$Listener(910): RpcServer.listener,port=52177: DISCONNECTING client 192.168.1.25:52205 because read count=-1. Number of active connections: 2
2017-02-22 10:38:49,554 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: stopped, connections 0
2017-02-22 10:38:49,657 DEBUG [main] ipc.RpcClient$Connection(432): Use SIMPLE authentication for service MasterService, sasl=false
2017-02-22 10:38:49,657 DEBUG [main] ipc.RpcClient$Connection(867): Connecting to /192.168.1.25:52191
2017-02-22 10:38:49,660 DEBUG [RpcServer.listener,port=52191] ipc.RpcServer$Listener(885): RpcServer.listener,port=52191: connection from 192.168.1.25:52206; # active connections: 2
2017-02-22 10:38:49,660 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 0 method_name: "IsMasterRunning" request_param: true priority: 0
2017-02-22 10:38:49,660 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(727): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: starting, connections 1
2017-02-22 10:38:49,661 DEBUG [RpcServer.reader=2,port=52191] ipc.RpcServer$Connection(1911): Authorized user_info { effective_user: "roger" } service_name: "MasterService" cell_block_codec_class: "org.apache.hadoop.hbase.codec.KeyValueCodec" version_info { version: "0.98.24-hadoop2" url: "git://buildbox/data/src/hbase" revision: "9c13a1c3d8cf999014f30104d1aa9d79e74ca3d6" user: "apurtell" date: "Thu Dec 22 02:36:05 UTC 2016" src_checksum: "286dfd46f04c92066a514339558c8bf2" }
2017-02-22 10:38:49,661 DEBUG [FifoRpcScheduler.handler16-thread-14] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 0 wrote 10 bytes.
2017-02-22 10:38:49,661 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 0, totalSize: 6 bytes
2017-02-22 10:38:49,661 DEBUG [main] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 1 method_name: "GetTableDescriptors" request_param: true priority: 0
2017-02-22 10:38:49,662 DEBUG [FifoRpcScheduler.handler16-thread-15] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 1 wrote 8 bytes.
2017-02-22 10:38:49,662 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 1, totalSize: 4 bytes
2017-02-22 10:38:49,662 INFO  [main] client.HConnectionManager$HConnectionImplementation(2322): Closing master protocol: MasterService
2017-02-22 10:38:49,662 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652c12db000e
2017-02-22 10:38:49,664 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:49,668 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: closed
2017-02-22 10:38:49,668 DEBUG [RpcServer.reader=2,port=52191] ipc.RpcServer$Listener(910): RpcServer.listener,port=52191: DISCONNECTING client 192.168.1.25:52206 because read count=-1. Number of active connections: 2
2017-02-22 10:38:49,668 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: stopped, connections 0
2017-02-22 10:38:49,771 DEBUG [main] util.JVMClusterUtil(241): Shutting down HBase Cluster
2017-02-22 10:38:49,771 INFO  [main] master.HMaster(2748): Cluster shutdown requested
2017-02-22 10:38:49,772 INFO  [M:0;192.168.1.25:52163] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52165,1487756283339
2017-02-22 10:38:49,772 INFO  [192.168.1.25,52163,1487756283297-BalancerChore] hbase.Chore(93): 192.168.1.25,52163,1487756283297-BalancerChore exiting
2017-02-22 10:38:49,772 INFO  [192.168.1.25,52163,1487756283297-ClusterStatusChore] hbase.Chore(93): 192.168.1.25,52163,1487756283297-ClusterStatusChore exiting
2017-02-22 10:38:49,772 INFO  [CatalogJanitor-192.168.1.25:52163] hbase.Chore(93): CatalogJanitor-192.168.1.25:52163 exiting
2017-02-22 10:38:49,774 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:49,774 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:49,774 INFO  [main] regionserver.HRegionServer(1865): STOPPED: Shutdown requested
2017-02-22 10:38:49,775 INFO  [RS:0;192.168.1.25:52165] ipc.RpcServer(2286): Stopping server on 52165
2017-02-22 10:38:49,775 INFO  [RpcServer.listener,port=52165] ipc.RpcServer$Listener(823): RpcServer.listener,port=52165: stopping
2017-02-22 10:38:49,775 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:49,776 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:38:49,776 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZKUtil(368): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:49,776 INFO  [RS:0;192.168.1.25:52165] regionserver.SplitLogWorker(604): Sending interrupt to stop the worker thread
2017-02-22 10:38:49,776 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(971): Stopping infoServer
2017-02-22 10:38:49,776 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:38:49,777 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:38:49,777 INFO  [SplitLogWorker-192.168.1.25,52165,1487756283339] regionserver.SplitLogWorker(295): SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2017-02-22 10:38:49,778 INFO  [SplitLogWorker-192.168.1.25,52165,1487756283339] regionserver.SplitLogWorker(212): SplitLogWorker 192.168.1.25,52165,1487756283339 exiting
2017-02-22 10:38:49,894 INFO  [RS:0;192.168.1.25:52165] snapshot.RegionServerSnapshotManager(136): Stopping RegionServerSnapshotManager gracefully.
2017-02-22 10:38:49,894 INFO  [192.168.1.25,52165,1487756283339-HeapMemoryChore] hbase.Chore(93): 192.168.1.25,52165,1487756283339-HeapMemoryChore exiting
2017-02-22 10:38:49,895 INFO  [RS:0;192.168.1.25:52165.nonceCleaner] hbase.Chore(93): RS:0;192.168.1.25:52165.nonceCleaner exiting
2017-02-22 10:38:49,895 INFO  [RS:0;192.168.1.25:52165.compactionChecker] hbase.Chore(93): RS:0;192.168.1.25:52165.compactionChecker exiting
2017-02-22 10:38:49,895 INFO  [RS_OPEN_META-192.168.1.25:52165-0-MetaLogRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:38:49,894 INFO  [RS:0;192.168.1.25:52165.logRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:38:49,896 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1018): stopping server 192.168.1.25,52165,1487756283339
2017-02-22 10:38:49,894 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.0 exiting
2017-02-22 10:38:49,897 DEBUG [RS_CLOSE_REGION-192.168.1.25:52165-0] handler.CloseRegionHandler(128): Processing close of hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:49,897 DEBUG [RS:0;192.168.1.25:52165] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@34b36444
2017-02-22 10:38:49,898 DEBUG [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.HRegion(1224): Closing hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.: disabling compactions & flushes
2017-02-22 10:38:49,896 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.1 exiting
2017-02-22 10:38:49,898 DEBUG [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:49,898 INFO  [RS:0;192.168.1.25:52165] regionserver.CompactSplitThread(381): Waiting for Split Thread to finish...
2017-02-22 10:38:49,898 INFO  [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.HRegion(1819): Started memstore flush for hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319., current region memstore size 344
2017-02-22 10:38:49,899 INFO  [RS:0;192.168.1.25:52165] regionserver.CompactSplitThread(381): Waiting for Merge Thread to finish...
2017-02-22 10:38:49,899 INFO  [RS:0;192.168.1.25:52165] regionserver.CompactSplitThread(381): Waiting for Large Compaction Thread to finish...
2017-02-22 10:38:49,899 INFO  [RS:0;192.168.1.25:52165] regionserver.CompactSplitThread(381): Waiting for Small Compaction Thread to finish...
2017-02-22 10:38:49,899 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1231): Waiting on 2 regions to close
2017-02-22 10:38:49,899 DEBUG [RS_CLOSE_META-192.168.1.25:52165-0] handler.CloseRegionHandler(128): Processing close of hbase:meta,,1.1588230740
2017-02-22 10:38:49,899 DEBUG [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1235): {1588230740=hbase:meta,,1.1588230740, af97da49046429fb0f19334415bce319=hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.}
2017-02-22 10:38:49,900 DEBUG [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:38:49,901 DEBUG [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:38:49,901 INFO  [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.HRegion(1819): Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 992
2017-02-22 10:38:49,919 INFO  [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/af97da49046429fb0f19334415bce319/.tmp/7ae4e9f76f944be08a9719d1ec17dbea
2017-02-22 10:38:49,919 INFO  [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=992, hasBloomFilter=false, into tmp file file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/.tmp/1f6307a2e464495681126a38df02b0f9
2017-02-22 10:38:49,920 DEBUG [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/.tmp/1f6307a2e464495681126a38df02b0f9 as file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/info/1f6307a2e464495681126a38df02b0f9
2017-02-22 10:38:49,920 DEBUG [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/af97da49046429fb0f19334415bce319/.tmp/7ae4e9f76f944be08a9719d1ec17dbea as file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/af97da49046429fb0f19334415bce319/info/7ae4e9f76f944be08a9719d1ec17dbea
2017-02-22 10:38:49,922 INFO  [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster1/root/data/hbase/meta/1588230740/info/1f6307a2e464495681126a38df02b0f9, entries=4, sequenceid=4, filesize=1.3 K
2017-02-22 10:38:49,922 INFO  [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster1/root/data/hbase/namespace/af97da49046429fb0f19334415bce319/info/7ae4e9f76f944be08a9719d1ec17dbea, entries=2, sequenceid=4, filesize=1.0 K
2017-02-22 10:38:49,922 INFO  [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.HRegion(1986): Finished memstore flush of ~992/992, currentsize=0/0 for region hbase:meta,,1.1588230740 in 21ms, sequenceid=4, compaction requested=false
2017-02-22 10:38:49,922 INFO  [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.HRegion(1986): Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319. in 24ms, sequenceid=4, compaction requested=false
2017-02-22 10:38:49,924 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:38:49,924 INFO  [StoreCloserThread-hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.-1] regionserver.HStore(780): Closed info
2017-02-22 10:38:49,924 DEBUG [RS_CLOSE_META-192.168.1.25:52165-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:38:49,924 DEBUG [RS_CLOSE_REGION-192.168.1.25:52165-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:38:49,924 DEBUG [RS_CLOSE_META-192.168.1.25:52165-0] coprocessor.CoprocessorHost(316): Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2017-02-22 10:38:49,924 INFO  [RS_CLOSE_REGION-192.168.1.25:52165-0] regionserver.HRegion(1340): Closed hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:49,924 INFO  [RS_CLOSE_META-192.168.1.25:52165-0] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:38:49,925 DEBUG [RS_CLOSE_REGION-192.168.1.25:52165-0] handler.CloseRegionHandler(182): Closed hbase:namespace,,1487756288585.af97da49046429fb0f19334415bce319.
2017-02-22 10:38:49,925 DEBUG [RS_CLOSE_META-192.168.1.25:52165-0] handler.CloseRegionHandler(182): Closed hbase:meta,,1.1588230740
2017-02-22 10:38:50,021 INFO  [192.168.1.25,52163,1487756283297.splitLogManagerTimeoutMonitor] hbase.Chore(93): 192.168.1.25,52163,1487756283297.splitLogManagerTimeoutMonitor exiting
2017-02-22 10:38:50,105 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1037): stopping server 192.168.1.25,52165,1487756283339; all regions closed.
2017-02-22 10:38:50,105 DEBUG [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:38:50,105 INFO  [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncNotifier exiting
2017-02-22 10:38:50,105 DEBUG [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,105 INFO  [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer0 exiting
2017-02-22 10:38:50,106 DEBUG [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,106 INFO  [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer1 exiting
2017-02-22 10:38:50,106 DEBUG [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,106 INFO  [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer2 exiting
2017-02-22 10:38:50,106 DEBUG [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,106 INFO  [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer3 exiting
2017-02-22 10:38:50,106 DEBUG [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,106 INFO  [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncSyncer4 exiting
2017-02-22 10:38:50,107 DEBUG [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:38:50,107 INFO  [RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS_OPEN_META-192.168.1.25:52165-0-WAL.AsyncWriter exiting
2017-02-22 10:38:50,107 DEBUG [RS:0;192.168.1.25:52165] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:50,107 DEBUG [RS:0;192.168.1.25:52165-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS:0;192.168.1.25:52165-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:38:50,107 INFO  [RS:0;192.168.1.25:52165-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS:0;192.168.1.25:52165-WAL.AsyncNotifier exiting
2017-02-22 10:38:50,107 DEBUG [RS:0;192.168.1.25:52165-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52165-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,108 INFO  [RS:0;192.168.1.25:52165-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52165-WAL.AsyncSyncer0 exiting
2017-02-22 10:38:50,108 DEBUG [RS:0;192.168.1.25:52165-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52165-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,108 INFO  [RS:0;192.168.1.25:52165-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52165-WAL.AsyncSyncer1 exiting
2017-02-22 10:38:50,108 DEBUG [RS:0;192.168.1.25:52165-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52165-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,108 INFO  [RS:0;192.168.1.25:52165-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52165-WAL.AsyncSyncer2 exiting
2017-02-22 10:38:50,108 DEBUG [RS:0;192.168.1.25:52165-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52165-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,108 INFO  [RS:0;192.168.1.25:52165-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52165-WAL.AsyncSyncer3 exiting
2017-02-22 10:38:50,109 DEBUG [RS:0;192.168.1.25:52165-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52165-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:50,109 INFO  [RS:0;192.168.1.25:52165-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52165-WAL.AsyncSyncer4 exiting
2017-02-22 10:38:50,109 DEBUG [RS:0;192.168.1.25:52165-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS:0;192.168.1.25:52165-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:38:50,109 INFO  [RS:0;192.168.1.25:52165-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS:0;192.168.1.25:52165-WAL.AsyncWriter exiting
2017-02-22 10:38:50,109 DEBUG [RS:0;192.168.1.25:52165] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster1/root/WALs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:50,110 DEBUG [RS:0;192.168.1.25:52165] wal.FSHLog(892): Moved 2 WAL file(s) to /var/tmp/test-data/cluster1/root/oldWALs
2017-02-22 10:38:50,110 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:50,112 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: closed
2017-02-22 10:38:50,113 DEBUG [RpcServer.reader=1,port=52163] ipc.RpcServer$Listener(910): RpcServer.listener,port=52163: DISCONNECTING client 192.168.1.25:52170 because read count=-1. Number of active connections: 1
2017-02-22 10:38:50,113 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52163 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52163 from roger: stopped, connections 0
2017-02-22 10:38:50,214 INFO  [RS:0;192.168.1.25:52165] regionserver.Leases(147): RS:0;192.168.1.25:52165 closing leases
2017-02-22 10:38:50,214 INFO  [RS:0;192.168.1.25:52165] regionserver.Leases(150): RS:0;192.168.1.25:52165 closed leases
2017-02-22 10:38:50,799 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 13 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:50,800 DEBUG [FifoRpcScheduler.handler16-thread-16] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 13 wrote 8 bytes.
2017-02-22 10:38:50,800 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 13, totalSize: 4 bytes
2017-02-22 10:38:50,816 INFO  [M:0;192.168.1.25:52163] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52165,1487756283339
2017-02-22 10:38:51,507 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: wrote request header call_id: 15 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:51,507 DEBUG [FifoRpcScheduler.handler13-thread-18] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 8 bytes.
2017-02-22 10:38:51,508 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: got response header call_id: 15, totalSize: 4 bytes
2017-02-22 10:38:51,849 INFO  [M:0;192.168.1.25:52163] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52165,1487756283339
2017-02-22 10:38:52,894 INFO  [M:0;192.168.1.25:52163] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52165,1487756283339
2017-02-22 10:38:53,806 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 14 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:53,806 DEBUG [FifoRpcScheduler.handler16-thread-17] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 14 wrote 8 bytes.
2017-02-22 10:38:53,807 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 14, totalSize: 4 bytes
2017-02-22 10:38:53,927 INFO  [M:0;192.168.1.25:52163] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52165,1487756283339
2017-02-22 10:38:54,001 INFO  [RS:0;192.168.1.25:52165.periodicFlusher] hbase.Chore(93): RS:0;192.168.1.25:52165.periodicFlusher exiting
2017-02-22 10:38:54,002 INFO  [RS:0;192.168.1.25:52165.leaseChecker] regionserver.Leases(147): RS:0;192.168.1.25:52165.leaseChecker closing leases
2017-02-22 10:38:54,002 INFO  [RS:0;192.168.1.25:52165.leaseChecker] regionserver.Leases(150): RS:0;192.168.1.25:52165.leaseChecker closed leases
2017-02-22 10:38:54,005 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/replication/rs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:54,005 INFO  [RS:0;192.168.1.25:52165] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bd7820013
2017-02-22 10:38:54,008 DEBUG [RS:0;192.168.1.25:52165] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:54,009 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:54,010 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,52165,1487756283339
2017-02-22 10:38:54,010 INFO  [main-EventThread] zookeeper.RegionServerTracker(118): RegionServer ephemeral node deleted, processing expiration [192.168.1.25,52165,1487756283339]
2017-02-22 10:38:54,010 DEBUG [RS:0;192.168.1.25:52165-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52165-0x15a652bd7820012, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:38:54,011 INFO  [main-EventThread] master.ServerManager(550): Cluster shutdown set; 192.168.1.25,52165,1487756283339 expired; onlineServers=0
2017-02-22 10:38:54,011 DEBUG [M:0;192.168.1.25:52163] master.HMaster(1359): Stopping service threads
2017-02-22 10:38:54,011 INFO  [M:0;192.168.1.25:52163] ipc.RpcServer(2286): Stopping server on 52163
2017-02-22 10:38:54,011 INFO  [main-EventThread] master.HMaster(2748): Cluster shutdown set; onlineServer=0
2017-02-22 10:38:54,012 INFO  [RpcServer.listener,port=52163] ipc.RpcServer$Listener(823): RpcServer.listener,port=52163: stopping
2017-02-22 10:38:54,012 DEBUG [main-EventThread] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@5fa5c346
2017-02-22 10:38:54,012 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:38:54,015 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:38:54,015 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:38:54,015 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:38:54,015 INFO  [M:0;192.168.1.25:52163.oldLogCleaner] hbase.Chore(93): M:0;192.168.1.25:52163.oldLogCleaner exiting
2017-02-22 10:38:54,015 INFO  [M:0;192.168.1.25:52163.archivedHFileCleaner] hbase.Chore(93): M:0;192.168.1.25:52163.archivedHFileCleaner exiting
2017-02-22 10:38:54,015 INFO  [M:0;192.168.1.25:52163.oldLogCleaner] master.ReplicationLogCleaner(164): Stopping replicationLogCleaner-0x15a652bd7820011, quorum=localhost:16262, baseZNode=/hbase
2017-02-22 10:38:54,019 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1075): stopping server 192.168.1.25,52165,1487756283339; zookeeper connection closed.
2017-02-22 10:38:54,019 INFO  [RS:0;192.168.1.25:52165] regionserver.HRegionServer(1078): RS:0;192.168.1.25:52165 exiting
2017-02-22 10:38:54,019 INFO  [Shutdown of org.apache.hadoop.hbase.fs.HFileSystem@5c1d6db1] hbase.MiniHBaseCluster$SingleFileSystemShutdownThread(190): Hook closing fs=org.apache.hadoop.hbase.fs.HFileSystem@5c1d6db1
2017-02-22 10:38:54,020 INFO  [main] util.JVMClusterUtil(325): Shutdown of 1 master(s) and 1 regionserver(s) complete
2017-02-22 10:38:54,020 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bf9a60014
2017-02-22 10:38:54,020 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master
2017-02-22 10:38:54,021 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52163-0x15a652bd782000f, quorum=localhost:16262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:38:54,023 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:54,023 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652c12db0014
2017-02-22 10:38:54,024 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:54,025 INFO  [main] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bd7820014
2017-02-22 10:38:54,027 DEBUG [main] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:54,027 DEBUG [main] util.JVMClusterUtil(241): Shutting down HBase Cluster
2017-02-22 10:38:54,027 INFO  [main] master.HMaster(2748): Cluster shutdown requested
2017-02-22 10:38:54,028 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:38:54,028 INFO  [192.168.1.25,52177,1487756288838-BalancerChore] hbase.Chore(93): 192.168.1.25,52177,1487756288838-BalancerChore exiting
2017-02-22 10:38:54,029 INFO  [192.168.1.25,52177,1487756288838-ClusterStatusChore] hbase.Chore(93): 192.168.1.25,52177,1487756288838-ClusterStatusChore exiting
2017-02-22 10:38:54,029 INFO  [CatalogJanitor-192.168.1.25:52177] hbase.Chore(93): CatalogJanitor-192.168.1.25:52177 exiting
2017-02-22 10:38:54,029 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:54,030 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:38:54,030 INFO  [main] regionserver.HRegionServer(1865): STOPPED: Shutdown requested
2017-02-22 10:38:54,030 INFO  [M:0;192.168.1.25:52163] master.HMaster(733): HMaster main thread exiting
2017-02-22 10:38:54,030 INFO  [RS:0;192.168.1.25:52179] ipc.RpcServer(2286): Stopping server on 52179
2017-02-22 10:38:54,031 INFO  [RpcServer.listener,port=52179] ipc.RpcServer$Listener(823): RpcServer.listener,port=52179: stopping
2017-02-22 10:38:54,033 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZKUtil(368): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:54,033 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:38:54,033 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:38:54,034 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:38:54,034 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:38:54,035 INFO  [RS:0;192.168.1.25:52179] regionserver.SplitLogWorker(604): Sending interrupt to stop the worker thread
2017-02-22 10:38:54,035 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(971): Stopping infoServer
2017-02-22 10:38:54,035 INFO  [SplitLogWorker-192.168.1.25,52179,1487756288868] regionserver.SplitLogWorker(295): SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2017-02-22 10:38:54,035 INFO  [SplitLogWorker-192.168.1.25,52179,1487756288868] regionserver.SplitLogWorker(212): SplitLogWorker 192.168.1.25,52179,1487756288868 exiting
2017-02-22 10:38:54,148 INFO  [RS:0;192.168.1.25:52179] snapshot.RegionServerSnapshotManager(136): Stopping RegionServerSnapshotManager gracefully.
2017-02-22 10:38:54,148 INFO  [RS:0;192.168.1.25:52179.logRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:38:54,149 INFO  [RS:0;192.168.1.25:52179.nonceCleaner] hbase.Chore(93): RS:0;192.168.1.25:52179.nonceCleaner exiting
2017-02-22 10:38:54,149 INFO  [RS_OPEN_META-192.168.1.25:52179-0-MetaLogRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:38:54,148 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.1 exiting
2017-02-22 10:38:54,148 INFO  [192.168.1.25,52179,1487756288868-HeapMemoryChore] hbase.Chore(93): 192.168.1.25,52179,1487756288868-HeapMemoryChore exiting
2017-02-22 10:38:54,150 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1018): stopping server 192.168.1.25,52179,1487756288868
2017-02-22 10:38:54,150 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.0 exiting
2017-02-22 10:38:54,149 INFO  [RS:0;192.168.1.25:52179.compactionChecker] hbase.Chore(93): RS:0;192.168.1.25:52179.compactionChecker exiting
2017-02-22 10:38:54,150 DEBUG [RS_CLOSE_REGION-192.168.1.25:52179-0] handler.CloseRegionHandler(128): Processing close of hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:54,150 DEBUG [RS:0;192.168.1.25:52179] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@2e75c6ef
2017-02-22 10:38:54,151 INFO  [RS:0;192.168.1.25:52179] regionserver.CompactSplitThread(381): Waiting for Split Thread to finish...
2017-02-22 10:38:54,151 DEBUG [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.HRegion(1224): Closing hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.: disabling compactions & flushes
2017-02-22 10:38:54,152 INFO  [RS:0;192.168.1.25:52179] regionserver.CompactSplitThread(381): Waiting for Merge Thread to finish...
2017-02-22 10:38:54,152 DEBUG [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:54,152 INFO  [RS:0;192.168.1.25:52179] regionserver.CompactSplitThread(381): Waiting for Large Compaction Thread to finish...
2017-02-22 10:38:54,152 INFO  [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.HRegion(1819): Started memstore flush for hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f., current region memstore size 344
2017-02-22 10:38:54,152 INFO  [RS:0;192.168.1.25:52179] regionserver.CompactSplitThread(381): Waiting for Small Compaction Thread to finish...
2017-02-22 10:38:54,152 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1231): Waiting on 2 regions to close
2017-02-22 10:38:54,152 DEBUG [RS_CLOSE_META-192.168.1.25:52179-0] handler.CloseRegionHandler(128): Processing close of hbase:meta,,1.1588230740
2017-02-22 10:38:54,152 DEBUG [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1235): {bfe890dd6be7d22d590410994269660f=hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f., 1588230740=hbase:meta,,1.1588230740}
2017-02-22 10:38:54,153 DEBUG [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:38:54,153 DEBUG [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:38:54,153 INFO  [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.HRegion(1819): Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 992
2017-02-22 10:38:54,173 INFO  [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=992, hasBloomFilter=false, into tmp file file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/.tmp/9e98735521b94a2db15034c0a192c936
2017-02-22 10:38:54,173 INFO  [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/bfe890dd6be7d22d590410994269660f/.tmp/541fa0aeebc04fc2a0a68763e17fed76
2017-02-22 10:38:54,174 DEBUG [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/.tmp/9e98735521b94a2db15034c0a192c936 as file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/info/9e98735521b94a2db15034c0a192c936
2017-02-22 10:38:54,174 DEBUG [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/bfe890dd6be7d22d590410994269660f/.tmp/541fa0aeebc04fc2a0a68763e17fed76 as file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/bfe890dd6be7d22d590410994269660f/info/541fa0aeebc04fc2a0a68763e17fed76
2017-02-22 10:38:54,175 INFO  [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster2/root/data/hbase/meta/1588230740/info/9e98735521b94a2db15034c0a192c936, entries=4, sequenceid=4, filesize=1.3 K
2017-02-22 10:38:54,176 INFO  [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.HRegion(1986): Finished memstore flush of ~992/992, currentsize=0/0 for region hbase:meta,,1.1588230740 in 23ms, sequenceid=4, compaction requested=false
2017-02-22 10:38:54,176 INFO  [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster2/root/data/hbase/namespace/bfe890dd6be7d22d590410994269660f/info/541fa0aeebc04fc2a0a68763e17fed76, entries=2, sequenceid=4, filesize=1.0 K
2017-02-22 10:38:54,176 INFO  [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.HRegion(1986): Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f. in 24ms, sequenceid=4, compaction requested=false
2017-02-22 10:38:54,177 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:38:54,177 INFO  [StoreCloserThread-hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.-1] regionserver.HStore(780): Closed info
2017-02-22 10:38:54,178 DEBUG [RS_CLOSE_META-192.168.1.25:52179-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:38:54,178 DEBUG [RS_CLOSE_REGION-192.168.1.25:52179-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:38:54,178 DEBUG [RS_CLOSE_META-192.168.1.25:52179-0] coprocessor.CoprocessorHost(316): Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2017-02-22 10:38:54,178 INFO  [RS_CLOSE_REGION-192.168.1.25:52179-0] regionserver.HRegion(1340): Closed hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:54,178 INFO  [RS_CLOSE_META-192.168.1.25:52179-0] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:38:54,178 DEBUG [RS_CLOSE_REGION-192.168.1.25:52179-0] handler.CloseRegionHandler(182): Closed hbase:namespace,,1487756293991.bfe890dd6be7d22d590410994269660f.
2017-02-22 10:38:54,178 DEBUG [RS_CLOSE_META-192.168.1.25:52179-0] handler.CloseRegionHandler(182): Closed hbase:meta,,1.1588230740
2017-02-22 10:38:54,357 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1037): stopping server 192.168.1.25,52179,1487756288868; all regions closed.
2017-02-22 10:38:54,357 DEBUG [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:38:54,357 INFO  [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncNotifier exiting
2017-02-22 10:38:54,357 DEBUG [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,358 INFO  [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer0 exiting
2017-02-22 10:38:54,358 DEBUG [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,358 INFO  [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer1 exiting
2017-02-22 10:38:54,358 DEBUG [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,358 INFO  [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer2 exiting
2017-02-22 10:38:54,358 DEBUG [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,359 INFO  [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer3 exiting
2017-02-22 10:38:54,359 DEBUG [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,359 INFO  [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncSyncer4 exiting
2017-02-22 10:38:54,359 DEBUG [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:38:54,359 INFO  [RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS_OPEN_META-192.168.1.25:52179-0-WAL.AsyncWriter exiting
2017-02-22 10:38:54,359 DEBUG [RS:0;192.168.1.25:52179] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:54,360 DEBUG [RS:0;192.168.1.25:52179-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS:0;192.168.1.25:52179-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:38:54,360 INFO  [RS:0;192.168.1.25:52179-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS:0;192.168.1.25:52179-WAL.AsyncNotifier exiting
2017-02-22 10:38:54,360 DEBUG [RS:0;192.168.1.25:52179-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52179-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,360 INFO  [RS:0;192.168.1.25:52179-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52179-WAL.AsyncSyncer0 exiting
2017-02-22 10:38:54,360 DEBUG [RS:0;192.168.1.25:52179-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52179-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,360 INFO  [RS:0;192.168.1.25:52179-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52179-WAL.AsyncSyncer1 exiting
2017-02-22 10:38:54,361 DEBUG [RS:0;192.168.1.25:52179-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52179-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,361 INFO  [RS:0;192.168.1.25:52179-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52179-WAL.AsyncSyncer2 exiting
2017-02-22 10:38:54,361 DEBUG [RS:0;192.168.1.25:52179-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52179-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,361 INFO  [RS:0;192.168.1.25:52179-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52179-WAL.AsyncSyncer3 exiting
2017-02-22 10:38:54,361 DEBUG [RS:0;192.168.1.25:52179-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52179-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:38:54,361 INFO  [RS:0;192.168.1.25:52179-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52179-WAL.AsyncSyncer4 exiting
2017-02-22 10:38:54,361 DEBUG [RS:0;192.168.1.25:52179-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS:0;192.168.1.25:52179-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:38:54,362 INFO  [RS:0;192.168.1.25:52179-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS:0;192.168.1.25:52179-WAL.AsyncWriter exiting
2017-02-22 10:38:54,362 DEBUG [RS:0;192.168.1.25:52179] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster2/root/WALs/192.168.1.25,52179,1487756288868
2017-02-22 10:38:54,363 DEBUG [RS:0;192.168.1.25:52179] wal.FSHLog(892): Moved 2 WAL file(s) to /var/tmp/test-data/cluster2/root/oldWALs
2017-02-22 10:38:54,364 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:38:54,365 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: closed
2017-02-22 10:38:54,365 DEBUG [RpcServer.reader=1,port=52177] ipc.RpcServer$Listener(910): RpcServer.listener,port=52177: DISCONNECTING client 192.168.1.25:52183 because read count=-1. Number of active connections: 1
2017-02-22 10:38:54,365 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52177 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52177 from roger: stopped, connections 0
2017-02-22 10:38:54,455 INFO  [192.168.1.25,52177,1487756288838.splitLogManagerTimeoutMonitor] hbase.Chore(93): 192.168.1.25,52177,1487756288838.splitLogManagerTimeoutMonitor exiting
2017-02-22 10:38:54,465 INFO  [RS:0;192.168.1.25:52179] regionserver.Leases(147): RS:0;192.168.1.25:52179 closing leases
2017-02-22 10:38:54,465 INFO  [RS:0;192.168.1.25:52179] regionserver.Leases(150): RS:0;192.168.1.25:52179 closed leases
2017-02-22 10:38:55,065 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:38:56,110 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:38:56,808 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 15 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:56,808 DEBUG [FifoRpcScheduler.handler16-thread-18] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 15 wrote 8 bytes.
2017-02-22 10:38:56,808 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 15, totalSize: 4 bytes
2017-02-22 10:38:57,155 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:38:58,200 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:38:59,241 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:38:59,811 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient$Connection(1062): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: wrote request header call_id: 16 method_name: "RegionServerReport" request_param: true priority: 0
2017-02-22 10:38:59,812 DEBUG [FifoRpcScheduler.handler16-thread-19] ipc.RpcServer$Responder(1128): RpcServer.responder: callId: 16 wrote 8 bytes.
2017-02-22 10:38:59,812 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1090): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: got response header call_id: 16, totalSize: 4 bytes
2017-02-22 10:39:00,280 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:39:01,323 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:39:02,368 INFO  [M:0;192.168.1.25:52177] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52179,1487756288868
2017-02-22 10:39:02,412 INFO  [RS:0;192.168.1.25:52179.periodicFlusher] hbase.Chore(93): RS:0;192.168.1.25:52179.periodicFlusher exiting
2017-02-22 10:39:02,412 INFO  [RS:0;192.168.1.25:52179.leaseChecker] regionserver.Leases(147): RS:0;192.168.1.25:52179.leaseChecker closing leases
2017-02-22 10:39:02,412 INFO  [RS:0;192.168.1.25:52179.leaseChecker] regionserver.Leases(150): RS:0;192.168.1.25:52179.leaseChecker closed leases
2017-02-22 10:39:02,416 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/replication/rs/192.168.1.25,52179,1487756288868
2017-02-22 10:39:02,416 INFO  [RS:0;192.168.1.25:52179] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652bf9a60013
2017-02-22 10:39:02,418 DEBUG [RS:0;192.168.1.25:52179] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:39:02,419 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,52179,1487756288868
2017-02-22 10:39:02,419 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,52179,1487756288868
2017-02-22 10:39:02,420 INFO  [main-EventThread] zookeeper.RegionServerTracker(118): RegionServer ephemeral node deleted, processing expiration [192.168.1.25,52179,1487756288868]
2017-02-22 10:39:02,420 DEBUG [RS:0;192.168.1.25:52179-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52179-0x15a652bf9a60011, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:39:02,420 INFO  [main-EventThread] master.ServerManager(550): Cluster shutdown set; 192.168.1.25,52179,1487756288868 expired; onlineServers=0
2017-02-22 10:39:02,420 DEBUG [M:0;192.168.1.25:52177] master.HMaster(1359): Stopping service threads
2017-02-22 10:39:02,420 INFO  [M:0;192.168.1.25:52177] ipc.RpcServer(2286): Stopping server on 52177
2017-02-22 10:39:02,420 INFO  [main-EventThread] master.HMaster(2748): Cluster shutdown set; onlineServer=0
2017-02-22 10:39:02,420 INFO  [RpcServer.listener,port=52177] ipc.RpcServer$Listener(823): RpcServer.listener,port=52177: stopping
2017-02-22 10:39:02,420 DEBUG [main-EventThread] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4477b22a
2017-02-22 10:39:02,421 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:39:02,422 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:39:02,422 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:39:02,423 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:39:02,423 INFO  [M:0;192.168.1.25:52177.oldLogCleaner] hbase.Chore(93): M:0;192.168.1.25:52177.oldLogCleaner exiting
2017-02-22 10:39:02,423 INFO  [M:0;192.168.1.25:52177.oldLogCleaner] master.ReplicationLogCleaner(164): Stopping replicationLogCleaner-0x15a652bf9a60012, quorum=localhost:26262, baseZNode=/hbase
2017-02-22 10:39:02,423 INFO  [M:0;192.168.1.25:52177.archivedHFileCleaner] hbase.Chore(93): M:0;192.168.1.25:52177.archivedHFileCleaner exiting
2017-02-22 10:39:02,425 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1075): stopping server 192.168.1.25,52179,1487756288868; zookeeper connection closed.
2017-02-22 10:39:02,426 INFO  [RS:0;192.168.1.25:52179] regionserver.HRegionServer(1078): RS:0;192.168.1.25:52179 exiting
2017-02-22 10:39:02,426 INFO  [Shutdown of org.apache.hadoop.hbase.fs.HFileSystem@11eb42c5] hbase.MiniHBaseCluster$SingleFileSystemShutdownThread(190): Hook closing fs=org.apache.hadoop.hbase.fs.HFileSystem@11eb42c5
2017-02-22 10:39:02,427 INFO  [main] util.JVMClusterUtil(325): Shutdown of 1 master(s) and 1 regionserver(s) complete
2017-02-22 10:39:02,428 DEBUG [main] util.JVMClusterUtil(241): Shutting down HBase Cluster
2017-02-22 10:39:02,429 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master
2017-02-22 10:39:02,429 INFO  [main] master.HMaster(2748): Cluster shutdown requested
2017-02-22 10:39:02,429 INFO  [M:0;192.168.1.25:52191] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52193,1487756294244
2017-02-22 10:39:02,429 INFO  [192.168.1.25,52191,1487756294218-BalancerChore] hbase.Chore(93): 192.168.1.25,52191,1487756294218-BalancerChore exiting
2017-02-22 10:39:02,430 INFO  [192.168.1.25,52191,1487756294218-ClusterStatusChore] hbase.Chore(93): 192.168.1.25,52191,1487756294218-ClusterStatusChore exiting
2017-02-22 10:39:02,430 INFO  [CatalogJanitor-192.168.1.25:52191] hbase.Chore(93): CatalogJanitor-192.168.1.25:52191 exiting
2017-02-22 10:39:02,430 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52177-0x15a652bf9a6000f, quorum=localhost:26262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:39:02,431 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:39:02,431 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/running
2017-02-22 10:39:02,431 INFO  [main] regionserver.HRegionServer(1865): STOPPED: Shutdown requested
2017-02-22 10:39:02,431 INFO  [RS:0;192.168.1.25:52193] ipc.RpcServer(2286): Stopping server on 52193
2017-02-22 10:39:02,431 INFO  [RpcServer.listener,port=52193] ipc.RpcServer$Listener(823): RpcServer.listener,port=52193: stopping
2017-02-22 10:39:02,432 INFO  [M:0;192.168.1.25:52177] master.HMaster(733): HMaster main thread exiting
2017-02-22 10:39:02,433 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:39:02,433 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:39:02,433 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:39:02,433 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZKUtil(368): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:39:02,434 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/running
2017-02-22 10:39:02,434 INFO  [RS:0;192.168.1.25:52193] regionserver.SplitLogWorker(604): Sending interrupt to stop the worker thread
2017-02-22 10:39:02,434 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(971): Stopping infoServer
2017-02-22 10:39:02,434 INFO  [SplitLogWorker-192.168.1.25,52193,1487756294244] regionserver.SplitLogWorker(295): SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2017-02-22 10:39:02,434 INFO  [SplitLogWorker-192.168.1.25,52193,1487756294244] regionserver.SplitLogWorker(212): SplitLogWorker 192.168.1.25,52193,1487756294244 exiting
2017-02-22 10:39:02,543 INFO  [RS:0;192.168.1.25:52193] snapshot.RegionServerSnapshotManager(136): Stopping RegionServerSnapshotManager gracefully.
2017-02-22 10:39:02,543 INFO  [192.168.1.25,52193,1487756294244-HeapMemoryChore] hbase.Chore(93): 192.168.1.25,52193,1487756294244-HeapMemoryChore exiting
2017-02-22 10:39:02,543 INFO  [RS:0;192.168.1.25:52193.logRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:39:02,543 INFO  [RS_OPEN_META-192.168.1.25:52193-0-MetaLogRoller] regionserver.LogRoller(120): LogRoller exiting.
2017-02-22 10:39:02,543 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.0 exiting
2017-02-22 10:39:02,543 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1018): stopping server 192.168.1.25,52193,1487756294244
2017-02-22 10:39:02,544 DEBUG [RS_CLOSE_REGION-192.168.1.25:52193-0] handler.CloseRegionHandler(128): Processing close of hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:39:02,543 INFO  [RS:0;192.168.1.25:52193.nonceCleaner] hbase.Chore(93): RS:0;192.168.1.25:52193.nonceCleaner exiting
2017-02-22 10:39:02,543 INFO  [RS:0;192.168.1.25:52193.compactionChecker] hbase.Chore(93): RS:0;192.168.1.25:52193.compactionChecker exiting
2017-02-22 10:39:02,545 DEBUG [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.HRegion(1224): Closing hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.: disabling compactions & flushes
2017-02-22 10:39:02,544 DEBUG [RS:0;192.168.1.25:52193] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@60a10040
2017-02-22 10:39:02,544 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher$FlushHandler(274): MemStoreFlusher.1 exiting
2017-02-22 10:39:02,545 INFO  [RS:0;192.168.1.25:52193] regionserver.CompactSplitThread(381): Waiting for Split Thread to finish...
2017-02-22 10:39:02,545 DEBUG [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.HRegion(1251): Updates disabled for region hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:39:02,545 INFO  [RS:0;192.168.1.25:52193] regionserver.CompactSplitThread(381): Waiting for Merge Thread to finish...
2017-02-22 10:39:02,546 INFO  [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.HRegion(1819): Started memstore flush for hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749., current region memstore size 344
2017-02-22 10:39:02,546 INFO  [RS:0;192.168.1.25:52193] regionserver.CompactSplitThread(381): Waiting for Large Compaction Thread to finish...
2017-02-22 10:39:02,546 INFO  [RS:0;192.168.1.25:52193] regionserver.CompactSplitThread(381): Waiting for Small Compaction Thread to finish...
2017-02-22 10:39:02,546 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1231): Waiting on 2 regions to close
2017-02-22 10:39:02,546 DEBUG [RS_CLOSE_META-192.168.1.25:52193-0] handler.CloseRegionHandler(128): Processing close of hbase:meta,,1.1588230740
2017-02-22 10:39:02,546 DEBUG [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1235): {1588230740=hbase:meta,,1.1588230740, 17ef2f59c4d7f1148ea1b890ea053749=hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.}
2017-02-22 10:39:02,547 DEBUG [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.HRegion(1224): Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2017-02-22 10:39:02,547 DEBUG [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.HRegion(1251): Updates disabled for region hbase:meta,,1.1588230740
2017-02-22 10:39:02,547 INFO  [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.HRegion(1819): Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 992
2017-02-22 10:39:02,568 INFO  [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/17ef2f59c4d7f1148ea1b890ea053749/.tmp/14a4594fb66b47aba41f040673aadc15
2017-02-22 10:39:02,569 DEBUG [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/17ef2f59c4d7f1148ea1b890ea053749/.tmp/14a4594fb66b47aba41f040673aadc15 as file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/17ef2f59c4d7f1148ea1b890ea053749/info/14a4594fb66b47aba41f040673aadc15
2017-02-22 10:39:02,570 INFO  [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.DefaultStoreFlusher(95): Flushed, sequenceid=4, memsize=992, hasBloomFilter=false, into tmp file file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/.tmp/9e28e7671e7942da8d5e18123eb90303
2017-02-22 10:39:02,570 INFO  [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster3/root/data/hbase/namespace/17ef2f59c4d7f1148ea1b890ea053749/info/14a4594fb66b47aba41f040673aadc15, entries=2, sequenceid=4, filesize=1.0 K
2017-02-22 10:39:02,570 INFO  [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.HRegion(1986): Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749. in 24ms, sequenceid=4, compaction requested=false
2017-02-22 10:39:02,571 DEBUG [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.HRegionFileSystem(382): Committing store file file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/.tmp/9e28e7671e7942da8d5e18123eb90303 as file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/info/9e28e7671e7942da8d5e18123eb90303
2017-02-22 10:39:02,571 INFO  [StoreCloserThread-hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.-1] regionserver.HStore(780): Closed info
2017-02-22 10:39:02,572 DEBUG [RS_CLOSE_REGION-192.168.1.25:52193-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:39:02,572 INFO  [RS_CLOSE_REGION-192.168.1.25:52193-0] regionserver.HRegion(1340): Closed hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:39:02,572 DEBUG [RS_CLOSE_REGION-192.168.1.25:52193-0] handler.CloseRegionHandler(182): Closed hbase:namespace,,1487756299252.17ef2f59c4d7f1148ea1b890ea053749.
2017-02-22 10:39:02,572 INFO  [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.HStore(883): Added file:/var/tmp/test-data/cluster3/root/data/hbase/meta/1588230740/info/9e28e7671e7942da8d5e18123eb90303, entries=4, sequenceid=4, filesize=1.3 K
2017-02-22 10:39:02,572 INFO  [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.HRegion(1986): Finished memstore flush of ~992/992, currentsize=0/0 for region hbase:meta,,1.1588230740 in 25ms, sequenceid=4, compaction requested=false
2017-02-22 10:39:02,573 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore(780): Closed info
2017-02-22 10:39:02,573 DEBUG [RS_CLOSE_META-192.168.1.25:52193-0] coprocessor.CoprocessorHost(316): Stop coprocessor pt.uminho.haslab.smcoprocessors.SmpcCoprocessor
2017-02-22 10:39:02,573 DEBUG [RS_CLOSE_META-192.168.1.25:52193-0] coprocessor.CoprocessorHost(316): Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2017-02-22 10:39:02,573 INFO  [RS_CLOSE_META-192.168.1.25:52193-0] regionserver.HRegion(1340): Closed hbase:meta,,1.1588230740
2017-02-22 10:39:02,573 DEBUG [RS_CLOSE_META-192.168.1.25:52193-0] handler.CloseRegionHandler(182): Closed hbase:meta,,1.1588230740
2017-02-22 10:39:02,740 INFO  [192.168.1.25,52191,1487756294218.splitLogManagerTimeoutMonitor] hbase.Chore(93): 192.168.1.25,52191,1487756294218.splitLogManagerTimeoutMonitor exiting
2017-02-22 10:39:02,751 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1037): stopping server 192.168.1.25,52193,1487756294244; all regions closed.
2017-02-22 10:39:02,751 DEBUG [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:39:02,752 INFO  [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncNotifier exiting
2017-02-22 10:39:02,752 DEBUG [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,752 INFO  [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer0 exiting
2017-02-22 10:39:02,752 DEBUG [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,752 INFO  [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer1 exiting
2017-02-22 10:39:02,752 DEBUG [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,753 INFO  [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer2 exiting
2017-02-22 10:39:02,753 DEBUG [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,753 INFO  [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer3 exiting
2017-02-22 10:39:02,753 DEBUG [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,753 INFO  [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncSyncer4 exiting
2017-02-22 10:39:02,753 DEBUG [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:39:02,753 INFO  [RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS_OPEN_META-192.168.1.25:52193-0-WAL.AsyncWriter exiting
2017-02-22 10:39:02,754 DEBUG [RS:0;192.168.1.25:52193] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,52193,1487756294244
2017-02-22 10:39:02,754 DEBUG [RS:0;192.168.1.25:52193-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1351): RS:0;192.168.1.25:52193-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2017-02-22 10:39:02,754 INFO  [RS:0;192.168.1.25:52193-WAL.AsyncNotifier] wal.FSHLog$AsyncNotifier(1356): RS:0;192.168.1.25:52193-WAL.AsyncNotifier exiting
2017-02-22 10:39:02,754 DEBUG [RS:0;192.168.1.25:52193-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52193-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,754 INFO  [RS:0;192.168.1.25:52193-WAL.AsyncSyncer0] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52193-WAL.AsyncSyncer0 exiting
2017-02-22 10:39:02,754 DEBUG [RS:0;192.168.1.25:52193-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52193-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,755 INFO  [RS:0;192.168.1.25:52193-WAL.AsyncSyncer1] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52193-WAL.AsyncSyncer1 exiting
2017-02-22 10:39:02,755 DEBUG [RS:0;192.168.1.25:52193-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52193-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,755 INFO  [RS:0;192.168.1.25:52193-WAL.AsyncSyncer2] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52193-WAL.AsyncSyncer2 exiting
2017-02-22 10:39:02,755 DEBUG [RS:0;192.168.1.25:52193-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52193-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,755 INFO  [RS:0;192.168.1.25:52193-WAL.AsyncSyncer3] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52193-WAL.AsyncSyncer3 exiting
2017-02-22 10:39:02,755 DEBUG [RS:0;192.168.1.25:52193-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1297): RS:0;192.168.1.25:52193-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2017-02-22 10:39:02,755 INFO  [RS:0;192.168.1.25:52193-WAL.AsyncSyncer4] wal.FSHLog$AsyncSyncer(1302): RS:0;192.168.1.25:52193-WAL.AsyncSyncer4 exiting
2017-02-22 10:39:02,756 DEBUG [RS:0;192.168.1.25:52193-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1163): RS:0;192.168.1.25:52193-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2017-02-22 10:39:02,756 INFO  [RS:0;192.168.1.25:52193-WAL.AsyncWriter] wal.FSHLog$AsyncWriter(1168): RS:0;192.168.1.25:52193-WAL.AsyncWriter exiting
2017-02-22 10:39:02,756 DEBUG [RS:0;192.168.1.25:52193] wal.FSHLog(948): Closing WAL writer in file:/var/tmp/test-data/cluster3/root/WALs/192.168.1.25,52193,1487756294244
2017-02-22 10:39:02,757 DEBUG [RS:0;192.168.1.25:52193] wal.FSHLog(892): Moved 2 WAL file(s) to /var/tmp/test-data/cluster3/root/oldWALs
2017-02-22 10:39:02,757 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:39:02,758 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(1022): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: closed
2017-02-22 10:39:02,758 DEBUG [RpcServer.reader=1,port=52191] ipc.RpcServer$Listener(910): RpcServer.listener,port=52191: DISCONNECTING client 192.168.1.25:52198 because read count=-1. Number of active connections: 1
2017-02-22 10:39:02,758 DEBUG [IPC Client (1499867659) connection to /192.168.1.25:52191 from roger] ipc.RpcClient$Connection(742): IPC Client (1499867659) connection to /192.168.1.25:52191 from roger: stopped, connections 0
2017-02-22 10:39:02,859 INFO  [RS:0;192.168.1.25:52193] regionserver.Leases(147): RS:0;192.168.1.25:52193 closing leases
2017-02-22 10:39:02,860 INFO  [RS:0;192.168.1.25:52193] regionserver.Leases(150): RS:0;192.168.1.25:52193 closed leases
2017-02-22 10:39:03,295 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x27e0f2f5] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x27e0f2f5 exiting
2017-02-22 10:39:03,471 INFO  [M:0;192.168.1.25:52191] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52193,1487756294244
2017-02-22 10:39:04,011 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x1842d38d] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x1842d38d exiting
2017-02-22 10:39:04,036 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x97d8c32] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x97d8c32 exiting
2017-02-22 10:39:04,513 INFO  [M:0;192.168.1.25:52191] master.ServerManager(504): Waiting on regionserver(s) to go down 192.168.1.25,52193,1487756294244
2017-02-22 10:39:04,692 INFO  [RS:0;192.168.1.25:52193.periodicFlusher] hbase.Chore(93): RS:0;192.168.1.25:52193.periodicFlusher exiting
2017-02-22 10:39:04,692 INFO  [RS:0;192.168.1.25:52193.leaseChecker] regionserver.Leases(147): RS:0;192.168.1.25:52193.leaseChecker closing leases
2017-02-22 10:39:04,692 INFO  [RS:0;192.168.1.25:52193.leaseChecker] regionserver.Leases(150): RS:0;192.168.1.25:52193.leaseChecker closed leases
2017-02-22 10:39:04,696 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/replication/rs/192.168.1.25,52193,1487756294244
2017-02-22 10:39:04,696 INFO  [RS:0;192.168.1.25:52193] client.HConnectionManager$HConnectionImplementation(1961): Closing zookeeper sessionid=0x15a652c12db0013
2017-02-22 10:39:04,698 DEBUG [RS:0;192.168.1.25:52193] ipc.RpcClient(1427): Stopping rpc client
2017-02-22 10:39:04,699 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,52193,1487756294244
2017-02-22 10:39:04,699 DEBUG [RS:0;192.168.1.25:52193-EventThread] zookeeper.ZooKeeperWatcher(528): regionserver:52193-0x15a652c12db0012, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:39:04,699 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/rs/192.168.1.25,52193,1487756294244
2017-02-22 10:39:04,700 INFO  [main-EventThread] zookeeper.RegionServerTracker(118): RegionServer ephemeral node deleted, processing expiration [192.168.1.25,52193,1487756294244]
2017-02-22 10:39:04,700 INFO  [main-EventThread] master.ServerManager(550): Cluster shutdown set; 192.168.1.25,52193,1487756294244 expired; onlineServers=0
2017-02-22 10:39:04,700 DEBUG [M:0;192.168.1.25:52191] master.HMaster(1359): Stopping service threads
2017-02-22 10:39:04,701 INFO  [M:0;192.168.1.25:52191] ipc.RpcServer(2286): Stopping server on 52191
2017-02-22 10:39:04,700 INFO  [main-EventThread] master.HMaster(2748): Cluster shutdown set; onlineServer=0
2017-02-22 10:39:04,701 INFO  [RpcServer.listener,port=52191] ipc.RpcServer$Listener(823): RpcServer.listener,port=52191: stopping
2017-02-22 10:39:04,701 DEBUG [main-EventThread] catalog.CatalogTracker(223): Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@4cb84158
2017-02-22 10:39:04,701 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeChildrenChanged, state=SyncConnected, path=/hbase/rs
2017-02-22 10:39:04,702 DEBUG [RpcServer.responder] ipc.RpcServer$Responder(999): RpcServer.responder: checking for old call responses.
2017-02-22 10:39:04,702 INFO  [RpcServer.responder] ipc.RpcServer$Responder(1042): RpcServer.responder: stopped
2017-02-22 10:39:04,702 INFO  [RpcServer.responder] ipc.RpcServer$Responder(962): RpcServer.responder: stopping
2017-02-22 10:39:04,702 INFO  [M:0;192.168.1.25:52191.oldLogCleaner] hbase.Chore(93): M:0;192.168.1.25:52191.oldLogCleaner exiting
2017-02-22 10:39:04,702 INFO  [M:0;192.168.1.25:52191.oldLogCleaner] master.ReplicationLogCleaner(164): Stopping replicationLogCleaner-0x15a652c12db0011, quorum=localhost:36262, baseZNode=/hbase
2017-02-22 10:39:04,703 INFO  [M:0;192.168.1.25:52191.archivedHFileCleaner] hbase.Chore(93): M:0;192.168.1.25:52191.archivedHFileCleaner exiting
2017-02-22 10:39:04,704 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1075): stopping server 192.168.1.25,52193,1487756294244; zookeeper connection closed.
2017-02-22 10:39:04,704 INFO  [RS:0;192.168.1.25:52193] regionserver.HRegionServer(1078): RS:0;192.168.1.25:52193 exiting
2017-02-22 10:39:04,705 INFO  [Shutdown of org.apache.hadoop.hbase.fs.HFileSystem@6eb3afde] hbase.MiniHBaseCluster$SingleFileSystemShutdownThread(190): Hook closing fs=org.apache.hadoop.hbase.fs.HFileSystem@6eb3afde
2017-02-22 10:39:04,705 INFO  [main] util.JVMClusterUtil(325): Shutdown of 1 master(s) and 1 regionserver(s) complete
2017-02-22 10:39:04,707 DEBUG [main-EventThread] zookeeper.ZooKeeperWatcher(528): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Received ZooKeeper Event, type=NodeDeleted, state=SyncConnected, path=/hbase/master
2017-02-22 10:39:04,707 DEBUG [main-EventThread] zookeeper.ZKUtil(368): master:52191-0x15a652c12db000f, quorum=localhost:36262, baseZNode=/hbase Set watcher on znode that does not yet exist, /hbase/master
2017-02-22 10:39:04,709 INFO  [M:0;192.168.1.25:52191] master.HMaster(733): HMaster main thread exiting
2017-02-22 10:39:08,835 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x7a0e1b5e] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x7a0e1b5e exiting
2017-02-22 10:39:12,411 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0xcd1cb06] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0xcd1cb06 exiting
2017-02-22 10:39:12,434 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x211e0306] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x211e0306 exiting
2017-02-22 10:39:14,211 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x2fa7ae9] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x2fa7ae9 exiting
2017-02-22 10:39:14,695 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x346110f5] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x346110f5 exiting
2017-02-22 10:39:14,725 INFO  [ZooKeeperWatcher and Master delayed closing for connection hconnection-0x722815ef] hbase.Chore(93): ZooKeeperWatcher and Master delayed closing for connection hconnection-0x722815ef exiting
2017-02-22 10:39:34,715 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(111): Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@163370c2
2017-02-22 10:39:34,715 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(133): Shutdown hook finished.
2017-02-22 10:39:34,715 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(111): Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@163370c2
2017-02-22 10:39:34,715 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(133): Shutdown hook finished.
2017-02-22 10:39:34,715 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(111): Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@163370c2
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(133): Shutdown hook finished.
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(111): Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@163370c2
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(133): Shutdown hook finished.
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(111): Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@163370c2
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(133): Shutdown hook finished.
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(111): Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@163370c2
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(120): Starting fs shutdown hook thread.
2017-02-22 10:39:34,716 INFO  [Thread-5] regionserver.ShutdownHook$ShutdownHookThread(133): Shutdown hook finished.
